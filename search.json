[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R 4 Epidemiology",
    "section": "",
    "text": "Welcome\nWelcome to R for Epidemiology!\nThis electronic textbook was originally created to accompany the Introduction to R Programming for Epidemiologic Research course at the University of Texas Health Science Center School of Public Health. However, we hope it will be useful to anyone who is interested in R, epidemiology, or human health and well-being.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "R 4 Epidemiology",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis book is currently a work in progress (and probably always will be); however, there are already many people who have played an important role (some unknowingly) in helping develop it thus far. First, we’d like to offer our gratitude to all past, current, and future members of the R Core Team for maintaining this amazing, free software. We’d also like to express our gratitude to everyone at Posit. You are also developing and giving away some amazing software. In particular, we’d like to acknowledge Garrett Grolemund and Hadley Wickham. Both have had a huge impact on how we use and teach R. We’d also like to thank our students for all the feedback they’ve given us while taking our courses. In particular, we want to thank Jared Wiegand and Yiqun Wang for their many edits and suggestions.\nThis electronic textbook was created and published using R, RStudio, the Quarto, and GitHub.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "chapters/introduction.html",
    "href": "chapters/introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Goals\nWe’re going to start the introduction by writing down some basic goals that underlie the construction and content of this book. We’re writing this for you, the reader, but also to hold ourselves accountable as we write. So, feel free to read if you are interested or skip ahead if you aren’t.\nThe goals of this book are:",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/introduction.html#goals",
    "href": "chapters/introduction.html#goals",
    "title": "Introduction",
    "section": "",
    "text": "To teach you how to use R and RStudio as tools for applied epidemiology.1 Our goal is not to teach you to be a computer scientist or an advanced R programmer. Therefore, some readers who are experienced programmers may catch some technical inaccuracies regarding what we consider to be the fine points of what R is doing “under the hood.”\nTo make this writing as accessible and practically useful as possible without stripping out all of the complexity that makes doing epidemiology in real life a challenge. In other words, We’re going to try to give you all the tools you need to do epidemiology in “real world” conditions (as opposed to ideal conditions) without providing a whole bunch of extraneous (often theoretical) stuff that detracts from doing. Having said that, we will strive to add links to the other (often theoretical) stuff for readers who are interested.\nTo teach you to accomplish common tasks, rather than teach you to use functions or families of functions. In many R courses and texts, there is a focus on learning all the things a function, or set of related functions, can do. It’s then up to you, the reader, to sift through all of these capabilities and decided which, if any, of the things that can be done will accomplish the tasks that you are actually trying to accomplish. Instead, we will strive to start with the end in mind. What is the task we are actually trying to accomplish? What are some functions/methods we could use to accomplish that task? What are the strengths and limitations of each?\nTo start each concept by showing you the end result and then deconstruct how we arrived at that result, where possible. We find that it is easier for many people to understand new concepts when learning them as a component of a final product.\nTo learn concepts with data instead of (or alongside) mathematical formulas and text descriptions, where possible. We find that it is easier for many people to understand new concepts by seeing them in action.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/introduction.html#text-conventions-used-in-this-book",
    "href": "chapters/introduction.html#text-conventions-used-in-this-book",
    "title": "Introduction",
    "section": "Text conventions used in this book",
    "text": "Text conventions used in this book\n\nWe will hyperlink many keywords or phrases to their glossary entry.\nAdditionally, we may use bold face for a word or phrase that we want to call attention to, but it is not necessarily a keyword or phrase that we want to define in the glossary.\nHighlighted inline code is used to emphasize small sections of R code and program elements such as variable or function names.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/introduction.html#other-reading",
    "href": "chapters/introduction.html#other-reading",
    "title": "Introduction",
    "section": "Other reading",
    "text": "Other reading\nIf you are interested in R4Epi, you may also be interested in:\n\nHands-on Programming with R by Garrett Grolemund. This book is designed to provide a friendly introduction to the R language.\nR for Data Science by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund. This book is designed to teach readers how to do data science with R.\nStatistical Inference via Data Science: A ModernDive into R and the Tidyverse. This book is designed to be a gentle introduction to the practice of analyzing data and answering questions using data the way data scientists, statisticians, data journalists, and other researchers would.\nReproducable Research with R and RStudio by Christopher Gandrud. This book gives you tools for data gathering, analysis, and presentation of results so that you can create dynamic and highly reproducible research.\nAdvanced R by Hadley Wickham. This book is designed primarily for R users who want to improve their programming skills and understanding of the language.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/introduction.html#footnotes",
    "href": "chapters/introduction.html#footnotes",
    "title": "Introduction",
    "section": "",
    "text": "In this case, “tools for applied epidemiology” means (1) understanding epidemiologic concepts; and (2) completing and interpreting epidemiologic analyses.↩︎",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "chapters/contributing/contributing.html",
    "href": "chapters/contributing/contributing.html",
    "title": "Contributing",
    "section": "",
    "text": "Typos\nThe easiest way for you to contribute is to help us clean up the little typos and grammatical errors that inevitably sneak into the text.\nIf you spot a typo, you can offer a correction directly in GitHub. You will first need to create a free GitHub account: sign-up at github.com. Later in the book, we will cover using GitHub in greater depth in see Using-git-and-Github. Here, we’re just going to walk you through how to fix a typo without much explanation of how GitHub works.\nLet’s say you spot a typo while reading along.\nNext, click the edit button in the toolbar as shown in the screenshot below.\nThe first time you click the icon, you will be taken to the R4Epi repository on GitHub and asked to fork it. For our purposes, you can think of a GitHub repository as being similar to a shared folder on Dropbox or Google Drive.\n“Forking the repository” basically just means “make a copy of the repository” on your GitHub account. In other words, copy all of the files that make up the R4Epi textbook to your GitHub account. Then, you can fix the typos you found in your copy of the files that make up the book instead of directly editing the actual files that make up the book. This is a safeguard to prevent people from accidentally making changes that shouldn’t be made.\nAfter you fork the repository, you will see a text editor on your screen.\nThe text editor will display the contents of the file used to make the chapter you were looking at when you clicked the edit button. In this example, it was a file named contributing.qmd. The .qmd file extension means that the file is a Quarto/file. We will learn more about Quarto files, but for now just know that Quarto/ files can be used to create web pages and other documents that contain a mix of R code, text, and images.\nNext, scroll down through the text until you find the typo and fix it. In this case, line 11 contains the word “typoo”. To fix it, you just need to click in the editor window and begin typing. In this case, you would click next to the word “typoo” and delete the second “o”.\nNow, the only thing left to do is propose your typo fix to the authors. To do so, click the green Commit changes... button on the right side of the screen above the text editor (surrounded with a red box in the screenshot above). When you click it, a new Propose changes box will appear on your screen. Type a brief (i.e., 72 characters or less) summary of the change you made in the Commit message box. There is also an Extended description box where you can add a more detailed description of what you did. In the screenshot below, shows an example commit message and extended description that will make it easy for the author to quickly figure out exactly what changes are being proposed.\nNext, click the Propose changes button. That will take you to another screen where you will be able to create a pull request. This screen is kind of busy, but try not to let it overwhelm you.\nFor now, we will focus on the three different sections of the screen that are highlighted with a red outline. We will start at the bottom and work our way up. The red box that is closest to the bottom of the screenshot shows us that the change that made was on line 11. The word “typoo” (highlighted in red) was replaced with the word “typo” (highlighted in green). The red box in the middle of the screenshot shows us the brief description that was written for our proposed change – “Fix a typo in contributing.qmd”. Finally, the red box closest to the top of the screenshot is surrounding the Create pull request button. You will click it to move on with your pull request.\nAfter doing so, you will get one final chance to amend the description of your proposed changes. If you are happy with the commit message and description, then click the Create pull request button one more time. At this point, your job is done! It is now up to the authors to review the changes you’ve proposed and “pull” them into the file in their repository.\nIn case you are curious, here is what the process looks like on the authors’ end. First, when we open the R4Epi repository page on GitHub, we will see that there is a new pull request.\nWhen we open the pull request, we can see the proposed changes to the file.\nThen, all we have to do is click the Merge pull request button and the fixed file is “pulled in” to replace the file with the typo.",
    "crumbs": [
      "Contributing"
    ]
  },
  {
    "objectID": "chapters/contributing/contributing.html#typos",
    "href": "chapters/contributing/contributing.html#typos",
    "title": "Contributing",
    "section": "",
    "text": "Note\n\n\n\nForking the R4Epi repository does not cost any money or add any files to your computer.",
    "crumbs": [
      "Contributing"
    ]
  },
  {
    "objectID": "chapters/contributing/contributing.html#issues",
    "href": "chapters/contributing/contributing.html#issues",
    "title": "Contributing",
    "section": "Issues",
    "text": "Issues\nThere may be times when you see a problem that you don’t know how to fix, but you still want to make the authors aware of. In that case, you can create an issue in the R4Epi repository. To do so, navigate to the issue tracker using this link: https://github.com/brad-cannell/r4epi/issues.\n\n\n\n\n\n\n\n\n\nOnce there, you can check to see if someone has already raised the issue you are concerned about. If not, you can click the green “New issue” button to raise it yourself.\nPlease note that R4Epi uses a Contributor Code of Conduct. By contributing to this book, you agree to abide by its terms.",
    "crumbs": [
      "Contributing"
    ]
  },
  {
    "objectID": "chapters/contributing/contributing.html#license-information",
    "href": "chapters/contributing/contributing.html#license-information",
    "title": "Contributing",
    "section": "License Information",
    "text": "License Information\nThis book was created by Brad Cannell and is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License.",
    "crumbs": [
      "Contributing"
    ]
  },
  {
    "objectID": "chapters/about_the_authors/about_the_authors.html",
    "href": "chapters/about_the_authors/about_the_authors.html",
    "title": "About the Authors",
    "section": "",
    "text": "Brad Cannell\nMichael (Brad) Cannell, PhD, MPH\n  Associate Professor\nElder Mistreatment Lead, UTHealth Institute of Aging\nDirector, Research Informatics Core, Cizik Nursing Research Institute\nUTHealth Houston\nMcGovern Medical School\nJoan and Stanford Alexander Division of Geriatric & Palliative Medicine\nwww.bradcannell.com\nDr. Cannell received his PhD in Epidemiology, and Graduate Certificate in Gerontology, in 2013 from the University of Florida. He received his MPH with a concentration in Epidemiology from the University of Louisville in 2009, and his BA in Political Science and Marketing from the University of North Texas in 2005. During his doctoral studies, he was a Graduate Research Assistant for the Florida Office on Disability and Health, an affiliated scholar with the Claude D. Pepper Older Americans Independence Center, and a student-inducted member of the Delta Omega Honorary Society in Public Health. In 2016, Dr. Cannell received a Graduate Certificate in Predictive Analytics from the University of Maryland University College, and a Certificate in Big Data and Social Analytics from the Massachusetts Institute of Technology.\nHe previously held professional staff positions in the Louisville Metro Health Department and the Northern Kentucky Independent District Health Department. He spent three years as a project epidemiologist for the Florida Office on Disability and Health at the University of Florida. He also served as an Environmental Science Officer in the United States Army Reserves from 2009 to 2013.\nDr. Cannell’s research is broadly focused on healthy aging and health-related quality of life. Specifically, he has published research focusing on preservation of physical and cognitive function, living and aging with disability, and understanding and preventing elder mistreatment. Additionally, he has a strong background and training in epidemiologic methods and predictive analytics. He has been principal or co-investigator on multiple trials and observational studies in community and healthcare settings. He is currently the principal investigator on multiple data-driven federally funded projects that utilize technological solutions to public health issues in novel ways.\nContact\nConnect with Dr. Cannell and follow his work.",
    "crumbs": [
      "About the Authors"
    ]
  },
  {
    "objectID": "chapters/about_the_authors/about_the_authors.html#melvin-livingston",
    "href": "chapters/about_the_authors/about_the_authors.html#melvin-livingston",
    "title": "About the Authors",
    "section": "Melvin Livingston",
    "text": "Melvin Livingston\nMelvin (Doug) Livingston, PhD\n  Research Associate Professor\nDepartment of Behavioral, Social, and Health Education Sciences\nEmory University Woodruff Health Sciences Center\nRollins School of Public Health\nDr. Livingston’s Faculty Profile\nDr. Livingston is a methodologist with expertise in the the application of quasi-experimental design principals to the evaluation for both community interventions and state policies. He has particular expertise in time series modeling, mixed effects modeling, econometric methods, and power analysis. As part of his work involving community trials, he has been the statistician on the long term follow-up study of a school based cluster randomized trial in low-income communities with a focus on explaining the etiology of risky alcohol, drug, and sexual behaviors. Additionally, he was the statistician for a longitudinal study examining the etiology of alcohol use among racially diverse and economically disadvantaged urban youth, and co-investigator for a NIAAA- and NIDA-funded trial to prevent alcohol use and alcohol-related problems among youth living in high-risk, low-income communities within the Cherokee Nation. Prevention work at the community level led him to an interest in the impact of state and federal socioeconomic policies on health outcomes. He is a Co-Investigator of a 50-state, 30-year study of effects of state-level economic and education policies on a diverse set of public health outcomes, explicitly examining differential effects across disadvantaged subgroups of the population.\nHis current research interests center around the application of quasi-experimental design and econometric methods to the evaluation of the health effects of state and federal policy.\nContact\nConnect with Dr. Livingston and follow his work.",
    "crumbs": [
      "About the Authors"
    ]
  },
  {
    "objectID": "chapters/installing_r_and_rstudio/installing_r_and_rstudio.html",
    "href": "chapters/installing_r_and_rstudio/installing_r_and_rstudio.html",
    "title": "1  Installing R and RStudio",
    "section": "",
    "text": "1.1 Download and install on a Mac\nStep 2: Navigate to the Comprehensive R Archive Network (CRAN), which is located at https://cran.r-project.org/.\nStep 3: Click on Download R for macOS.\nStep 4: Click on the link for the latest version of R. As you are reading this, the newest version may be different than the version you see in this picture, but the location of the newest version should be roughly in the same place – the middle of the screen under “Latest release:”. After clicking the link, R should start to download to your computer automatically.\nStep 5: Locate the package file you just downloaded and double click it. Unless you’ve changed your download settings, this file will probably be in your “downloads” folder. That is the default location for most web browsers. After you locate the file, just double click it.\nStep 6: A dialogue box will open and ask you to make some decisions about how and where you want to install R on your computer. We typically just click “continue” at every step without changing any of the default options.\nIf R installed properly, you should now see it in your applications folder.\nStep 7: Now, we need to install the RStudio IDE. To do this, navigate to the RStudio desktop download website, which is located at https://posit.co/download/rstudio-desktop/. On that page, click the button to download the latest version of RStudio for your computer. Note that the website may look different that what you see in the screenshot below because websites change over time.\nStep 8: Again, locate the DMG file you just downloaded and double click it. Unless you’ve changed your download settings, this file should be in the same location as the R package file you already downloaded.\nStep 9: A new finder window should automatically pop up that looks like the one you see below. Click on the RStudio icon and drag it into the Applications folder.\nYou should now see RStudio in your Applications folder. Double click the icon to open RStudio.\nIf this warning pops up, just click Open.\nThe RStudio IDE should open and look something like the window you see here. If so, you are good to go! 🎉",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installing R and RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/installing_r_and_rstudio/installing_r_and_rstudio.html#download-and-install-on-a-pc",
    "href": "chapters/installing_r_and_rstudio/installing_r_and_rstudio.html#download-and-install-on-a-pc",
    "title": "1  Installing R and RStudio",
    "section": "1.2 Download and install on a PC",
    "text": "1.2 Download and install on a PC\nStep 2: Navigate to the Comprehensive R Archive Network (CRAN), which is located at https://cran.r-project.org/.\n\n\n\n\n\n\n\n\n\nStep 3: Click on Download R for Windows.\n\n\n\n\n\n\n\n\n\nStep 4: Click on the base link.\n\n\n\n\n\n\n\n\n\nStep 5: Click on the link for the latest version of R. As you are reading this, the newest version may be different than the version you see in this picture, but the location of the newest version should be roughly the same. After clicking, R should start to download to your computer.\n\n\n\n\n\n\n\n\n\nStep 6: Locate the installation file you just downloaded and double click it. Unless you’ve changed your download settings, this file will probably be in your downloads folder. That is the default location for most web browsers.\n\n\n\n\n\n\n\n\n\nStep 7: A dialogue box will open that asks you to make some decisions about how and where you want to install R on your computer. We typically just click “Next” at every step without changing any of the default options.\n\n\n\n\n\n\n\n\n\nIf R installed properly, you should now see it in the Windows start menu.\n\n\n\n\n\n\n\n\n\nStep 8: Now, we need to install the RStudio IDE. To do this, navigate to the RStudio desktop download website, which is located at https://posit.co/download/rstudio-desktop/. On that page, click the button to download the latest version of RStudio for your computer. Note that the website may look different that what you see in the screenshot below because websites change over time.\n\n\n\n\n\n\n\n\n\nStep 9: Again, locate the installation file you just downloaded and double click it. Unless you’ve changed your download settings, this file should be in the same location as the R installation file you already downloaded.\n\n\n\n\n\n\n\n\n\nStep 10: Another dialogue box will open and ask you to make some decisions about how and where you want to install RStudio on your computer. We typically just click “Next” at every step without changing any of the default options.\n\n\n\n\n\n\n\n\n\nWhen RStudio is finished installing, you should see RStudio in the Windows start menu. Click the icon to open RStudio.\n\n\n\n\n\n\n\n\n\nThe RStudio IDE should open and look something like the window you see here. If so, you are good to go! 🎉",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Installing R and RStudio</span>"
    ]
  },
  {
    "objectID": "chapters/what_is_r/what_is_r.html",
    "href": "chapters/what_is_r/what_is_r.html",
    "title": "2  What is R?",
    "section": "",
    "text": "2.1 What is data?\nData is information about objects (e.g., people, places, schools) and observable phenomenon (e.g., weather, temperatures, and disease symptoms) that is recorded and stored somehow as a collection of symbols, numbers, and letters. So, data is just information that has been “written” down.\nHere we have a table, which is a common way of organizing data. In R, we will typically refer to these tables as data frames.\nEach box in a data frame is called a cell.\nMoving from left to right across the data frame are columns. Columns are also sometimes referred to as variables. In this book, we will often use the terms columns and variables interchangeably. Each column in a data frame has one, and only one, type. For now, know that the type tells us what kind of data is contained in a column and what we can do with that data. You may have already noticed that 3 of the columns in the table we’ve been looking at contain numbers and 1 of the columns contains words. These columns will have different types in R and we can do different things with them based on their type. For example, we could ask R to tell us what the average value of the numbers in the height column are, but it wouldn’t make sense to ask R to tell us the average value of the words in the Gender column. We will talk more about many of the different column types exist in R later in this book.\nThe information contained in the first cell of each column is called the column name (or variable) name.\nR gives us a lot of flexibility in terms of what we can name our columns, but there are a few rules.\nMoving from top to bottom across the table are rows, which are sometimes referred to as records.\nFinally, the contents of each cell are called values.\nYou should now be up to speed on some basic terminology used by R, as well as other analytic, database, and spreadsheet programs. These terms will be used repeatedly throughout the course.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is R?</span>"
    ]
  },
  {
    "objectID": "chapters/what_is_r/what_is_r.html#what-is-data",
    "href": "chapters/what_is_r/what_is_r.html#what-is-data",
    "title": "2  What is R?",
    "section": "",
    "text": "Column names can contain letters, numbers and the dot (.) or underscore (_) characters.\n\nAdditionally, they can begin with a letter or a dot – as long as the dot is not followed by a number. So, a name like “.2cats” is not allowed.\n\nFinally, R has some reserved words that you are not allowed to use for column names. These include: “if”, “else”, “repeat”, “while”, “function”, “for”, “in”, “next”, and “break”.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is R?</span>"
    ]
  },
  {
    "objectID": "chapters/what_is_r/what_is_r.html#what-is-r",
    "href": "chapters/what_is_r/what_is_r.html#what-is-r",
    "title": "2  What is R?",
    "section": "2.2 What is R?",
    "text": "2.2 What is R?\n\n\n\n\n\n\n\n\n\nSo, what is R? Well, R is an open source statistical programming language that was created in the 1990’s specifically for data analysis. We will talk more about what open source means later, but for now, just think of R as an easy (relatively 😂) way to ask your computer to do math and statistics for you. More specifically, by the end of this book you will be able to independently use R to transfer data, manage data, analyze data, and present the results of your analysis. Let’s quickly take a closer look at each of these.\n\n\n\n\n\n\n\n\n\n\n2.2.1 Transferring data\n\n\n\n\n\n\n\n\n\nSo, what do we mean by “transfer data”? Well, individuals and organizations store their data using different computer programs that use different file types. Some common examples that you may come across in epidemiology are database files, spreadsheets, raw data files, and SAS data sets. No matter how the data is stored, you can’t do anything with it until you can get it into R, in a form that R can use, and in a location that you can reach. In other words, transferring your data. Therefore, among our first tasks in this course will be to transfer data.\n\n\n2.2.2 Managing data\n\n\n\n\n\n\n\n\n\nThis isn’t very specific, but managing data is all the things you may have to do to your data to get it ready for analysis. You may also hear people refer to this process as data wrangling or data munging. Some specific examples of data management tasks include:\n\nValidating and cleaning data. In other words, dealing with potential errors in the data.\n\nSubsetting data. For example, using only some of the columns or some of the rows.\n\nCreating new variables. For example, creating a BMI variable in a data frame that was sent to you with height and weight columns.\n\nCombining data frames. For example, combining sociodemographic data about study participants with data collected in the field during an intervention.\n\nYou may sometimes hear people refer to the 80/20 rule in reference to data management. This “rule” says that in a typical data analysis project, roughly 80% of your time will be spent on data management and only 20% will be spent on the analysis itself. We can’t provide you with any empirical evidence (i.e., data) to back this claim up. But, as people who have been involved in many projects that involve the collection and analysis of data, we can tell you anecdotally that this ”rule” is probably pretty close to being accurate in most cases.\nAdditionally, it’s been our experience that most students of epidemiology are required to take one or more classes that emphasize methods for analyzing data; however, almost none of them have taken a course that emphasizes data management!\nTherefore, because data management is such a large component of most projects that involve the collection and analysis of data, and because most readers will have already been exposed to data analysis to a much greater extent than data management, this course will heavily emphasize the latter.\n\n\n2.2.3 Analyzing data\n\n\n\n\n\n\n\n\n\nAs just discussed, this is probably the capability you most closely associate with R, and there is no doubt that R is a powerful tool for analyzing data. However, in this book we won’t go beyond using R to calculate basic descriptive statistics. For our purposes, descriptive statistics include:\n\nMeasures of central tendency. For example, mean, median, and mode.\n\nMeasures of dispersion. For example, variance and standard error.\n\nMeasures for describing categorical variables. For example, counts and percentages.\n\nDescribing data using graphs and charts. With R, we can describe our data using beautiful and informative graphs.\n\n\n\n2.2.4 Presenting data\n\n\n\n\n\n\n\n\n\nAnd finally, the ultimate goal is typically to present your findings in some form or another. For example, a report, a website, or a journal article. With R you can present your results in many different formats with relative ease. In fact, this is one of our favorite things about R and RStudio. In this class you will learn how to take your text, tabular, or graphical results and then publish them in many different formats including Microsoft Word, html files that can be viewed in web browsers, and pdf documents. Let’s take a look at some examples.\n\nMicrosoft Word documents. Click here to view an example report created for one of our research projects in Microsoft Word.\n\nPDF documents. Click here to view a data dictionary we created in PDF format.\n\nHTML files. Hypertext Markup Language (HTML) files are what you are looking at whenever you view a webpage. You can use R to create HTML files that others can view in their web browser. You can email them these files to view in their web browser, or you can make them available for others to view online just like any other website. Click here to view an example dashboard we created for one of our research projects.\n\nWeb applications. You can even use R to create full-fledged web applications. View the RStudio website to see some examples.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>What is R?</span>"
    ]
  },
  {
    "objectID": "chapters/navigating_rstudio/navigating_rstudio.html",
    "href": "chapters/navigating_rstudio/navigating_rstudio.html",
    "title": "3  Navigating the RStudio Interface",
    "section": "",
    "text": "3.1 The console pane\nThe first pane we are going to talk about is the console/terminal/background jobs pane.\nFigure 3.2: The R Console.\nIt’s called the “console/terminal/background jobs” pane because it has three tabs we can click on by default: “console”, “terminal”, and “background jobs”. However, we will refer to this pane as the “console pane” and will mostly ignore the terminal and background jobs tabs for now. We aren’t ignoring them because they aren’t useful; instead, we are ignoring them because using them isn’t essential for anything we will discuss in this chapter, and we want to keep things as simple as possible for now.\nThe console is the most basic way to interact with R. We can type a command to R into the console prompt (the prompt looks like “&gt;”) and R will respond to what we type. For example, below we typed “1 + 1,” pressed the return/enter key, and the R console returned the sum of the numbers 1 and 1.\nFigure 3.3: Doing some addition in the R console.\nThe number 1 we see in brackets before the 2 (i.e., [1]) is telling us that this line of results starts with the first result. That fact is obvious here because there is only one result. So, let’s look at a result that spans multiple lines to make this idea clearer.\nFigure 3.4: Demonstrating a function that returns multiple results.\nIn Figure 3.4 we see examples of a couple of new concepts that are worth discussing.\nFirst, as promised, we have more than one line of results (or output). The first line of results starts with a 1 in brackets (i.e., [1]), which indicates that this line of results starts with the first result. In this case, the first result is the number 2. The second line of results starts with a 29 in brackets (i.e., [29]), which indicates that this line of results starts with the twenty-ninth result. In this case, the twenty-ninth result is the number 58. If we count the numbers in the first line, there should be 28 – results 1 through 28. We also want to make it clear that “1” and “29” are NOT results themselves. They are just helping us count the number of results per line.\nThe second new thing that you may have noticed in Figure 3.4 is our use of a function. Functions are a BIG DEAL in R. So much so that R is called a functional language. We don’t really need to know all the details of what that means; however, we should know that, in general, everything we do in R we will do with a function. By contrast, everything we create in R will be an object. If we wanted to make an analogy between the R language and the English language, we could think of functions as verbs – they do things – and objects as nouns – they are things. This distinction likely seems abstract and confusing at the moment, but we will make it more concrete soon.\nMost functions in R begin with the function name followed by parentheses. For example, seq(), sum(), and mean().\nQuestion: What is the name of the function we used in the example above?\nAnswer: We used the seq() function – short for sequence - in the example above.\nYou may notice that there are three pairs of words, equal symbols, and numbers that are separated by commas inside the seq() function. They are, from = 2, to = 100, and by = 2. The words from, to, and by are all arguments to the seq() function. We will learn more about functions and arguments later. For now, just know that arguments give functions the information they need to give us the result we want.\nIn this case, the seq() function returns a sequence of numbers. But first, we had to give it information about where that sequence should start, where it should end, and how many steps should be in the middle. Above, the sequence began with the value we passed to the from argument (i.e., 2), it ended with the value we passed to the to argument (i.e., 100), and it increased at each step by the number we passed to the by argument (i.e., 2). So, 2, 4, 6, 8 … 100.\nWhether you realize it or not, we’ve covered some important programming terms while discussing the seq() function above. Before we move on to discussing RStudio’s other panes, let’s quickly review and reinforce a few of terms we will use repeatedly in this book.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Navigating the RStudio Interface</span>"
    ]
  },
  {
    "objectID": "chapters/navigating_rstudio/navigating_rstudio.html#the-console-pane",
    "href": "chapters/navigating_rstudio/navigating_rstudio.html#the-console-pane",
    "title": "3  Navigating the RStudio Interface",
    "section": "",
    "text": "Arguments: Arguments always live inside the parentheses of R functions and receive information the function needs to generate the result we want.\nPass: In programming lingo, we pass a value to a function argument. For example, in the function call seq(from = 2, to = 100, by = 2) we could say that we passed a value of 2 to the from argument, we passed a value of 100 to the to argument, and we passed a value of 2 to the by argument.\nReturn: Instead of saying, “the seq() function gives us a sequence of numbers…” we say, “the seq() function returns a sequence of numbers…” In programming lingo, functions return one or more results.\n\n\n\n\n\n\n\nNote\n\n\n\n🗒Side Note: The seq() function isn’t particularly important or noteworthy. We essentially chose it at random to illustrate some key points. However, arguments, passing values, and return values are extremely important concepts and we will return to them many times.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Navigating the RStudio Interface</span>"
    ]
  },
  {
    "objectID": "chapters/navigating_rstudio/navigating_rstudio.html#the-environment-pane",
    "href": "chapters/navigating_rstudio/navigating_rstudio.html#the-environment-pane",
    "title": "3  Navigating the RStudio Interface",
    "section": "3.2 The environment pane",
    "text": "3.2 The environment pane\nThe second pane we are going to talk about is the environment/history/connections pane in Figure 3.5. However, we will mostly refer to it as the environment pane and we will mostly ignore the history and connections tab. We aren’t ignoring them because they aren’t useful; rather, we are ignoring them because using them isn’t essential for anything we will discuss anytime soon, and we want to keep things as simple as possible.\n\n\n\n\n\n\n\n\nFigure 3.5: The environment pane\n\n\n\n\n\nThe Environment pane shows you all the objects that R can currently use for data management or analysis. In this picture, Figure 3.5 our environment is empty. Let’s create an object and add it to our environment.\n\n\n\n\n\n\n\n\nFigure 3.6: The vector x in the global environment.\n\n\n\n\n\nHere we see that we created a new object called x, which now appears in our Global Environment. Figure 3.6 This gives us another great opportunity to discuss some new concepts.\nFirst, we created the x object in the console by assigning the value 2 to the letter x. We did this by typing “x” followed by a less than symbol (&lt;), a dash symbol (-), and the number 2. R is kind of unique in this way. we have never seen another programming language (although I’m sure they are out there) that uses &lt;- to assign values to variables. By the way, &lt;- is called the assignment operator (or assignment arrow), and ”assign” here means “make x contain 2” or “put 2 inside x.”\nIn many other languages you would write that as x = 2. But, for whatever reason, in R it is &lt;-. Unfortunately, &lt;- is more awkward to type than =. Fortunately, RStudio gives us a keyboard shortcut to make it easier. To type the assignment operator in RStudio, just hold down Option + - (dash key) on a Mac or Alt + - (dash key) on a PC and RStudio will insert &lt;- complete with spaces on either side of the arrow. This may still seem awkward at first, but you will get used to it.\n\n\n\n\n\n\nNote\n\n\n\n🗒Side Note: A note about using the letter “x”: By convention, the letter “x” is a widely used variable name. You will see it used a lot in example documents and online. However, there is nothing special about the letter x. We could have just as easily used any other letter (a &lt;- 2), word (variable &lt;- 2), or descriptive name (my_favorite_number &lt;- 2) that is allowed by R.\n\n\nSecond, you can see that our Global Environment now includes the object x, which has a value of 2. In this case, we would say that x is a numeric vector of length 1 (i.e., it has one value stored in it). We will talk more about vectors and vector types soon. For now, just notice that objects that you can manipulate or analyze in R will appear in your Global Environment.\n\n\n\n\n\n\nWarning\n\n\n\nR is a case sensitive language. That means that uppercase x (X) and lowercase x (x) are different things to R. So, if you assign 2 to lower case x (x &lt;- 2). And then later ask R to tell what number you stored in uppercase X, you will get an error (Error: object 'X' not found).",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Navigating the RStudio Interface</span>"
    ]
  },
  {
    "objectID": "chapters/navigating_rstudio/navigating_rstudio.html#the-files-pane",
    "href": "chapters/navigating_rstudio/navigating_rstudio.html#the-files-pane",
    "title": "3  Navigating the RStudio Interface",
    "section": "3.3 The files pane",
    "text": "3.3 The files pane\nNext, let’s talk about the Files/Plots/Packages/Help/Viewer pane (that’s a mouthful). Figure 3.7\n\n\n\n\n\n\n\n\nFigure 3.7: The Files/Plots/Packages/Help/Viewer pane.\n\n\n\n\n\nAgain, some of these tabs are more applicable for us than others. For us, the files tab and the help tab will probably be the most useful. You can think of the files tab as a mini Finder window (for Mac) or a mini File Explorer window (for PC). The help tab is also extremely useful once you get acclimated to it.\n\n\n\n\n\n\n\n\nFigure 3.8: The help tab.\n\n\n\n\n\nFor example, in the screenshot above Figure 3.8 we typed the seq into the search bar. The help pane then shows us a page of documentation for the seq() function. The documentation includes a brief description of what the function does, outlines all the arguments the seq() function recognizes, and, if you scroll down, gives examples of using the seq() function. Admittedly, this help documentation can seem a little like reading Greek (assuming you don’t speak Greek) at first. But, you will get more comfortable using it with practice. We hated the help documentation when we were learning R. Now, we use it all the time.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Navigating the RStudio Interface</span>"
    ]
  },
  {
    "objectID": "chapters/navigating_rstudio/navigating_rstudio.html#the-source-pane",
    "href": "chapters/navigating_rstudio/navigating_rstudio.html#the-source-pane",
    "title": "3  Navigating the RStudio Interface",
    "section": "3.4 The source pane",
    "text": "3.4 The source pane\nThere is actually a fourth pane available in RStudio. If you click on the icon shown below you will get the following dropdown box with a list of files you can create. Figure 3.9\n\n\n\n\n\n\n\n\nFigure 3.9: Click the new source file icon.\n\n\n\n\n\nIf you click any of these options, a new pane will appear. We will arbitrarily pick the first option – R Script.\n\n\n\n\n\n\n\n\nFigure 3.10: New source file options.\n\n\n\n\n\nWhen we do, a new pane appears. It’s called the source pane. In this case, the source pane contains an untitled R Script. We won’t get into the details now because we don’t want to overwhelm you, but soon you will do the majority of your R programming in the source pane.\n\n\n\n\n\n\n\n\nFigure 3.11: A blank R script in the source pane.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Navigating the RStudio Interface</span>"
    ]
  },
  {
    "objectID": "chapters/navigating_rstudio/navigating_rstudio.html#rstudio-preferences",
    "href": "chapters/navigating_rstudio/navigating_rstudio.html#rstudio-preferences",
    "title": "3  Navigating the RStudio Interface",
    "section": "3.5 RStudio preferences",
    "text": "3.5 RStudio preferences\nFinally, We’re going to recommend that you change a few settings in RStudio before we move on. Start by clicking Tools, and then Global Options in RStudio’s menu bar, which probably runs horizontally across the top of your computer’s screen.\n\n\n\n\n\n\n\n\nFigure 3.12: Select the preferences menu on Mac.\n\n\n\n\n\nIn the General tab, we recommend turning off the Restore .Rdata into workspace at startup option. We also recommend setting the Save workspace .Rdata on exit dropdown to Never. Finally, we recommend turning off the Always save history (even when not saving .Rdata) option.\n\n\n\n\n\n\n\n\nFigure 3.13: General options tab.\n\n\n\n\n\nWe change our editor theme to Twilight in the Appearance tab. We aren’t necessarily recommending that you change your theme – this is entirely personal preference – we’re just letting you know why our screenshots will look different from here on out.\n\n\n\n\n\n\n\n\nFigure 3.14: Appearance tab.\n\n\n\n\n\nIt’s likely that you still have lots of questions at this point. That’s totally natural. However, we hope you now feel like you have some idea of what you are looking at when you open RStudio. Most of you will naturally get more comfortable with RStudio as we move through the book. For those of you who want more resources now, here are some suggestions.\n\nRStudio IDE cheatsheet\nModernDive: What are R and RStudio?",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Navigating the RStudio Interface</span>"
    ]
  },
  {
    "objectID": "chapters/speaking_r/speaking_r.html",
    "href": "chapters/speaking_r/speaking_r.html",
    "title": "4  Speaking R’s Language",
    "section": "",
    "text": "4.1 R is a language\nIn the same way that many people use the English language to communicate with each other, we will use the R programming language to communicate with R. Just like the English language, the R language comes complete with its own structure and vocabulary. Unfortunately, just like the English language, it also includes some weird exceptions and occasional miscommunications. We’ve already seen a couple examples of commands written to R in the R programming language. Specifically:\n# Store the value 2 in the variable x\nx &lt;- 2\n# Print the contents of x to the screen\nx\n\n[1] 2\nand\n# Print an example number sequence to the screen\nseq(from = 2, to = 100, by = 2)\n\n [1]   2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36  38\n[20]  40  42  44  46  48  50  52  54  56  58  60  62  64  66  68  70  72  74  76\n[39]  78  80  82  84  86  88  90  92  94  96  98 100",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Speaking R’s Language</span>"
    ]
  },
  {
    "objectID": "chapters/speaking_r/speaking_r.html#r-is-a-language",
    "href": "chapters/speaking_r/speaking_r.html#r-is-a-language",
    "title": "4  Speaking R’s Language",
    "section": "",
    "text": "Note\n\n\n\n🗒Side Note: The gray boxes you see above are called R code chunks and we created them (and this entire book) using something called Quarto files. Can you believe that you can write an entire book with R and RStudio? How cool is that? You will learn to use Quarto files later in this book. Quarto is great because it allows you to mix R code with narrative text and multimedia content as we’ve done throughout the page you’re currently looking at. This makes it really easy for us to add context and aesthetic appeal to our results.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Speaking R’s Language</span>"
    ]
  },
  {
    "objectID": "chapters/speaking_r/speaking_r.html#the-r-interpreter",
    "href": "chapters/speaking_r/speaking_r.html#the-r-interpreter",
    "title": "4  Speaking R’s Language",
    "section": "4.2 The R interpreter",
    "text": "4.2 The R interpreter\nQuestion: We keep talking about “speaking” to R, but when you speak to R using the R language, who are you actually speaking to?\nWell, you are speaking to something called the R interpreter. The R interpreter takes the commands we’ve written in the R language, sends them to our computer to do the actual work (e.g., get the mean of a set of numbers), and then translates the results of that work back to us in a form that we humans can understand (e.g., the mean is 25.5). At this stage, one of the key concepts for you to understand about the R language is that is extremely literal! Understanding the literal nature of R is important because it will be the underlying cause of a lot of errors in our R code.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Speaking R’s Language</span>"
    ]
  },
  {
    "objectID": "chapters/speaking_r/speaking_r.html#errors",
    "href": "chapters/speaking_r/speaking_r.html#errors",
    "title": "4  Speaking R’s Language",
    "section": "4.3 Errors",
    "text": "4.3 Errors\nNo matter what we write next, you are going to get errors in your R code. We still get errors in our R code every single time we write R code. However, our hope is that this section will help you begin to understand why you are getting errors when you get them and provide us with a common language for discussing errors.\nSo, what exactly do we mean when we say that the R interpreter is extremely literal? Well, in the Navigating RStudio chapter, we already told you that R is a case sensitive language. Again, that means that uppercase x (X) and lowercase x (x) are different things to R. So, if you assign 2 to lowercase x (x &lt;- 2). And then later ask R to tell what number you stored in upper case X; you will get an error (Error: object 'X' not found).\n\nx &lt;- 2\nX\n\nError in eval(expr, envir, enclos): object 'X' not found\n\n\nSpecifically, this is an example of a logic error. Meaning, R understands what you are asking it to do – you want it to print the contents of the uppercase X object to the screen. However, it can’t complete your request because you are asking it to do something that doesn’t logically make sense – print the contents of a thing that doesn’t exist. Remember, R is literal and it will not try to guess that you actually meant to ask it to print the contents of lowercase x.\nAnother general type of error is known as a syntax error. In programming languages, syntax refers to the rules of the language. You can sort of think of this as the grammar of the language. In English, we could say something like, “giving dog water drink.” This sentence is grammatically completely incorrect; however, most of you would roughly be able to figure out what we’re asking you to do based on your life experience and knowledge of the situational context. The R interpreter, as awesome as it is, would not be able to make an assumption about what we want it to do. In this case, the R interpreter would say, “I don’t know what you’re asking me to do.” When the R interpreter says, “I don’t know what you’re asking me to do,” we’ve made a syntax error.\nThroughout the rest of the book, we will try to point out situations where R programmers often encounter errors and how you may be able to address them. The remainder of this chapter will discuss some key components of R’s syntax and the data structures (i.e., ways of storing data) that the R syntax interacts with.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Speaking R’s Language</span>"
    ]
  },
  {
    "objectID": "chapters/speaking_r/speaking_r.html#functions",
    "href": "chapters/speaking_r/speaking_r.html#functions",
    "title": "4  Speaking R’s Language",
    "section": "4.4 Functions",
    "text": "4.4 Functions\nR is a functional programming language, which simply means that functions play a central role in the R language. But what are functions? Well, factories are a common analogy used to represent functions. In this analogy, arguments are raw material inputs that go into the factory. For example, steel and rubber. The function is the factory where all the work takes place – converting raw materials into the desired output. Finally, the factory output represents the returned results. In this case, bicycles.\n\n\n\n\n\nA factory making bicycles.\n\n\n\n\nTo make this concept more concrete, in the Navigating RStudio chapter we used the seq() function as a factory. Specifically, we wrote seq(from = 2, to = 100, by = 2). The inputs (arguments) were from, to, and by. The output (returned result) was a set of numbers that went from 2 to 100 by 2’s. Most functions, like the seq() function, will be a word or word part followed by parentheses. Other examples are the sum() function for addition and the mean() function to calculate the average value of a set of numbers.\n\n\n\n\n\nA function factory making numbers.\n\n\n\n\n\n4.4.1 Passing values to function arguments\nWhen we supply a value to a function argument, that is called “passing” a value to the argument. Let’s take another look at the sequence function we previously wrote and use it to help us with this discussion.\n\n# Create a sequence of numbers beginning at 2 and ending at 100, incremented by 2.\nseq(from = 2, to = 100, by = 2)\n\n [1]   2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36  38\n[20]  40  42  44  46  48  50  52  54  56  58  60  62  64  66  68  70  72  74  76\n[39]  78  80  82  84  86  88  90  92  94  96  98 100\n\n\nIn the code above, we passed the value 2 to the from argument, we passed the value 100 to the to argument, and we passed the value 2 to the by argument. How do we know we passed the value 2 to the from argument? We know because we wrote from = 2. To R, this means “pass the value 2 to the from argument,” and it is an example of passing a value by name. Alternatively, we could have also gotten the same result if we had passed the same values to the seq() function by position. What does that mean? We’ll explain, but first take a look at the following R code.\n\n# Create a sequence of numbers beginning at 2 and ending at 100, incremented by 2.\nseq(2, 100, 2)\n\n [1]   2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36  38\n[20]  40  42  44  46  48  50  52  54  56  58  60  62  64  66  68  70  72  74  76\n[39]  78  80  82  84  86  88  90  92  94  96  98 100\n\n\nHow is code different from the code chunk before it? You got it! We didn’t explicitly write the names of the function arguments inside of the seq() function. So, how did we get the same results? We got the same results because R allows us to pass values to function arguments by name or by position. When we pass values to a function by position, R will pass the first input value to the first function argument, the second input value to the second function argument, the third input value to the third function argument, and so on.\nBut how do we know what the first, second, and third arguments to a function are? Do you remember our discussion about RStudio’s [help tab][The files pane] in the previous chapter? There, we saw the documentation for the seq() function.\n\n\n\n\n\nThe help tab.\n\n\n\n\nIn the “Usage” section of the documentation for the seq() function, we can see that all of the arguments that the seq() function accepts. These documentation files are a little cryptic until you get used to them but look directly underneath the part that says “## Default S3 method.” There, it tells us that the seq() function understands the from, to, by, length.out, along.with, and ... arguments. The from argument is first argument to the seq() function because it is listed there first, the to argument is second argument to the seq() function because it is listed there second, and so on. It is really that simple. Therefore, when we type seq(2, 100, 2), R automatically translates it to seq(from = 2, to = 100, by = 2). And this is called passing values to function arguments by position.\n\n\n\n\n\n\nNote\n\n\n\n🗒Side Note: As an aside, we can view the documentation for any function by typing ?function name into the R console and then pressing the enter/return key. For example, we can type ?seq to view the documentation for the seq() function.\n\n\nPassing values to our functions by position has the benefit of making our code more compact, we don’t have to write out all the function names. But, as you might have already guessed, passing values to our functions by position also has some potential risks. First, it makes our code harder to read. If we give our code to someone who has never used the seq() function before, they will have to guess (or look up) what purpose 2, 100, and 2 serve. When we pass the values to the function by name, their purpose is typically easier to figure out even if we’ve never used a particular function before. The second, and potentially more important, risk is that we may accidentally pass a value to a different argument than the one we intended. For example, what if we mistakenly think the order of the arguments to the seq() function is from. by, to? In that case, we might write the following code:\n\n# Create a sequence of numbers beginning at 2 and ending at 100, incremented by 2.\nseq(2, 2, 100)\n\n[1] 2\n\n\nNotice that R still gives us a result, but it isn’t the result we want! What happened? Well, we passed the values 2, 2, and 100 to the seq() function by position, which R translated to seq(from = 2, to = 2, by = 100) because from is the first argument in the seq() function, to is the second argument in the seq() function, and by is the third argument in the seq() function.\nQuick review: is this an example of a syntax error or a logic error?\nThis is a logic error. We used perfectly valid R syntax in the code above, but we mistakenly asked R to do something different than we actually wanted it to do. In this simple example, it’s easy to see that this result is very different than what we were expecting and try to figure out what we did wrong. But that won’t always be the case. Therefore, we need to be really careful when passing values to function arguments by position.\nOne final note on passing values to functions. When we pass values to R functions by name, we can pass them in any order we want. For example:\n\n# Create a sequence of numbers beginning at 2 and ending at 100, incremented by 2.\nseq(from = 2, to = 100, by = 2)\n\n [1]   2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36  38\n[20]  40  42  44  46  48  50  52  54  56  58  60  62  64  66  68  70  72  74  76\n[39]  78  80  82  84  86  88  90  92  94  96  98 100\n\n\nand\n\n# Create a sequence of numbers beginning at 2 and ending at 100, incremented by 2.\nseq(to = 100, by = 2, from = 2)\n\n [1]   2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34  36  38\n[20]  40  42  44  46  48  50  52  54  56  58  60  62  64  66  68  70  72  74  76\n[39]  78  80  82  84  86  88  90  92  94  96  98 100\n\n\nreturn the exact same values. Why? Because we explicitly told R which argument to pass each value to by name. Of course, just because we can do something doesn’t mean we should do it. We really shouldn’t rearrange argument order like this unless there is a good reason.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Speaking R’s Language</span>"
    ]
  },
  {
    "objectID": "chapters/speaking_r/speaking_r.html#objects",
    "href": "chapters/speaking_r/speaking_r.html#objects",
    "title": "4  Speaking R’s Language",
    "section": "4.5 Objects",
    "text": "4.5 Objects\nIn addition to functions, the R programming language also includes objects. In the Navigating RStudio chapter we created an object called x with a value of 2 using the x &lt;- 2 R code. In general, you can think of objects as anything that lives in your R global environment. Objects may be single variables (also called vectors in R) or entire data sets (also called data frames in R).\nObjects can be a confusing concept at first. We think it’s because it is hard to precisely define exactly what an object is. We’ll say two things about this. First, you’re probably overthinking it (because we’ve overthought it too). When we use R, we create and save stuff. We have to call that stuff something in order to talk about it or write books about it. Somebody decided we would call that stuff “objects.” The second thing we’ll say is that this becomes much less abstract when we finally get to a place where you can really get your hands dirty doing some R programming.\n\n\n\n\n\nCreating the x object.\n\n\n\n\nSometimes it can be useful to relate the R language to English grammar. That is, when you are writing R code you can roughly think of functions as verbs and objects as nouns. Just like nouns are things in the English language, and verbs do things in the English language, objects are things and functions do things in the R language.\nSo, in the x &lt;- 2 command x is the object and &lt;- is the function. “Wait! Didn’t you just tell us that functions will be a word followed by parentheses?” Fair question. Technically, we said, “Most functions will be a word, or word part, followed by parentheses.” Just like English, R has exceptions. All operators in R are also functions. Operators are symbols like +, -, =, and &lt;-. There are many more operators, but you will notice that they all do things. In this case, they add, subtract, and assign values to objects.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Speaking R’s Language</span>"
    ]
  },
  {
    "objectID": "chapters/speaking_r/speaking_r.html#comments",
    "href": "chapters/speaking_r/speaking_r.html#comments",
    "title": "4  Speaking R’s Language",
    "section": "4.6 Comments",
    "text": "4.6 Comments\nAnd finally, there are comments. If our R code is a conversation we are having with the R interpreter, then comments are your inner thoughts taking place during the conversation. Comments don’t actually mean anything to R, but they will be extremely important for you. You actually already saw a couple examples of comments above.\n\n# Store the value 2 in the variable x\nx &lt;- 2\n# Print the contents of x to the screen\nx\n\n[1] 2\n\n\nIn this code chunk, “# Store the value 2 in the variable x” and “# Print the contents of x to the screen” are both examples of comments. Notice that they both start with the pound or hash sign (#). The R interpreter will ignore anything on the current line that comes after the hash sign. A carriage return (new line) ends the comment. However, comments don’t have to be written on their own line. They can also be written on the same line as R code as long as put them after the R code, like this:\n\nx &lt;- 2 # Store the value 2 in the variable x\nx      # Print the contents of x to the screen\n\n[1] 2\n\n\nMost beginning R programmers underestimate the importance of comments. In the silly little examples above, the comments are not that useful. However, comments will become extremely important as you begin writing more complex programs. When working on projects, you will often need to share your programs with others. Reading R code without any context is really challenging – even for experienced R programmers. Additionally, even if your collaborators can surmise what your R code is doing, they may have no idea why you are doing it. Therefore, your comments should tell others what your code does (if it isn’t completely obvious), and more importantly, what your code is trying to accomplish. Even if you aren’t sharing your code with others, you may need to come back and revise or reuse your code months or years down the line. You may be shocked at how foreign the code you wrote will seem months or years after you wrote it. Therefore, comments are not just important for others, they are also important for future you!\n\n\n\n\n\n\nNote\n\n\n\n🗒Side Note: RStudio has a handy little keyboard shortcut for creating comments. On a Mac, type shift + command + C. On Windows, Shift + Ctrl + C.\n\n\n\n\n\n\n\n\nNote\n\n\n\n🗒Side Note: Please put a space in between the pound/hash sign and the rest of your text when writing comments. For example, # here is my comment instead of #here is my comment. It just makes the comment easier to read.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Speaking R’s Language</span>"
    ]
  },
  {
    "objectID": "chapters/speaking_r/speaking_r.html#packages",
    "href": "chapters/speaking_r/speaking_r.html#packages",
    "title": "4  Speaking R’s Language",
    "section": "4.7 Packages",
    "text": "4.7 Packages\nIn addition to being a functional programming language, R is also a type of programming language called an open source programming language. For our purposes, this has two big advantages. First, it means that R is FREE! Second, it means that smart people all around the world get to develop new packages for the R language that can do cutting edge and/or very niche things.\nThat second advantage is probably really confusing if this is not a concept you are already familiar with. For example, when you install Microsoft Word on your computer all the code that makes that program work is owned and Maintained by the Microsoft corporation. If you need Word to do something that it doesn’t currently do, your only option is to make a feature request on Microsoft’s website. Microsoft may or may not every get around to fulfilling that request.\nR works a little differently. When you downloaded R from the CRAN website, you actually downloaded something called Base R. Base R is maintained by the R Core Team. However, anybody – even you – can write your own code (called packages) that add new functions to the R syntax. Like all functions, these new functions allow you to do things that you can’t do (or can’t do as easily) with Base R.\nAn analogy that we really like here is used by Ismay and Kim in ModernDive.\n\nA good analogy for R packages is they are like apps you can download onto a mobile phone. So R is like a new mobile phone: while it has a certain amount of features when you use it for the first time, it doesn’t have everything. R packages are like the apps you can download onto your phone from Apple’s App Store or Android’s Google Play.1\n\nSo, when you get a new smart phone it comes with apps for making phone calls, checking email, and sending text messages. But, what if you want to listen to music on Spotify? You may or may not be able to do that through your phone’s web browser, but it’s way more convenient and powerful to download and install the Spotify app.\nIn this course, we will make extensive use of packages developed by people and teams outside of the R Core Team. In particular, we will use a number of related packages that are collectively known as the Tidyverse. One of the most popular packages in the tidyverse collection (and one of the most popular R packages overall) is called the dplyr package for data management.\nIn the same way that you have to download and install Spotify on your mobile phone before you can use it, you have to download and install new R packages on your computer before you can use the functions they contain. Fortunately, R makes this really easy. For most packages, all you have to do is run the install.packages() function in the R console. For example, here is how you would install the dplyr package.\n\n# Make sure you remember to wrap the name of the package in single or double quotes.\ninstall.packages(\"dplyr\")\n\nOver time, you will download and install a lot of different packages. All those packages with all of those new functions start to create a lot of overhead. Therefore, R doesn’t keep them loaded and available for use at all times. Instead, every time you open RStudio, you will have to explicitly tell R which packages you want to use. So, when you close RStudio and open it again, the only functions that you will be able to use are Base R functions. If you want to use functions from any other package (e.g., dplyr) you will have to tell R that you want to do so using the library() function.\n\n# No quotes needed here\nlibrary(dplyr)\n\nTechnically, loading the package with the library() function is not the only way to use a function from a package you’ve downloaded. For example, the dplyr package contains a function called filter() that helps us keep or drop certain rows in a data frame. To use this function, we have to first download the dplyr package. Then we can use the filter function in one of two different ways.\n\nlibrary(dplyr)\nfilter(states_data, state == \"Texas\") # Keeps only the rows from Texas\n\nThe first way you already saw above. Load all the functions contained in the dplyr package using the library() function. Then use that function just like any other Base R function.\nThe second way is something called the double colon syntax. To use the double colon syntax, you type the package name, two colons, and the name of the function you want to use from the package. Here is an example of the double colon syntax.\n\ndplyr::filter(states_data, state == \"Texas\") # Keeps only the rows from Texas\n\nMost of the time you will load packages using the library() function. However, we wanted to show you the double colon syntax because you may come across it when you are reading R documentation and because there are times when it makes sense to use this syntax.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Speaking R’s Language</span>"
    ]
  },
  {
    "objectID": "chapters/speaking_r/speaking_r.html#programming-style",
    "href": "chapters/speaking_r/speaking_r.html#programming-style",
    "title": "4  Speaking R’s Language",
    "section": "4.8 Programming style",
    "text": "4.8 Programming style\nFinally, we want to discuss programming style. R can read any code you write as long as you write it using valid R syntax. However, R code can be much easier or harder for people (including you) to read depending on how it’s written. The coding best practices chapter of this book gives complete details on writing R code that is as easy as possible for people to read. So, please make sure to read it. It will make things so much easier for all of us!\n\n\n\n\n1. Ismay C, Kim AY. Chapter 1 getting started with data in R. Published online November 2019.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Speaking R’s Language</span>"
    ]
  },
  {
    "objectID": "chapters/lets_get_programming/lets_get_programming.html",
    "href": "chapters/lets_get_programming/lets_get_programming.html",
    "title": "5  Let’s Get Programming",
    "section": "",
    "text": "5.1 Simulating data\nData simulation can be really complicated, but it doesn’t have to be. It is simply the process of creating data as opposed to finding data in the wild. This can be really useful in several different ways.\nSo, let’s go ahead and write a complete R program to simulate and analyze some data. As we said, it doesn’t have to be complicated. In fact, in just a few lines of R code below we simulate and analyze some data about a hypothetical class.\nclass &lt;- data.frame(\n  names   = c(\"John\", \"Sally\", \"Brad\", \"Anne\"),\n  heights = c(68, 63, 71, 72)\n)\nclass\n\n  names heights\n1  John      68\n2 Sally      63\n3  Brad      71\n4  Anne      72\nmean(class$heights)\n\n[1] 68.5\nAs you can see, this data frame contains the students’ names and heights. We also use the mean() function to calculate the average height of the class. By the end of this chapter, you will understand all the elements of this R code and how to simulate your own data.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Let’s Get Programming</span>"
    ]
  },
  {
    "objectID": "chapters/lets_get_programming/lets_get_programming.html#simulating-data",
    "href": "chapters/lets_get_programming/lets_get_programming.html#simulating-data",
    "title": "5  Let’s Get Programming",
    "section": "",
    "text": "Simulating data is really useful for getting help with a problem you are trying to solve. Often, it isn’t feasible for you to send other people the actual data set you are working on when you encounter a problem you need help with. Sometimes, it may not even be legally allowed (i.e., for privacy reasons). Instead of sending them your entire data set, you can simulate a little data set that recreates the challenge you are trying to address without all the other complexity of the full data set. As a bonus,we have often found that we end up figuring out the solution to the problem we’re trying to solve as we recreate the problem in a simulated data set that we intended to share with others.\nSimulated data can also be useful for learning about and testing statistical assumptions. In epidemiology, we use statistics to draw conclusions about populations of people we are interested in based on samples of people drawn from the population. Because we don’t actually have data from all the people in the population, we have to make some assumptions about the population based on what we find in our sample. When we simulate data, we know the truth about our population because we created our population to have that truth. We can then use this simulated population to play “what if” games with our analysis. What if we only sampled half as many people? What if their heights aren’t actually normally distributed? What if we used a probit model instead of a logit model? Going through this process and answering these questions can help us understand how much, and under what circumstances, we can trust the answers we found in the real world.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Let’s Get Programming</span>"
    ]
  },
  {
    "objectID": "chapters/lets_get_programming/lets_get_programming.html#vectors",
    "href": "chapters/lets_get_programming/lets_get_programming.html#vectors",
    "title": "5  Let’s Get Programming",
    "section": "5.2 Vectors",
    "text": "5.2 Vectors\nVectors are the most fundamental data structure in R. Here, data structure means “container for our data.” There are other data structures as well; however, they are all built from vectors. That’s why we say vectors are the most fundamental data structure. Some of these other structures include matrices, lists, and data frames. In this book, we won’t use matrices or lists much at all, so you can forget about them for now. Instead, we will almost exclusively use data frames to hold and manipulate our data. However, because data frames are built from vectors, it can be useful to start by learning a little bit about them. Let’s create our first vector now.\n\n# Create an example vector\nnames &lt;- c(\"John\", \"Sally\", \"Brad\", \"Anne\")\n# Print contents to the screen\nnames\n\n[1] \"John\"  \"Sally\" \"Brad\"  \"Anne\" \n\n\n👆Here’s what we did above:\n\nWe created a vector of names with the c() (short for combine) function.\n\nThe vector contains four values: “John”, “Sally”, “Brad”, and “Anne”.\nAll of the values are character strings (i.e., words). We know this because all of the values are wrapped with quotation marks.\nHere we used double quotes above, but we could have also used single quotes. We cannot, however, mix double and single quotes for each character string. For example, c(\"John', ...) won’t work.\n\nWe assigned that vector of character strings to the word names using the &lt;- function.\n\nR now recognizes names as an object that we can do things with.\nR programmers may refer to the names object as “the names object”, “the names vector”, or “the names variable”. For our purposes, these all mean the same thing.\n\nWe printed the contents of the names object to the screen by typing the word “names”.\n\nR returns (shows us) the four character values (“John” “Sally” “Brad” “Anne”) on the computer screen.\n\n\nTry copying and pasting the code above into the RStudio console on your computer. You should notice the names vector appear in your global environment. You may also notice that the global environment pane gives you some additional information about this vector to the right of its name. Specifically, you should see chr [1:4] \"John\"  \"Sally\" \"Brad\"  \"Anne\". This is R telling us that names is a character vector (chr), with four values ([1:4]), and the first four values are \"John\"  \"Sally\" \"Brad\"  \"Anne\".\n\n\n5.2.1 Vector types\nThere are several different vector types, but each vector can have only one type. The type of the vector above was character. We can validate that with the typeof() function like so:\n\ntypeof(names)\n\n[1] \"character\"\n\n\nThe other vector types that we will use in this book are double, integer, and logical. Double vectors hold real numbers and integer vectors hold integers. Collectively, double vectors and integer vectors are known as numeric vectors. Logical vectors can only hold the values TRUE and FALSE. Here are some examples of each:\n\n\n5.2.2 Double vectors\n\n# A numeric vector\nmy_numbers &lt;- c(12.5, 13.98765, pi)\nmy_numbers\n\n[1] 12.500000 13.987650  3.141593\n\n\n\ntypeof(my_numbers)\n\n[1] \"double\"\n\n\n\n\n5.2.3 Integer vectors\nCreating integer vectors involves a weird little quirk of the R language. For some reason, and we have no idea why, we must type an “L” behind the number to make it an integer.\n\n# An integer vector - first attempt\nmy_ints_1 &lt;- c(1, 2, 3)\nmy_ints_1\n\n[1] 1 2 3\n\n\n\ntypeof(my_ints_1)\n\n[1] \"double\"\n\n\n\n# An integer vector - second attempt\n# Must put \"L\" behind the number to make it an integer. No idea why they chose \"L\".\nmy_ints_2 &lt;- c(1L, 2L, 3L)\nmy_ints_2\n\n[1] 1 2 3\n\n\n\ntypeof(my_ints_2)\n\n[1] \"integer\"\n\n\n\n\n5.2.4 Logical vectors\n\n# A logical vector\n# Type TRUE and FALSE in all caps\nmy_logical &lt;- c(TRUE, FALSE, TRUE)\nmy_logical\n\n[1]  TRUE FALSE  TRUE\n\n\n\ntypeof(my_logical)\n\n[1] \"logical\"\n\n\nRather than have an abstract discussion about the particulars of each of these vector types right now, we think it’s best to wait and learn more about them when they naturally arise in the context of a real challenge we are trying to solve with data. At this point, just having some vague idea that they exist is good enough.\n\n\n5.2.5 Factor vectors\nAbove, we said that we would only work with three vector types in this book: double, integer, and logical. Technically, that is true. Factors aren’t technically a vector type (we will explain below) but calling them a vector type is close enough to true for our purposes. We will briefly introduce you to factors here, and then discuss them in more depth later in the chapter on [Numerical Descriptions of Categorical Variables]. We cover them in greater depth there because factors are most useful in the context of working with categorical data – data that is grouped into discrete categories. Some examples of categorical variables commonly seen in public health data are sex, race or ethnicity, and level of educational attainment.\nIn R, we can represent a categorical variable in multiple different ways. For example, let’s say that we are interested in recording people’s highest level of formal education completed in our data. The discrete categories we are interested in are:\n\n1 = Less than high school\n2 = High school graduate\n3 = Some college\n4 = College graduate\n\nWe could then create a numeric vector to record the level of educational attainment for four hypothetical people as shown below.\n\n# A numeric vector of education categories\neducation_num &lt;- c(3, 1, 4, 1)\neducation_num\n\n[1] 3 1 4 1\n\n\nBut what is less-than-ideal about storing our categorical data this way? Well, it isn’t obvious what the numbers in education_num mean. For the purposes of this example, we defined them above, but if we didn’t have that information then we would likely have no idea what categories the numbers represent.\nWe could also create a character vector to record the level of educational attainment for four hypothetical people as shown below.\n\n# A character vector of education categories\neducation_chr &lt;- c(\n  \"Some college\", \"Less than high school\", \"College graduate\", \n  \"Less than high school\"\n)\neducation_chr\n\n[1] \"Some college\"          \"Less than high school\" \"College graduate\"     \n[4] \"Less than high school\"\n\n\nBut this strategy also has a few limitations that we will discuss in in the chapter on [Numerical Descriptions of Categorical Variables]. For now, we just need to quickly learn how to create and identify factor vectors.\nTypically, we don’t create factors from scratch. Instead, we typically convert (or “coerce”) an existing numeric or character vector into a factor. For example, we can coerce education_num to a factor like this:\n\n# Coerce education_num to a factor\neducation_num_f &lt;- factor(\n  x      = education_num,\n  levels = 1:4,\n  labels = c(\n    \"Less than high school\", \"High school graduate\", \"Some college\", \n    \"College graduate\"\n  )\n)\neducation_num_f\n\n[1] Some college          Less than high school College graduate     \n[4] Less than high school\n4 Levels: Less than high school High school graduate ... College graduate\n\n\n👆 Here’s what we did above:\n\nWe used the factor() function to create a new factor version of education_num.\n\nYou can type ?factor into your R console to view the help documentation for this function and follow along with the explanation below.\nThe first argument to the factor() function is the x argument. The value passed to the x argument should be a vector of data. We passed the education_num vector to the x argument.\nThe second argument to the factor() function is the levels argument. This argument tells R the unique values that the new factor variable can take. We used the shorthand 1:4 to tell R that education_num_f can take the unique values 1, 2, 3, or 4.\nThe third argument to the factor() function is the labels argument. The value passed to the labels argument should be a character vector of labels (i.e., descriptive text) for each value in the levels argument. The order of the labels in the character vector we pass to the labels argument should match the order of the values passed to the levels argument. For example, the ordering of levels and labels above tells R that 1 should be labeled with “Less than high school”, 2 should be labeled with “High school graduate”, etc.\n\nWe used the assignment operator (&lt;-) to save our new factor vector in our global environment as education_num_f.\n\nIf we had used the name education_num instead, then the previous values in the education_num vector would have been replaced with the new values. That is sometimes what we want to happen. However, when it comes to creating factors, we typically keep the numeric version of the vector and create an additional factor version of the vector. We just often find that it can be useful to have both versions of the variable hanging around during the analysis process.\nWe also use the _f naming convention in our code. That means that when we create a new factor vector, we name it the same thing the original vector was named with the addition of _f (for factor) at the end.\n\nWe printed the vector to the screen. The values in education_num_f look similar to the character strings displayed in education_chr. Notice, however, that the values no longer have quotes around them and R displays Levels: Less than high school High school graduate Some college College graduate below the data values. This is R telling us the possible categorical values that this factor could take on. This is a telltale sign that the vector being printed to the screen is a factor.\n\nInterestingly, although R uses labels to make factors look like character vectors, they are still integer vectors under the hood. For example:\n\ntypeof(education_num_f)\n\n[1] \"integer\"\n\n\nAnd we can still view them as such.\n\nas.numeric(education_num_f)\n\n[1] 3 1 4 1\n\n\nIt is also possible to coerce character vectors to factors. For example, we can coerce education_chr to a factor like so:\n\n# Coerce education_chr to a factor\neducation_chr_f &lt;- factor(\n  x      = education_chr,\n  levels = c(\n    \"Less than high school\", \"High school graduate\", \"Some college\", \n    \"College graduate\"\n  )\n)\neducation_chr_f\n\n[1] Some college          Less than high school College graduate     \n[4] Less than high school\n4 Levels: Less than high school High school graduate ... College graduate\n\n\n👆 Here’s what we did above:\n\nWe coerced a character vector (education_chr) to a factor using the factor() function.\nBecause the levels are character strings, there was no need to pass any values to the labels argument this time. Keep in mind, though, that the order of the values passed to the levels argument matters. It will be the order that the factor levels will be displayed in our analyses.\n\nYou might reasonably wonder why we would want to convert character vectors to factors, but we will save that discussion for the chapter on [Numerical Descriptions of Categorical Variables].",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Let’s Get Programming</span>"
    ]
  },
  {
    "objectID": "chapters/lets_get_programming/lets_get_programming.html#data-frames",
    "href": "chapters/lets_get_programming/lets_get_programming.html#data-frames",
    "title": "5  Let’s Get Programming",
    "section": "5.3 Data frames",
    "text": "5.3 Data frames\nVectors are useful for storing a single characteristic where all the data is of the same type. However, in epidemiology, we typically want to store information about many different characteristics of whatever we happen to be studying. For example, we didn’t just want the names of the people in our class, we also wanted the heights. Of course, we can also store the heights in a vector like so:\n\nheights &lt;- c(68, 63, 71, 72)\nheights\n\n[1] 68 63 71 72\n\n\nBut this vector, in and of itself, doesn’t tell us which height goes with which person. When we want to create relationships between our vectors, we can use them to build a data frame. For example:\n\n# Create a vector of names\nnames &lt;- c(\"John\", \"Sally\", \"Brad\", \"Anne\")\n# Create a vector of heights\nheights &lt;- c(68, 63, 71, 72)\n# Combine them into a data frame\nclass &lt;- data.frame(names, heights)\n# Print the data frame to the screen\nclass\n\n  names heights\n1  John      68\n2 Sally      63\n3  Brad      71\n4  Anne      72\n\n\n👆Here’s what we did above:\n\nWe created a data frame with the data.frame() function.\n\nThe first argument we passed to the data.frame() function was a vector of names that we previously created.\nThe second argument we passed to the data.frame() function was a vector of heights that we previously created.\n\nWe assigned that data frame to the word class using the &lt;- function.\n\nR now recognizes class as an object that we can do things with.\nR programmers may refer to this class object as “the class object” or “the class data frame”. For our purposes, these all mean the same thing. We could also call it a data set, but that term isn’t used much in R circles.\n\nWe printed the contents of the class object to the screen by typing the word “class”.\n\nR returns (shows us) the data frame on the computer screen.\n\n\nTry copying and pasting the code above into the RStudio console on your computer. You should notice the class data frame appear in your global environment. You may also notice that the global environment pane gives you some additional information about this data frame to the right of its name. Specifically, you should see 4 obs. of 2 variables. This is R telling us that class has four rows or observations (4 obs.) and two columns or variables (2 variables). If you click the little blue arrow to the left of the data frame’s name, you will see information about the individual vectors that make up the data frame.\nAs a shortcut, instead of creating individual vectors and then combining them into a data frame as we’ve done above, most R programmers will create the vectors (columns) directly inside of the data frame function like this:\n\n# Create the class data frame\nclass &lt;- data.frame(\n  names   = c(\"John\", \"Sally\", \"Brad\", \"Anne\"),\n  heights = c(68, 63, 71, 72)\n) # Closing parenthesis down here.\n\n# Print the data frame to the screen\nclass\n\n  names heights\n1  John      68\n2 Sally      63\n3  Brad      71\n4  Anne      72\n\n\nAs you can see, both methods produce the exact same result. The second method, however, requires a little less typing and results in fewer objects cluttering up your global environment. What we mean by that is that the names and heights vectors won’t exist independently in your global environment. Rather, they will only exist as columns of the class data frame.\nYou may have also noticed that when we created the names and heights vectors (columns) directly inside of the data.frame() function we used the equal sign (=) to assign values instead of the assignment arrow (&lt;-). This is just one of those quirky R exceptions we talked about in the chapter on speaking R’s language. In fact, = and &lt;- can be used interchangeably in R. It is only by convention that we usually use &lt;- for assigning values, but use = for assigning values to columns in data frames. we don’t know why this is the convention. If it were up to me, we wouldn’t do this. We would just pick = or &lt;- and use it in all cases where we want to assign values. But, it isn’t up to me and we gave up on trying to fight it a long time ago. Your R programming life will be easier if you just learn to assign values this way – even if it’s dumb. 🤷\n\n\n\n\n\n\nWarning\n\n\n\nBy definition, all columns in a data frame must have the same length (i.e., number of rows). That means that each vector you create when building your data frame must have the same number of values in it. For example, the class data frame above has four names and four heights. If we had only entered three heights, we would have gotten the following error: Error in data.frame(names = c(\"John\", \"Sally\", \"Brad\", \"Anne\"), heights = c(68,  : arguments imply differing number of rows: 4, 3",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Let’s Get Programming</span>"
    ]
  },
  {
    "objectID": "chapters/lets_get_programming/lets_get_programming.html#tibbles",
    "href": "chapters/lets_get_programming/lets_get_programming.html#tibbles",
    "title": "5  Let’s Get Programming",
    "section": "5.4 Tibbles",
    "text": "5.4 Tibbles\nTibbles are a data structure that come from another tidyverse package – the tibble package. Tibbles are data frames and serve the same purpose in R that data frames serve; however, they are enhanced in several ways. 💪 You are welcome to look over the tibble documentation or the tibbles chapter in R for Data Science if you are interested in learning about all the differences between tibbles and data frames. For our purposes, there are really only a couple things we want you to know about tibbles right now.\nFirst, tibbles are a part of the tibble package – NOT base R. Therefore, we have to install and load either the tibble package or the dplyr package (which loads the tibble package for us behind the scenes) before we can create tibbles. we typically just load the dplyr package.\n\n# Install the dplyr package. YOU ONLY NEED TO DO THIS ONE TIME.\ninstall.packages(\"dplyr\")\n\n\n# Load the dplyr package. YOU NEED TO DO THIS EVERY TIME YOU START A NEW R SESSION.\nlibrary(dplyr)\n\nSecond, we can create tibbles using one of three functions: as_tibble(), tibble(), or tribble(). I’ll show you some examples shortly.\nThird, try not to be confused by the terminology. Remember, tibbles are data frames. They are just enhanced data frames.\n\n5.4.1 The as_tibble function\nWe use the as_tibble() function to turn an already existing basic data frame into a tibble. For example:\n\n# Create a data frame\nmy_df &lt;- data.frame(\n  name = c(\"john\", \"alexis\", \"Steph\", \"Quiera\"),\n  age  = c(24, 44, 26, 25)\n)\n\n# Print my_df to the screen\nmy_df\n\n    name age\n1   john  24\n2 alexis  44\n3  Steph  26\n4 Quiera  25\n\n\n\n# View the class of my_df\nclass(my_df)\n\n[1] \"data.frame\"\n\n\n👆Here’s what we did above:\n\nWe used the data.frame() function to create a new data frame called my_df.\nWe used the class() function to view my_df’s class (i.e., what kind of object it is).\n\nThe result returned by the class() function tells us that my_df is a data frame.\n\n\n\n# Use as_tibble() to turn my_df into a tibble\nmy_df &lt;- as_tibble(my_df)\n\n# Print my_df to the screen\nmy_df\n\n# A tibble: 4 × 2\n  name     age\n  &lt;chr&gt;  &lt;dbl&gt;\n1 john      24\n2 alexis    44\n3 Steph     26\n4 Quiera    25\n\n\n\n# View the class of my_df\nclass(my_df)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n👆Here’s what we did above:\n\nWe used the as_tibble() function to turn my_df into a tibble.\nWe used the class() function to view my_df’s class (i.e., what kind of object it is).\n\nThe result returned by the class() function tells us that my_df is still a data frame, but it is also a tibble. That’s what “tbl_df” and “tbl” mean.\n\n\n\n\n5.4.2 The tibble function\nWe can use the tibble() function in place of the data.frame() function when we want to create a tibble from scratch. For example:\n\n# Create a data frame\nmy_df &lt;- tibble(\n  name = c(\"john\", \"alexis\", \"Steph\", \"Quiera\"),\n  age  = c(24, 44, 26, 25)\n)\n\n# Print my_df to the screen\nmy_df\n\n# A tibble: 4 × 2\n  name     age\n  &lt;chr&gt;  &lt;dbl&gt;\n1 john      24\n2 alexis    44\n3 Steph     26\n4 Quiera    25\n\n\n\n# View the class of my_df\nclass(my_df)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n👆Here’s what we did above:\n\nWe used the tibble() function to create a new tibble called my_df.\nWe used the class() function to view my_df’s class (i.e., what kind of object it is).\n\nThe result returned by the class() function tells us that my_df is still a data frame, but it is also a tibble. That’s what “tbl_df” and “tbl” mean.\n\n\n\n\n5.4.3 The tribble function\nAlternatively, we can use the tribble() function in place of the data.frame() function when we want to create a tibble from scratch. For example:\n\n# Create a data frame\nmy_df &lt;- tribble(\n  ~name,    ~age,\n  \"john\",   24, \n  \"alexis\", 44, \n  \"Steph\",  26,\n  \"Quiera\", 25\n)\n\n# Print my_df to the screen\nmy_df\n\n# A tibble: 4 × 2\n  name     age\n  &lt;chr&gt;  &lt;dbl&gt;\n1 john      24\n2 alexis    44\n3 Steph     26\n4 Quiera    25\n\n\n\n# View the class of my_df\nclass(my_df)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n👆Here’s what we did above:\n\nWe used the tribble() function to create a new tibble called my_df.\nWe used the class() function to view my_df’s class (i.e., what kind of object it is).\n\nThe result returned by the class() function tells us that my_df is still a data frame, but it is also a tibble. That’s what “tbl_df” and “tbl” mean.\n\nThere is absolutely no difference between the tibble we created above with the tibble() function and the tibble we created above with the tribble() function. The only difference between the two functions is the syntax we used to pass the column names and data values to each function.\n\nWhen we use the tibble() function, we pass the data values to the function horizontally as vectors. This is the same syntax that the data.frame() function expects us to use.\nWhen we use the tribble() function, we pass the data values to the function vertically instead. The only reason this function exists is because it can sometimes be more convenient to type in our data values this way. That’s it.\nRemember to type a tilde (“~”) in front of your column names when using the tribble() function. For example, type ~name instead of name. That’s how R knows you’re giving it a column name instead of a data value.\n\n\n\n\n5.4.4 Why use tibbles\nAt this point, some students wonder, “If tibbles are just data frames, why use them? Why not just use the data.frame() function?” That’s a fair question. As we have said multiple times already, tibbles are enhanced. However, we don’t believe that going into detail about those enhancements is going to be useful to most of you at this point – and may even be confusing. But, we will show you one quick example that’s pretty self-explanatory.\nLet’s say that we are given some data that contains four people’s age in years. We want to create a data frame from that data. However, let’s say that we also want a column in our new data frame that contains those same ages in months. Well, we could do the math ourselves. We could just multiply each age in years by 12 (for the sake of simplicity, assume that everyone’s age in years is gathered on their birthday). But, we’d rather have R do the math for us. We can do so by asking R to multiply each value of the the column called age_years by 12. Take a look:\n\n# Create a data frame using the data.frame() function\nmy_df &lt;- data.frame(\n  name       = c(\"john\", \"alexis\", \"Steph\", \"Quiera\"),\n  age_years  = c(24, 44, 26, 25),\n  age_months = age_years * 12\n)\n\nError in eval(expr, envir, enclos): object 'age_years' not found\n\n\nUh, oh! We got an error! This error says that the column age_years can’t be found. How can that be? We are clearly passing the column name age_years to the data.frame() function in the code chunk above. Unfortunately, the data.frame() function doesn’t allow us to create and refer to a column name in the same function call. So, we would need to break this task up into two steps if we wanted to use the data.frame() function. Here’s one way we could do this:\n\n# Create a data frame using the data.frame() function\nmy_df &lt;- data.frame(\n  name       = c(\"john\", \"alexis\", \"Steph\", \"Quiera\"),\n  age_years  = c(24, 44, 26, 25)\n)\n\n# Add the age in months column to my_df\nmy_df &lt;- my_df %&gt;% mutate(age_months = age_years * 12)\n\n# Print my_df to the screen\nmy_df\n\n    name age_years age_months\n1   john        24        288\n2 alexis        44        528\n3  Steph        26        312\n4 Quiera        25        300\n\n\nAlternatively, we can use the tibble() function to get the result we want in just one step like so:\n\n# Create a data frame using the tibble() function\nmy_df &lt;- tibble(\n  name       = c(\"john\", \"alexis\", \"Steph\", \"Quiera\"),\n  age_years  = c(24, 44, 26, 25),\n  age_months = age_years * 12\n)\n\n# Print my_df to the screen\nmy_df\n\n# A tibble: 4 × 3\n  name   age_years age_months\n  &lt;chr&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 john          24        288\n2 alexis        44        528\n3 Steph         26        312\n4 Quiera        25        300\n\n\nIn summary, tibbles are data frames. For the most part, we will use the terms “tibble” and “data frame” interchangeably for the rest of the book. However, remember that tibbles are enhanced data frames. Therefore, there are some things that we will do with tibbles that we can’t do with basic data frames.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Let’s Get Programming</span>"
    ]
  },
  {
    "objectID": "chapters/lets_get_programming/lets_get_programming.html#missing-data",
    "href": "chapters/lets_get_programming/lets_get_programming.html#missing-data",
    "title": "5  Let’s Get Programming",
    "section": "5.5 Missing data",
    "text": "5.5 Missing data\nAs indicated in the warning box at the end of the data frames section of this chapter, all columns in our data frames have to have the same length. So what do we do when we are truly missing information in some of our observations? For example, how do we create the class data frame if we are missing Anne’s height for some reason?\nIn R, we represent missing data with an NA. For example:\n\n# Create the class data frame\ndata.frame(\n  names   = c(\"John\", \"Sally\", \"Brad\", \"Anne\"),\n  heights = c(68, 63, 71, NA) # Now we are missing Anne's height\n)\n\n  names heights\n1  John      68\n2 Sally      63\n3  Brad      71\n4  Anne      NA\n\n\n\n\n\n\n\n\nWarning\n\n\n\nMake sure you capitalize NA and don’t use any spaces or quotation marks. Also, make sure you use NA instead of writing \"Missing\" or something like that.\n\n\nBy default, R considers NA to be a logical-type value (as opposed to character or numeric). for example:\n\ntypeof(NA)\n\n[1] \"logical\"\n\n\nHowever, you can tell R to make NA a different type by using one of the more specific forms of NA. For example:\n\ntypeof(NA_character_)\n\n[1] \"character\"\n\n\n\ntypeof(NA_integer_)\n\n[1] \"integer\"\n\n\n\ntypeof(NA_real_)\n\n[1] \"double\"\n\n\nMost of the time, you won’t have to worry about doing this because R will take care of converting NA for you. What do we mean by that? Well, remember that every vector can have only one type. So, when you add an NA (logical by default) to a vector with double values as we did above (i.e., c(68, 63, 71, NA)), that would cause you to have three double values and one logical value in the same vector, which is not allowed. Therefore, R will automatically convert the NA to NA_real_ for you behind the scenes.\nThis is a concept known as “type coercion” and you can read more about it here if you are interested. As we said, most of the time you don’t have to worry about type coercion – it will happen automatically. But, sometimes it doesn’t and it will cause R to give you an error. we mostly encounter this when using the if_else() and case_when() functions, which we will discuss later.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Let’s Get Programming</span>"
    ]
  },
  {
    "objectID": "chapters/lets_get_programming/lets_get_programming.html#our-first-analysis",
    "href": "chapters/lets_get_programming/lets_get_programming.html#our-first-analysis",
    "title": "5  Let’s Get Programming",
    "section": "5.6 Our first analysis",
    "text": "5.6 Our first analysis\nCongratulations on your new R programming skills. 🎉 You can now create vectors and data frames. This is no small thing. Basically, everything else we do in this book will start with vectors and data frames.\nHaving said that, just creating data frames may not seem super exciting. So, let’s round out this chapter with a basic descriptive analysis of the data we simulated. Specifically, let’s find the average height of the class.\nYou will find that in R there are almost always many different ways to accomplish a given task. Sometimes, choosing one over another is simply a matter of preference. Other times, one method is clearly more efficient and/or accurate than another. This is a point that will come up over and over in this book. Let’s use our desire to find the mean height of the class as an example.\n\n5.6.1 Manual calculation of the mean\nFor starters, we can add up all the heights and divide by the total number of heights to find the mean.\n\n(68 + 63 + 71 + 72) / 4\n\n[1] 68.5\n\n\n👆Here’s what we did above:\n\nWe used the addition operator (+) to add up all the heights.\nWe used the division operator (/) to divide the sum of all the heights by 4 - the number of individual heights we added together.\nWe used parentheses to enforce the correct order of operations (i.e., make R do addition before division).\n\nThis works, but why might it not be the best approach? Well, for starters, manually typing in the heights is error prone. We can easily accidently press the wrong key. Luckily, we already have the heights stored as a column in the class data frame. We can access or refer to a single column in a data frame using the dollar sign notation.\n\n\n5.6.2 Dollar sign notation\n\nclass$heights\n\n[1] 68 63 71 72\n\n\n👆Here’s what we did above:\n\nWe used the dollar sign notation to access the heights column in the class data frame.\n\nDollar sign notation is just the data frame name, followed by the dollar sign, followed by the column name.\n\n\n\n\n5.6.3 Bracket notation\nFurther, we can use bracket notation to access each value in a vector. we think it’s easier to demonstrate bracket notation than it is to describe it. For example, we could access the third value in the names vector like this:\n\n# Create the heights vector\nheights &lt;- c(68, 63, 71, 72)\n\n# Bracket notation\n# Access the third element in the heights vector with bracket notation\nheights[3]\n\n[1] 71\n\n\nRemember, that data frame columns are also vectors. So, we can combine the dollar sign notation and bracket notation, to access each individual value of the height column in the class data frame. This will help us get around the problem of typing each individual height value. For example:\n\n# First way to calculate the mean\n# (68 + 63 + 71 + 72) / 4\n\n# Second way. Use dollar sign notation and bracket notation so that we don't \n# have to type individual heights\n(class$heights[1] + class$heights[2] + class$heights[3] + class$heights[4]) / 4\n\n[1] 68.5\n\n\n\n\n5.6.4 The sum function\nThe second method is better in the sense that we no longer have to worry about mistyping the heights. However, who wants to type class$heights[...] over and over? What if we had a hundred numbers? What if we had a thousand numbers? This wouldn’t work. Luckily, there is a function that adds all the numbers contained in a numeric vector – the sum() function. Let’s take a look:\n\n# Create the heights vector\nheights &lt;- c(68, 63, 71, 72)\n\n# Add together all the individual heights with the sum function\nsum(heights)\n\n[1] 274\n\n\nRemember, that data frame columns are also vectors. So, we can combine the dollar sign notation and sum() function, to add up all the individual heights in the heights column of the class data frame. It looks like this:\n\n# First way to calculate the mean\n# (68 + 63 + 71 + 72) / 4\n\n# Second way. Use dollar sign notation and bracket notation so that we don't \n# have to type individual heights\n# (class$heights[1] + class$heights[2] + class$heights[3] + class$heights[4]) / 4\n\n# Third way. Use dollar sign notation and sum function so that we don't have \n# to type as much\nsum(class$heights) / 4\n\n[1] 68.5\n\n\n👆Here’s what we did above:\n\nWe passed the numeric vector heights from the class data frame to the sum() function using dollar sign notation.\nThe sum() function returned the total value of all the heights added together.\nWe divided the total value of the heights by four – the number of individual heights.\n\n\n\n5.6.5 Nesting functions\n!! Before we move on, we want to point out something that is actually kind of a big deal. In the third method above, we didn’t manually add up all the individual heights - R did this calculation for us. Further, we didn’t store the sum of the individual heights somewhere and then divide that stored value by 4. Heck, we didn’t even see what the sum of the individual heights were. Instead, the returned value from the sum function (274) was used directly in the next calculation (/ 4) by R without us seeing the result. In other words, (68 + 63 + 71 + 72) / 4, 274 / 4, and sum(class$heights) / 4 are all exactly the same thing to R. However, the third method (sum(class$heights) / 4) is much more scalable (i.e., adding a lot more numbers doesn’t make this any harder to do) and much less error prone. Just to be clear, the BIG DEAL is that we now know that the values returned by functions can be directly passed to other functions in exactly the same way as if we typed the values ourselves.\nThis concept, functions passing values to other functions is known as nesting functions. It’s called nesting functions because we can put functions inside of other functions.\n“But, Brad, there’s only one function in the command sum(class$heights) / 4 – the sum() function.” Really? Is there? Remember when we said that operators are also functions in R? Well, the division operator is a function. And, like all functions it can be written with parentheses like this:\n\n# Writing the division operator as a function with parentheses\n`/`(8, 4)\n\n[1] 2\n\n\n👆Here’s what we did above:\n\nWe wrote the division operator in its more function-looking form.\n\nBecause the division operator isn’t a letter, we had to wrap it in backticks (`).\nThe backtick key is on the top left corner of your keyboard near the escape key (esc).\nThe first argument we passed to the division function was the dividend (The number we want to divide).\nThe second argument we passed to the division function was the divisor (The number we want to divide by).\n\n\nSo, the following two commands mean exactly the same thing to R:\n\n8 / 4\n\n\n`/`(8, 4)\n\nAnd if we use this second form of the division operator, we can clearly see that one function is nested inside another function.\n\n`/`(sum(class$heights), 4)\n\n[1] 68.5\n\n\n👆Here’s what we did above:\n\nWe calculated the mean height of the class.\n\nThe first argument we passed to the division function was the returned value from the sum() function.\nThe second argument we passed to the division function was the divisor (4).\n\n\nThis is kind of mind-blowing stuff the first time you encounter it. 🤯 we wouldn’t blame you if you are feeling overwhelmed or confused. The main points to take away from this section are:\n\nEverything we do in R, we will do with functions. Even operators are functions, and they can be written in a form that looks function-like; however, we will almost never actually write them in that way.\nFunctions can be nested. This is huge because it allows us to directly pass returned values to other functions. Nesting functions in this way allows us to do very complex operations in a scalable way and without storing a bunch of unneeded values that are created in the intermediate steps of the operation.\nThe downside of nesting functions is that it can make our code difficult to read - especially when we nest many functions. Fortunately, we will learn to use the pipe operator (%&gt;%) in the workflow basics part of this book. Once you get used to pipes, they will make nested functions much easier to read.\n\nNow, let’s get back to our analysis…\n\n\n5.6.6 The length function\nWe think most of us would agree that the third method we learned for calculating the mean height is preferable to the first two methods for most situations. However, the third method still requires us to know how many individual heights are in the heights column (i.e., 4). Luckily, there is a function that tells us how many individual values are contained in a vector – the length() function. Let’s take a look:\n\n# Create the heights vector\nheights &lt;- c(68, 63, 71, 72)\n\n# Return the number of individual values in heights\nlength(heights)\n\n[1] 4\n\n\nRemember, that data frame columns are also vectors. So, we can combine the dollar sign notation and length() function to automatically calculate the number of values in the heights column of the class data frame. It looks like this:\n\n# First way to calculate the mean\n# (68 + 63 + 71 + 72) / 4\n\n# Second way. Use dollar sign notation and bracket notation so that we don't \n# have to type individual heights\n# (class$heights[1] + class$heights[2] + class$heights[3] + class$heights[4]) / 4\n\n# Third way. Use dollar sign notation and sum function so that we don't have \n# to type as much\n# sum(class$heights) / 4\n\n# Fourth way. Use dollar sign notation with the sum function and the length \n# function\nsum(class$heights) / length(class$heights)\n\n[1] 68.5\n\n\n👆Here’s what we did above:\n\nWe passed the numeric vector heights from the class data frame to the sum() function using dollar sign notation.\nThe sum() function returned the total value of all the heights added together.\nWe passed the numeric vector heights from the class data frame to the length() function using dollar sign notation.\nThe length() function returned the total number of values in the heights column.\nWe divided the total value of the heights by the total number of values in the heights column.\n\n\n\n5.6.7 The mean function\nThe fourth method above is definitely the best method yet. However, this need to find the mean value of a numeric vector is so common that someone had the sense to create a function that takes care of all the above steps for us – the mean() function. And as you probably saw coming, we can use the mean function like so:\n\n# First way to calculate the mean\n# (68 + 63 + 71 + 72) / 4\n\n# Second way. Use dollar sign notation and bracket notation so that we don't \n# have to type individual heights\n# (class$heights[1] + class$heights[2] + class$heights[3] + class$heights[4]) / 4\n\n# Third way. Use dollar sign notation and sum function so that we don't have \n# to type as much\n# sum(class$heights) / 4\n\n# Fourth way. Use dollar sign notation with the sum function and the length \n# function\n# sum(class$heights) / length(class$heights)\n\n# Fifth way. Use dollar sign notation with the mean function\nmean(class$heights)\n\n[1] 68.5\n\n\nCongratulations again! You completed your first analysis using R!",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Let’s Get Programming</span>"
    ]
  },
  {
    "objectID": "chapters/lets_get_programming/lets_get_programming.html#some-common-errors",
    "href": "chapters/lets_get_programming/lets_get_programming.html#some-common-errors",
    "title": "5  Let’s Get Programming",
    "section": "5.7 Some common errors",
    "text": "5.7 Some common errors\nBefore we move on, we want to briefly discuss a couple common errors that will frustrate many of you early in your R journey. You may have noticed that we went out of our way to differentiate between the heights vector and the heights column in the class data frame. As annoying as that may have been, we did it for a reason. The heights vector and the heights column in the class data frame are two separate things to the R interpreter, and you have to be very specific about which one you are referring to. To make this more concrete, let’s add a weight column to our class data frame.\n\nclass$weight &lt;- c(160, 170, 180, 190)\n\n👆Here’s what we did above:\n\nWe created a new column in our data frame – weight – using dollar sign notation.\n\nNow, let’s find the mean weight of the students in our class.\n\nmean(weight)\n\nError in eval(expr, envir, enclos): object 'weight' not found\n\n\nUh, oh! What happened? Why is R saying that weight doesn’t exist? We clearly created it above, right? Wrong. We didn’t create an object called weight in the code chunk above. We created a column called weight in the object called class in the code chunk above. Those are different things to R. If we want to get the mean of weight we have to tell R that weight is a column in class like so:\n\nmean(class$weight)\n\n[1] 175\n\n\nA related issue can arise when you have an object and a column with the same name but different values. For example:\n\n# An object called scores\nscores &lt;- c(5, 9, 3)\n\n# A colummn in the class data frame called scores\nclass$scores &lt;- c(95, 97, 93, 100)\n\nIf you ask R for the mean of scores, R will give you an answer.\n\nmean(scores)\n\n[1] 5.666667\n\n\nHowever, if you wanted the mean of the scores column in the class data frame, this won’t be the correct answer. Hopefully, you already know how to get the correct answer, which is:\n\nmean(class$scores)\n\n[1] 96.25\n\n\nAgain, the scores object and the scores column of the class object are different things to R.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Let’s Get Programming</span>"
    ]
  },
  {
    "objectID": "chapters/lets_get_programming/lets_get_programming.html#summary",
    "href": "chapters/lets_get_programming/lets_get_programming.html#summary",
    "title": "5  Let’s Get Programming",
    "section": "5.8 Summary",
    "text": "5.8 Summary\nWow! We covered a lot in this first part of the book on getting started with R and RStudio. Don’t feel bad if your head is swimming. It’s a lot to take-in. However, you should feel proud of the fact that you can already do some legitimately useful things with R. Namely, simulate and analyze data. In the next part of this book, we are going to discuss some tools and best practices that will make it easier and more efficient for you to write and share your R code. After that, we will move on to tackling more advanced programming and data analysis challenges.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Let’s Get Programming</span>"
    ]
  },
  {
    "objectID": "chapters/asking_questions/asking_questions.html",
    "href": "chapters/asking_questions/asking_questions.html",
    "title": "6  Asking Questions",
    "section": "",
    "text": "6.1 When should we seek help?\nImagine yourself sitting in front of your computer on a Wednesday afternoon. You are working on a project that requires the analysis of some data. You know that you need to clean up your data a little bit before you can do your analysis. For example, maybe you need to drop all the rows from your data that have a missing value for a set of variables. Before you drop them, you want to take a look at which rows meet this criterion and what information would potentially be lost in the process of dropping those rows. In other words, you just want to view the rows of your data that have a missing value for any variable. Sounds simple enough! However, you start typing out the code to make this happen and that’s when you start to run into problems. At this point, the problem you encounter will typically come in one of a few different flavors.\nIn any of these cases, you will need to figure out what your next step will be. We believe that there is typically a lot of value in starting out by attempting to solve the problem on your own without directly asking others for help. Doing so will often lead you to a deeper understanding of the solution than you would obtain by simply being given the answer. Further, finding the solution on your own helps you develop problem-solving skills that will be useful for the next coding problem you encounter – even if the details of that problem are completely different than the details of your current problem. Having said that, finding a solution on your own does not mean attempting to do so in a vacuum without the use of any resources (e.g., textbooks, existing code, or the internet). By all means, use available resources (we suggest some good ones below)!\nOn the other hand, we – the authors – have found ourselves stubbornly hacking away on our own solution to a coding problem long after doing so ceased being productive on many occasions. We don’t recommend doing this either. We hope that the guidance in this chapter will provide you with some tools for effectively and efficiently seeking help from the broader R programming community once you’ve made a sincere effort to solve the problem on your own.\nBut, how long should you attempt to solve the problem on your own before reaching out for help? As far as we know, there are no hard-and-fast rules about how long you should wait before seeking help with coding problems from others. In reality, the ideal amount of time to wait is probably dependent on a host of factors including the nature of the problem, your level of experience, project deadlines, all of your little personal idiosyncrasies, and a whole host of other factors. Therefore, the best guidance we can provide is pretty vague. In general, it isn’t ideal to reach out to the R programming community for help as soon as you encounter a problem, nor is it typically ideal to spend many hours attempting to solve a coding problem that could be solved in few minutes if you were to post a well-written question on Stack Overflow or the RStudio Community (more on these below).",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Asking Questions</span>"
    ]
  },
  {
    "objectID": "chapters/asking_questions/asking_questions.html#when-should-we-seek-help",
    "href": "chapters/asking_questions/asking_questions.html#when-should-we-seek-help",
    "title": "6  Asking Questions",
    "section": "",
    "text": "As you sit down to write the code, you realize that you don’t really even know where to start.\nYou happily start typing out the code that you believe should work, but when you run the code you get an [error][errors] message.\nYou happily start typing out the code that you believe should work, but when you run the code you don’t get the result you were expecting.\nYou happily start typing out the code that you believe should work and it does! However, you notice that your solution seems clunky, inefficient, or otherwise less than ideal.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Asking Questions</span>"
    ]
  },
  {
    "objectID": "chapters/asking_questions/asking_questions.html#where-should-we-seek-help",
    "href": "chapters/asking_questions/asking_questions.html#where-should-we-seek-help",
    "title": "6  Asking Questions",
    "section": "6.2 Where should we seek help?",
    "text": "6.2 Where should we seek help?\nWhere should you turn once you’ve determined that it is time to seek help for your coding problem? We suggest that you simply start with Google. Very often, a quick Google search will give you the results you need to help you solve your problem. However, Google search results won’t always have the answer you are looking for.\nIf you’ve done a Google search and you still can’t figure out how to solve your coding problem, we recommend posting a question on one of the following two websites:\n\nStack Overflow (https://stackoverflow.com/). This is a great website where programmers who use many different languages help each other solve programming problems. This website is free, but you will need to create an account.\nRStudio Community (https://community.rstudio.com/). Another great discussion-board-type website from the people who created a lot of the software we will use in this book. This website is also free, but also requires you to create an account.\n\n\n🗒Side Note: Please remember to cross-link your posts if you happen to create them on both Stack Overflow and RStudio Community. When we say “cross-link” we mean that you should add a hyperlink to your RStudio Community post on your Stack Overflow post and a link to your Stack Overflow post on your RStudio Community post.\n\nNext, let’s learn how to make a post.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Asking Questions</span>"
    ]
  },
  {
    "objectID": "chapters/asking_questions/asking_questions.html#how-should-we-seek-help",
    "href": "chapters/asking_questions/asking_questions.html#how-should-we-seek-help",
    "title": "6  Asking Questions",
    "section": "6.3 How should we seek help?",
    "text": "6.3 How should we seek help?\nAt this point, you’ve run into a problem, you’ve spent a little time trying to work out a solution in your head, you’ve searched Google for a solution to the problem, and you’ve still come up short. So, you decide to ask the R programming community for some help using Stack Overflow. But, how do you do that?\n\n🗒Side Note: We’ve decided to show you haw to create a post on Stack Overflow in this section, but the process for creating a post in the RStudio Community is very similar. Further, an RStudio Community tutorial is available here: https://community.rstudio.com/t/example-question-answer-topic-thread/70762.\n\n\n6.3.1 Creating a post on Stack Overflow\nThe first thing you need to do is navigate to the Stack Overflow website. The homepage will look something like the screenshot below.\n\n\n\n\n\n\n\n\n\nNext, you will click the blue “Ask Question” button. Doing so will take you to a screen like the following.\n\n\n\n\n\n\n\n\n\nAs you can see, you need to give your post a title, you need to post the actual question in the body section of the form, and then you can (and should) tag your post. “A tag is simply a word or a phrase that describes the topic of the question.”1 For our R-related questions we will want to use the “r” tag. Other examples of tags you may use often if you continue your R programming journey may include “dplyr” and “ggplot2”. When you have completed the form, you simply click the blue “Review your question” button towards the bottom-left corner of the screen.\n\n6.3.1.1 Inserting R code\nTo insert R code into your post (i.e., in the body), you will need to create code blocks. Then, you will type your R code inside of the code blocks. You can create code blocks using back-ticks ( ` ). The back-tick key is the upper-left key of most keyboards – right below the escape key. On our keyboard, the back-tick and the tilde ( ~ ) share the same key. We will learn more about code blocks in the chapter on using [Quarto/]. For now, let’s just take a look at an example of creating a code block in the screenshot below. This screenshot comes from the  example Stack Overflow post  introduced at the beginning of the chapter.\n\n\n\n\n\n\n\n\n\nAs you can see, we placed three back-ticks on their own line before our R code and three back-ticks on their own line after our R code. Alternatively, we could have used our mouse to highlight our R code and then clicked the code format button, which is highlighted in the screenshot above and looks like an empty pair of curly braces ( {} ).\n\n\n6.3.1.2 Reviewing the post\nAfter you create your post and click the “Review your question” button, you will have an opportunity to check your post for a couple of potential issues.\n\nDuplicates. You want to try your best to make sure your question isn’t a duplicate question. Meaning, you want to make sure that someone else hasn’t already asked the same question or a question that is very similar. As you are typing your post title, Stack Overflow will show you a list of potentially similar questions. It will show you that list again as you are reviewing your post. You should take a moment to look through that list and make sure you question isn’t going to be a duplicate. If it does end up being a duplicate, Stack Overflow moderators may tag it as such and close it.\nTypos and errors. Of course, you also want to check your post for standard typos, grammatical errors, and coding errors. However, you can always edit your post later if an error does slip through. You just need to click the edit text at the bottom of your post. A screenshot from the example post is shown in the screenshot below.\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.3.2 Creating better posts and asking better questions\nThere are no bad R programming questions, but there are definitely ways to ask those questions that will be better received than others. And better received questions will typically result in faster responses and more useful answers. It’s important that you ask your questions in a way that will allow the reader to understand what you are trying to accomplish, what you’ve already tried, and what results you are getting. Further, unless it’s something extremely straight forward, you should always provide a little chunk of data that recreates the problem you are experiencing. These are known as reproducible examples This is so important that there is an R package that does nothing but help you create reproducible examples – Reprex.\nAdditionally, Stack Overflow and the RStudio community both publish guidelines for posting good questions.\n\nStack Overflow guide to asking questions: https://stackoverflow.com/help/how-to-ask\nRStudio Community Tips for writing R-related questions: https://community.rstudio.com/t/faq-tips-for-writing-r-related-questions/6824\n\nYou should definitely pause here an take a few minutes to read through these guidelines. If not now, come back and read them before you post your first question on either website. Below, we show you a few example posts and highlight some of the most important characteristics of quality posts.\n\n6.3.2.1 Example posts\nHere are a few examples of highly viewed posts on Stack Overflow and the RStudio community. Feel free to look them over. Notice what was good about these posts and what could have been better. The specifics of these questions are totally irrelevant. Instead, look for the elements that make posts easy to understand and respond to.\n\nStack Overflow: How to join (merge) data frames (inner, outer, left, right)\nRStudio Community: Error: Aesthetics must be either length 1 or the same as the data (2): fill\nStack Overflow: How should I deal with “package ‘xxx’ is not available (for R version x.y.z)” warning?\nRStudio Community: Could anybody help me! Cannot add ggproto objects together\n\n\n\n6.3.2.2 Question title\nWhen creating your posts, you want to make sure they have succinct, yet descriptive, titles. Stack overflow suggests that you pretend you are talking to a busy colleague and have to summarize your issue in a single sentence.2 The RStudio Community tips for writing questions further suggests that you be specific and use keywords.3 Finally, if you are really struggling, it may be helpful to write your title last.2 In our opinion, the titles from the first 3 examples above are pretty good. The fourth has some room for improvement.\n\n\n6.3.2.3 Explanation of the issue\nMake sure your posts have a brief, yet clear, explanation of what you are trying to accomplish. For example, “Sometimes I want to view all rows in a data frame that will be dropped if I drop all rows that have a missing value for any variable. In this case, I’m specifically interested in how to do this with dplyr 1.0’s across() function used inside of the filter() verb.”\nIn addition, you may want to add what you’ve already tried, what result you are getting, and what result you are expecting. This information can help others better understand your problem and understand if the solution they offer you does what you are actually trying to do.\nFinally, if you’ve already come across other posts or resources that were similar to the problem you are having, but not quite similar enough for you to solve your problem, it can be helpful to provide links to those as well. The author of example 3 above (i.e., How should I deal with “package ‘xxx’ is not available (for R version x.y.z)” warning?) does a very thorough job of linking to other posts.\n\n\n6.3.2.4 Reproducible example\nMake sure your question/post includes a small, reproducible data set that helps others recreate your problem. This is so important, and so often overlooked by students in our courses. Notice that we did NOT say to post the actual data you are working on for your project. Typically, the actual data sets that we work with will have many more rows and columns than are needed to recreate the problem. All of this extra data just makes the problem harder to clearly see. And more importantly, the real data we often work with contains protected health information (PHI) that should NEVER be openly published on the internet.\nHere is an example of a small, reproducible data set that we created for the  example Stack Overflow post  introduced at the beginning of the chapter. It only has 5 data rows and 3 columns, but any solution that solves the problem for this small data set will likely solve the problem in our actual data set as well.\n\n# Load the dplyr package.\nlibrary(dplyr)\n\n# Simulate a small, reproducible example of the problem.\ndf &lt;- tribble(\n  ~id, ~x, ~y,\n  1, 1, 0,\n  2, 1, 1,\n  3, NA, 1,\n  4, 0, 0,\n  5, 1, NA\n)\n\nSometimes you can add reproducible data to your post without simulating your own data. When you download R, it comes with some built in data sets that all other R users have access to as well. You can see an full list of those data sets by typing the following command in your R console:\n\ndata()\n\nThere are two data sets in particular, mtcars and iris, that seemed to be used often in programming examples and question posts. You can add those data sets to your global environment and start experimenting with them using the following code.\n\n# Add the mtcars data frame your global environment\ndata(mtcars)\n\n# Add the iris data frame to your global environment\ndata(iris)\n\nIn general, you are safe to post a question on Stack Overflow or the RStudio Community using either of these data frames in your example code – assuming you are able to recreate the issue you are trying to solve using these data frames.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Asking Questions</span>"
    ]
  },
  {
    "objectID": "chapters/asking_questions/asking_questions.html#helping-others",
    "href": "chapters/asking_questions/asking_questions.html#helping-others",
    "title": "6  Asking Questions",
    "section": "6.4 Helping others",
    "text": "6.4 Helping others\nEventually, you may get to a point where you are able to help others with their R coding issues. In fact, spending a little time each day looking through posts and seeing if you can provide answers (whether you officially post them or not) is one way to improve your R coding skills. For some of us, this is even a fun way to pass time! 🤓\nIn the same way that there ways to improve the quality and usefulness of your question posts, there are also ways to improve the quality and usefulness of your replies to question posts. Stack Overflow also provides a guide for writing quality answers, which is available here: https://stackoverflow.com/help/how-to-answer. In our opinion, the most important part is to be patient, kind, and respond with a genuine desire to be helpful.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Asking Questions</span>"
    ]
  },
  {
    "objectID": "chapters/asking_questions/asking_questions.html#summary",
    "href": "chapters/asking_questions/asking_questions.html#summary",
    "title": "6  Asking Questions",
    "section": "6.5 Summary",
    "text": "6.5 Summary\nIn this chapter we discussed when and how to ask for help with R coding problems that will inevitably occur. In short,\n\nTry solving the problem on your own first, but don’t spend an entire day beating your head against the wall.\nStart with Google.\nIf you can’t find a solution on Google, create a post on Stack Overflow or the RStudio Community.\nUse best practices to create a high quality posts on Stack Overflow or the RStudio Community. Specifically:\n\nWrite succinct, yet descriptive, titles.\nWrite a a brief, yet clear, explanation of what you are trying to accomplish. Add what you’ve already tried, what result you are getting, and what result you are expecting.\nTry to always include a reproducable example of the problem you are encountering in the form of data.\n\nBe patient, kind, and genuine when posting or responding to posts.\n\n\n\n\n\n1. Stack Overflow. What are tags, and how should I use them? Published online January 2022.\n\n\n2. Stack Overflow. How do I ask a good question? Published online January 2022.\n\n\n3. RStudio. FAQ: Tips for writing r-related questions. Published online September 2021.",
    "crumbs": [
      "Getting Started",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Asking Questions</span>"
    ]
  },
  {
    "objectID": "chapters/r_scripts/r_scripts.html",
    "href": "chapters/r_scripts/r_scripts.html",
    "title": "7  R Scripts",
    "section": "",
    "text": "7.1 Creating R scripts\nTo create your own R scripts, click on the icon shown below Figure 7.5 and you will get a dropdown box with a list of files you can create. @ref(fig:new-r-script2)\nFigure 7.5: Click the new source file icon.\nClick the very first option – R Script.\nFigure 7.6: New source file options.\nWhen you do, a new untitled R Script will appear in the source pane.\nA blank R script in the source pane.\nAnd that’s pretty much it. Everything else in figure Figure 7.3 is just R code and comments about the R code. But, you can now easily save, modify, and share this code with others. In the next chapter, we are going to learn how to write R code in Quarto files, where we can add a ton of whistles and bells to this simple R script.",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>R Scripts</span>"
    ]
  },
  {
    "objectID": "chapters/quarto_files/quarto_files.html",
    "href": "chapters/quarto_files/quarto_files.html",
    "title": "8  Quarto Files",
    "section": "",
    "text": "8.1 What is Quarto?\nThere are literally entire websites and books about Quarto. Therefore, we’re only going to hit some of the highlights in this chapter. As a starting point, you can think of Quarto files as being a mix of R scripts, the R console, and a Microsoft Word or Google Doc document. We say this because:\nEven when we don’t share our Quarto files with anyone else, we find that the added functionality described above really helps us organize our data analysis more effectively and helps us understand what we were doing if we come back to the analysis at some point in the future.\nBut, Quarto_really_ shines when we do want to share our analysis or results with others. To get an idea of what we’re talking about, please take a look at the Quarto gallery and view some of the amazing things you can do with Quarto. As you can see there, Quarto files mix R code with other kinds of text and media to create documents, websites, presentations, and more. In fact, the book you are reading right now is created with Quarto files!",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Quarto Files</span>"
    ]
  },
  {
    "objectID": "chapters/quarto_files/quarto_files.html#what-is-quarto",
    "href": "chapters/quarto_files/quarto_files.html#what-is-quarto",
    "title": "8  Quarto Files",
    "section": "",
    "text": "The R code that you would otherwise write in R scripts is written in R code chunks when you use Quarto files. In Figure 8.1 there are R code chunks at lines 10 to 12, 14 to 16, 18 to 21, 27 to 29, and 33 to 35.\nInstead of having to flip back and forth between your source pane and your console (or viewer) pane in RStudio, the results from your R code are embedded directly in the Quarto file – directly below the code that generated them. In Figure 8.1 there are embedded results between lines 21 and 22, between lines 29 and 30, and between lines 35 and 36 (not fully visible).\nWhen creating a document in Microsoft Word or Google Docs, you may format text headings to help organize your document, you may format your text to emphasize certain words, you may add tables to help organize concepts or data, you may add links to other resources, and you may add pictures or charts to help you clearly communicate ideas to yourself or others. Similarly, Quarto files allow you to surround your R code with formatted text, tables, links, pictures, and charts directly in your document.",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Quarto Files</span>"
    ]
  },
  {
    "objectID": "chapters/quarto_files/quarto_files.html#why-use-quarto",
    "href": "chapters/quarto_files/quarto_files.html#why-use-quarto",
    "title": "8  Quarto Files",
    "section": "8.2 Why use Quarto?",
    "text": "8.2 Why use Quarto?\nAt this point, you may be thinking “Ok, that Quarto gallery has some cool stuff, but it also looks complicated. Why shouldn’t I just use a basic R script for the little R program I’m writing?” If that’s what you’re thinking, you have a valid point. Quarto files are slightly more complicated than basic R scripts. However, after reading the sections below, we think you will find that getting started with Quarto doesn’t have to be super complicated and the benefits provided make the initial investment in learning Quarto worth your time.",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Quarto Files</span>"
    ]
  },
  {
    "objectID": "chapters/quarto_files/quarto_files.html#create-a-quarto-file",
    "href": "chapters/quarto_files/quarto_files.html#create-a-quarto-file",
    "title": "8  Quarto Files",
    "section": "8.3 Create a Quarto file",
    "text": "8.3 Create a Quarto file\nRStudio makes it very easy to create your own Quarto file, of which there are several types. In this chapter, we’re going to show you how to create a Quarto file that can be rendered to an HTML file and viewed in your web browser.\nThe process is actually really similar to the process we used to create an R script. Start by clicking on the icon shown below in Figure 8.4.\n\n\n\n\n\n\n\n\nFigure 8.4: Click the new file icon.\n\n\n\n\n\nAs before, we’ll be presented with a dropdown box that lists a bunch of different file types for us to choose from. This time, we’ll click Quarto Document instead of R script. Figure 8.5\n\n\n\n\n\n\n\n\nFigure 8.5: New source file options.\n\n\n\n\n\nNext, a dialogue box will pop up with some options for us. For now, we will just give our Quarto document a super creative title – “Text Quarto” – and make sure the default HTML format is selected. Finally, we will click the Create button in the bottom right-hand corner of the dialogue box.\n\n\n\n\n\n\n\n\nFigure 8.6: New Quarto document options.\n\n\n\n\n\nA new Quarto file will appear in the RStudio source pane after we click the Create button. This Quarto file includes some example text and code meant to help us get started. We are typically going to erase all the example stuff and write our own text and code, but Figure 8.7 highlights some key components of Quarto files for now.\n\n\n\n\n\n\n\n\nFigure 8.7: The ‘Test Quarto’ file in the RStudio source pane.\n\n\n\n\n\nFirst, notice lines 1 through 6 in the example above. These lines make up something called the YAML header (pronounced yamel). It isn’t important for us to know what YAML means, but we do need to know that this is one of the defining features of Quarto files. We’ll talk more about the details of the YAML header soon.\nSecond, notice lines 16 through 18. These lines make up something called an R code chunk. Code chunks in Quarto files always start with three backticks ( ` ) and a pair of curly braces ({}), and they always end with three more backticks. We know that this code chunk contains R code because of the “r” inside of the curly braces. We can also create code chunks that will run other languages (e.g., python), but we won’t do that in this book. You can think of each R code chunk as a mini R script. We’ll talk more about the details of code chunks soon.\nThird, all of the other text is called Markdown. In Figure 8.7 above, the markdown text is just filler text with some basic instructions for users. In a real project we would use formatted text like this to add context around our code. For now, you can think of this as being very similar to the comments we wrote in our R scripts, but markdown allows us to do lots of cool things that the comments in our R scripts aren’t able to do. For example, line 6 has a link to a website embedded in it, line 8 includes a heading (i.e., ## Quarto), and line 14 includes text that is being formatted (the orange text surrounded by two asterisks). In this case, the text is being bolded.\nAnd that is all we have to do to create a basic Quarto file. Next, we’re going to give you a few more details about each of the key components of the Quarto file that we briefly introduced above.",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Quarto Files</span>"
    ]
  },
  {
    "objectID": "chapters/quarto_files/quarto_files.html#yaml-headers",
    "href": "chapters/quarto_files/quarto_files.html#yaml-headers",
    "title": "8  Quarto Files",
    "section": "8.4 YAML headers",
    "text": "8.4 YAML headers\nThe YAML header is unlike anything we’ve seen before. The YAML header always begins and ends with dash-dash-dash (---) typed on its own line (1 & 6 in Figure 8.7). The code written inside the YAML header generally falls into two categories:\n\nValues to be rendered in the Quarto file. For example, in Figure 8.7 we told Quarto to title our document “Test Quarto”. The title is added to the file by adding the title keyword, followed by a colon (:), followed by a character string wrapped in quotes. Examples of other values we could have added include author and date.\nInstructions that tell Quarto how to process the file. What do we mean by that? Well, remember the Quarto gallery you saw earlier? That gallery includes Word documents, PDF documents, websites, and more. But all of those different document types started as Quarto file similar to the one in Figure 8.7. Quarto will create a PDF document, a Word document, or a website from the Quarto file based, in part, on the instructions we give it inside the YAML header. For example, the YAML header in Figure 8.7 tells Quarto to create an HTML file from our Quarto file. This output type is selected by adding the format keyword, followed by a colon (:), followed by the html keyword. Further, we added the embed-resources: true option to our HTML format. Including that option makes it possible for us to send a single HTML file to others with all the supporting files embedded.\n\nWhat does an HTML file look like? Well, if you hit the Render button in RStudio:\n\n\n\n\n\n\n\n\nFigure 8.8: RStudio’s render button. Only visible when a Quarto file is open.\n\n\n\n\n\nR will ask you to save your Quarto file. After you save it, R will automatically create (or render) a new HTML file and save it in the same location where your Quarto file is saved. Additionally, a little browser window, like Figure 8.9 will pop up and give you a preview of what the rendered HTML file looks like.\n\n\n\n\n\n\n\n\nFigure 8.9: An HTML file created using a Quarto file.\n\n\n\n\n\nNotice all the formatting that was applied when R rendered the HTML file. For example, the title – “Test Quarto” – is in big bold letters at the top of the screen, The headings – Quarto and Running code – are also written in a large bold font with a faint line underneath them, the link to the Quarto website is now blue and clickable, and the word “Render” is written in bold font.\nWe can imagine that this section may seem a little confusing to some readers right now. If so, don’t worry. You don’t really need to understand the YAML header at this point. Remember, when you create a new Quarto file in the manner we described above, the YAML header is already there. You will probably want to change the title, but that may be the only change you make for now.",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Quarto Files</span>"
    ]
  },
  {
    "objectID": "chapters/quarto_files/quarto_files.html#r-code-chunks",
    "href": "chapters/quarto_files/quarto_files.html#r-code-chunks",
    "title": "8  Quarto Files",
    "section": "8.5 R code chunks",
    "text": "8.5 R code chunks\nAs we said above, R code chunks always start out with three backticks ( ` ) and a pair of curly braces ({}) with an “r” in them ({r}), and they always end with three more backticks. Typing that over and over can be tedious, so RStudio provides a keyboard shortcut for inserting R code chunks into our Quarto files.\nOn MacOS type option + command + i.\nOn Windows type control + alt + i\nInside the code chunk, we can type anything that we would otherwise type in the console or in an R script – including comments. We can then click the little green arrow in the top right corner of the code chunk to submit it to R and see the result (see the play button in Figure 8.7).\nAlternatively, we can run the code in the code chunk by typing shift + command + return on MacOS or shift + control + enter on Windows. If we want to submit a small section of code in a code chunk, as opposed to all of the code in the code chunk, we can use our mouse to highlight just the section of code we want to run and type control + return on MacOS or control + enter on Windows. There are also options to run all code chunks in the Quarto file, all code chunks above the current code chunk, and all code chunks below the current chunk. You can access these, and other, run options using the Run button in the top right-hand corner of the Quarto file in RStudio (see Figure 8.10 below).\n\n\n\n\n\n\n\n\nFigure 8.10: The run button in RStudio.",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Quarto Files</span>"
    ]
  },
  {
    "objectID": "chapters/quarto_files/quarto_files.html#markdown",
    "href": "chapters/quarto_files/quarto_files.html#markdown",
    "title": "8  Quarto Files",
    "section": "8.6 Markdown",
    "text": "8.6 Markdown\nMany readers have probably heard of HTML and CSS before. HTML stands for hypertext markup language and CSS stands for cascading style sheets. Together, HTML and CSS are used to create and style every website you’ve ever seen. HTML files created from our Quarto files are no different. They will open in any web browser and behave just like any other website. Therefore, we can manipulate and style them using HTML and CSS just like any other website. However, it takes most people a lot of time and effort to learn HTML and CSS. So, markdown was created as an easier-to-use alternative. Think of it as HTML and CSS lite. It can’t fully replace HTML and CSS, but it is much easier to learn, and you can use it to do many of the main things you might want to do with HTML and CSS. For example, Figure 8.7 and Figure 8.9 we saw that wrapping our text with two asterisks (**) bolds it.\nThere are a ton of other things we can do with markdown, and we recommend checking out Quarto’s markdown basics website to learn more. The website covers a lot and may feel overwhelming at first. So, we suggest just play around with some of the formatting options and get a feel for what they do. Having said that, it’s totally fine if you don’t try to tackle learning markdown syntax right now. You don’t really need markdown to follow along with the rest of the book. However, we still suggest using Quarto files for writing, saving, modifying, and sharing your R code.\n\n8.6.1 Markdown headings\nWhile we are discussing markdown, we would like to call special attention to markdown headings. We briefly glazed over them above, but we find that beginning R users typically benefit from a slightly more detailed discussion. Think back to the ## Quarto on line 8 of Figure 8.7. This markdown created a heading – text that stands out and breaks our document up into sections. We can create headings by beginning a line in our Quarto document with one or more hash symbols (#), followed by a space, and then our heading text. Headings can be nested underneath each other in the same way you might nest topics in a bulleted list. For example:\n\nAnimals\n\nDog\n\nLab\nYorkie\n\nCat\n\nPlants\n\nFlowers\nTrees\n\nOak\n\n\n\nNesting list items this way organizes our list and conveys information that would otherwise require explicitly writing out more text. For example, that a lab is a type of dog and that dogs are a type of animal. Thoughtfully nesting our headings in our Quarto files can have similar benefits. So, how do we nest our headings? Great question! Quarto and RStudio will automatically nest them based on the number of hash symbols we use (between 1 and 6). In the example above, ## Quarto it is a second-level heading. We know this because the line begins with two hash symbols. Figure 8.11 below shows how we might organize a Quarto file for a data analysis project into nested sections using markdown headings.\nA really important benefit of organizing our Quarto file this way is that it allows us to use RStudio’s document outline pane to quickly navigate around our Quarto file. In this trivial example, it isn’t such a big deal. But it can be a huge time saver in a Quarto file with hundreds, or thousands, of lines of code.\n\n\n\n\n\n\n\n\nFigure 8.11: A Quarto file with nested headings.\n\n\n\n\n\nAs a final note on markdown headings, we find that new R users sometimes mix up comments and headings. This is a really understandable mistake to make because both start with the hash symbol. So, how do you know when typing a hash symbol will create a comment and when it will create a heading?\n\nThe hash symbol always creates comments in R scripts. R scripts don’t understand markdown. Therefore, they don’t have markdown headings. R scripts only understand comments, which begin with a hash symbol, and R code.\nThe hash symbol always creates markdown headings in Quarto files when typed outside of an R code chunk. Remember, everything in between the R code chunks in our Quarto files is considered markdown by Quarto, and hash symbols create headings in the markdown language.\nThe hash symbol always creates comments in Quarto files when typed inside of an R code chunk. Remember, we can think of each R code chunk as a mini R script, and in R scripts, hash symbols create comments.",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Quarto Files</span>"
    ]
  },
  {
    "objectID": "chapters/quarto_files/quarto_files.html#summary",
    "href": "chapters/quarto_files/quarto_files.html#summary",
    "title": "8  Quarto Files",
    "section": "8.7 Summary",
    "text": "8.7 Summary\nQuarto files bring together R code, formatted text, and media in a single file. We can use them to make our lives easier when working on small projects that are just for us, and we can use them to create large complex documents, websites, and applications that are intended for much larger audiences. RStudio makes it easy for us to create and render Quarto files into many different document types, and learning a little bit of markdown can help us format those documents really nicely. We believe that Quarto files are a great default file type to use for most projects and we encourage readers to review the Quarto website for more details (and inspiration)!",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Quarto Files</span>"
    ]
  },
  {
    "objectID": "chapters/r_projects/projects.html",
    "href": "chapters/r_projects/projects.html",
    "title": "9  R Projects",
    "section": "",
    "text": "In previous chapters of this book, we learned how to use R Scripts and Quarto Files to create, modify, save, and share our R code and results. However, in most real-world projects we will actually create multiple different R scripts and/or Quarto files. Further, we will often have other files (e.g., images or data) that we want to store alongside our R code files. Over time, keeping up with all of these files can become cumbersome. R projects are a great tool for helping us organize and manage collections of files. Another really important advantage to organizing our files into R projects is that they allow us to use relative file paths instead of absolute file paths, which we will [discuss in detail later][File paths].\nRStudio makes creating R projects really simple. For starters, let’s take a look at the top right corner of our RStudio application window. Currently, we see an R project icon that looks like little blue 3-dimensional box with an “R” in the middle. To the right of the R project icon, we see words Project: (None). RStudio is telling us that our current session is not associated with an R project.\n\n\n\n\n\n\n\n\n\nTo create a new R project, we just need to click the drop-down arrow next to the words Project: (None) to open the projects menu. Then, we will click the New Project... option.\n\n\n\n\n\n\n\n\n\nDoing so will open the new project wizard. For now, we will select the New Directory option. We will discuss the other options later in the book.\n\n\n\n\n\n\n\n\n\nNext, we will click the New Project option.\n\n\n\n\n\n\n\n\n\nIn the next window, we will have to make some choices and enter some information. The fist thing we will have to do is name our project. We do so by entering a value in the Directory name: box. Often, we can name our R project directory to match the name of the larger project we are working on in a pretty natural way. If not, the name we choose for our project directory should essentially follow the same guidelines that we use for [object (variable) names][Object (variable) names], which we will learn about soon. In this example, we went with the very creative my_first_project project name.😆\nWhen we create our R project in a moment, RStudio will create a folder on our computer where we can keep all of the files we need for our project. That folder will be named using the name we entered in the Directory name: box in the previous step. So, the next thing we need to do is tell R where on our computer to put the folder. We do so by clicking the Browse... button and selecting a location. For this example, we chose to create the project on our computer’s desktop.\nFinally, we just click the Create Project button near the bottom-right corner of the New Project Wizard.\n\n\n\n\n\n\n\n\n\nDoing so will create our new R project in the location we selected in the Create project as subdirectory of: text box in the new project wizard. In the screenshot below, we can see that a folder was created on our computer’s desktop called my_first_project. Additionally, there is one file inside of that folder named my_first_project that ends with the file extension .Rproj (see red arrow 2 in the figure below).\n\n\n\n\n\n\n\n\n\nThis file is called an R project file. Every time we create an R project, RStudio will create an R project file and add it to our project directory (i.e., the folder) for us. This file helps RStudio track and organize our R project.\nTo easiest way to open the R project we just created is to double click the R project file – my_first_project.Rproj. Doing so will open a new RStudio session along with all of the R code files we had open last time we were working on our R project. Because this is our first time opening our example R project, we won’t see any R code files.\nAlternatively, we can open our R project by once again clicking the R project icon in the upper right corner of an open RStudio session and then clicking the Open Project... option. This will open a file selection window where we can select our R project directory and open it.\n\n\n\n\n\n\n\n\n\nFinally, we will know that RStudio understands that we are working in the context of our project because the words Project: (None) that we previously saw in the top right corner of the RStudio window will be replaced with the project name. In this case, my_first_project.\n\n\n\n\n\n\n\n\n\nNow that we’ve created our R project, there’s nothing special we need to do to add other files to it. We only need save files and folders for our project as we typically would. We just need to make sure that we save them in our project directory (i.e., the folder). RStudio will take care of the rest.\nR projects are a great tool for organizing our R code and other complimentary files. Should we use them every single time we use R? Probably not. So, when should we use them? Well, the best – albeit somewhat unhelpful – answer is probably to use them whenever they are useful. However, at this point in your R journey you may not have enough experience to know when they will be useful and when they won’t. Therefore, we are going to suggest that create an R project for your project if (1) your project will have more than one file and/or (2) more than one person will be working on the R code in your project. As we alluded to earlier, organizing our files into R projects allows us to use relative file paths instead of absolute file paths, which will make it much easier for us to collaborate with others. [File paths] will be discussed in detail later.",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>R Projects</span>"
    ]
  },
  {
    "objectID": "chapters/best_practices/best_practices.html",
    "href": "chapters/best_practices/best_practices.html",
    "title": "10  Coding Best Practices",
    "section": "",
    "text": "10.1 General principles",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Coding Best Practices</span>"
    ]
  },
  {
    "objectID": "chapters/best_practices/best_practices.html#general-principles",
    "href": "chapters/best_practices/best_practices.html#general-principles",
    "title": "10  Coding Best Practices",
    "section": "",
    "text": "Comment your code. Whether you intend to share your code with other people or not, make sure to write lots of comments about what you are trying to accomplish in each section of your code and why.\nUse a style consistently. We’re going to suggest several guidelines for styling your R code below, but you may find that you prefer to style your R code in a different way. Whether you adopt our suggested style or not, please find or create a style that works for you and your collaborators and use it consistently.",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Coding Best Practices</span>"
    ]
  },
  {
    "objectID": "chapters/best_practices/best_practices.html#code-comments",
    "href": "chapters/best_practices/best_practices.html#code-comments",
    "title": "10  Coding Best Practices",
    "section": "10.2 Code comments",
    "text": "10.2 Code comments\nThere isn’t a lot of specific advice that we can give here because comments are so idiosyncratic to the task at hand. So, we think the best we can do at this point is to offer a few examples for you to think about.\n\n10.2.1 Defining key variables\nAs we will discuss below, variables should have names that are concise, yet informative. However, the data you receive in the real world will not always include informative variable names. Even when someone has given the variables informative names, there may still be contextual information about the variables that is important to understand for data management and analysis. Some data sets will come with something called a codebook or data dictionary. These are text files that contain information about the data set that are intended to provide you with some of that more detailed information. For example, the survey questions that were used to capture the values in each variable or what category each value in a categorical variable represents. However, real data sets don’t always come with a data dictionary, and even when they do, it can be convenient to have some of that contextual information close at hand, right next to your code. Therefore, we will sometimes comment our code with information about variables that are important for the analysis at hand. Here is an example from an administrative data set we ww using for an analysis:\n\n* **Case number definition**\n\n    - Case / investigation number.\n\n* **Intake stage definition**\n\n    - An ID number assigned to the Intake. Each Intake (Report) has its \n      own number. A case may have more than one intake. For example, case # 12345 \n      has two intakes associated with it, 9 days apart, each with their own ID \n      number. Each of the two intakes associated with this case have multiple \n      allegations.\n\n* **Intake start definition**\n\n    - An intake is the submission or receipt of a report - a phone call or \n      web-based. The Intake Start Date refers to the date the staff member \n      opens a new record to begin recording the report.\n\n\n\n10.2.2 What this code is trying to accomplish\nSometimes, it is obvious what a section of code literally does. but not so obvious why you’re doing it. We often try to write some comments around our code about what it’s trying to ultimately accomplish and why. For example:\n\n## Standardize character strings\n\n# Because we will merge this data with other data sets in the future based on \n# character strings (e.g., name), we need to go ahead and standardize their \n# formats here. This will prevent mismatches during the merges. Specifically, \n# we:\n\n# 1. Transform all characters to lower case   \n# 2. Remove any special characters (e.g., hyphens, periods)   \n# 3. Remove trailing spaces (e.g., \"John Smith \")   \n# 4. Remove double spaces (e.g., \"John  Smith\")  \n\nvars &lt;- quos(full_name, first_name, middle_name, last_name, county, address, city)\n\nclient_data &lt;- client_data %&gt;% \n  mutate_at(vars(!!! vars), tolower) %&gt;% \n  mutate_at(vars(!!! vars), stringr::str_replace_all, \"[^a-zA-Z\\\\d\\\\s]\", \" \") %&gt;%\n  mutate_at(vars(!!! vars), stringr::str_replace, \"[[:blank:]]$\", \"\") %&gt;% \n  mutate_at(vars(!!! vars), stringr::str_replace_all, \"[[:blank:]]{2,}\", \" \")\n\nrm(vars)\n\n\n\n10.2.3 Why we chose this particular strategy\nIn addition to writing comments about why we did something, we sometimes write comments about why we did it instead of something else. Doing this can save you from having to relearn lessons you’ve already learned through trial and error but forgot. For example:\n\n### Create exact match dummy variables\n\n* We reshape the data from long to wide to create these variables because it significantly decreases computation time compared to doing this as a group_by operation on the long data.",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Coding Best Practices</span>"
    ]
  },
  {
    "objectID": "chapters/best_practices/best_practices.html#style-guidelines",
    "href": "chapters/best_practices/best_practices.html#style-guidelines",
    "title": "10  Coding Best Practices",
    "section": "10.3 Style guidelines",
    "text": "10.3 Style guidelines\nUsInG c_o_n_s_i_s_t_e_n_t STYLE i.s. import-ant!\n\nGood coding style is like using correct punctuation. You can manage without it, but it sure makes things easier to read. As with styles of punctuation, there are many possible variations… Good style is important because while your code only has one author, it’ll usually have multiple readers. This is especially true when you’re writing code with others. In that case, it’s a good idea to agree on a common style up-front. Since no style is strictly better than another, working with others may mean that you’ll need to sacrifice some preferred aspects of your style.1\n\nBelow, we outline the style that we and our collaborators typically use when writing R code for a research project. It generally follows the Tidyverse style guide, which we strongly suggest you read. Outside of our class, you don’t have to use our style, but you really should find or create a style that works for you and your collaborators and use it consistently.\n\n10.3.1 Comments\nPlease put a space in between the pound/hash sign and the rest of your text when writing comments. For example, # here is my comment instead of #here is my comment. It just makes the comment easier to read.\n\n\n10.3.2 Object (variable) names\nIn addition to the object naming guidance given in the Tidyverse style guide, We suggest the following object naming conventions.\n\n\n10.3.3 Use names that are informative\nUsing names that are informative and easy to remember will make life easier for everyone who uses your data – including you!\n\n# Uninformative names - Don't do this\nx1\nvar1\n\n# Informative names\nemployed\nmarried\neducation\n\n\n10.3.3.1 Use names that are concise\nYou want names to be informative, but you don’t want them to be overly verbose. Really long names create more work for you and more opportunities for typos. In fact, we recommend using a single word when you can.\n\n# Write out entire name of the study the data comes from - Don't do this\nwomens_health_initiative\n\n# Write out an acronym for the study the data comes from - assuming everyone \n# will be familiar with this acronym - Do this\nwhi\n\n\n\n10.3.3.2 Use all lowercase letters\nRemember, R is case-sensitive, which means that myStudyData and mystudydata are different things to R. Capitalizing letters in your file name just creates additional details to remember and potentially mess up. Just keep it simple and stick with lowercase letters.\n\n# All upper case - so aggressive - Don't use\nMYSTUDYDATA\n\n# Camel case - Don't use\nmyStudyData\n\n# All lowercase - Use\nmy_study_data\n\n\n\n10.3.3.3 Separate multiple words with underscores.\nSometimes you really just need to use multiple words to name your object. In those cases, we suggested separating words with an underscore.\n\n# Multiple words running together - Hard to read - Don't use\nmycancerdata\n\n# Camel case - easier to read, but more to remember and mess up - Don't use\nmyCancerData\n\n# Separate with periods - easier to read, but doesn't translate well to many \n# other languages. For example, SAS won't accept variable names with \n# periods - Don't use\nmy.cancer.data\n\n# Separate with underscores - Use\nmy_cancer_data\n\n\n\n10.3.3.4 Prefix the names of similar variables\nWhen you have multiple related variables, it’s good practice to start their variable names with the same word. It makes these related variables easier to find and work with in the future if we need to do something with all of them at once. We can sort our variable names alphabetically to easily find find them. Additionally, we can use variable selectors like starts_with(\"name\") to perform some operation on all of them at once.\n\n# Don't use\nfirst_name\nlast_name\nmiddle_name\n\n# Use\nname_first\nname_last\nname_middle\n\n# Don't use\nstreet\ncity\nstate\n\n# Use\naddress_street\naddress_city\naddress_state\n\n\n\n\n10.3.4 File Names\nAll the variable naming suggestons above also apply to file names. However, we make a few additional suggestions specific to file names below.\n\n10.3.4.1 Managing multiple files in projects\nWhen you are doing data management and analysis for real-world projects you will typically need to break the code up into multiple files. If you don’t, the code often becomes really difficult to read and manage. Having said that, finding the code you are looking for when there are 10, 20, or more separate files isn’t much fun either. Therefore, we suggest the following (or similar) file naming conventions be used in your projects.\n\nSeparate data cleaning and data analysis into separate files (typically, .R or .Rmd).\n\nData cleaning files should be prefixed with the word “data” and named as follows\n\ndata_[order number]_[purpose]\n\n\n\n\n# Examples\ndata_01_import.Rmd\ndata_02_clean.Rmd\ndata_03_process_for_regression.Rmd\n\n\nAnalysis files that do not directly create a table or figure should be prefixed with the word “analysis” and named as follows\n\nanalysis_[order number]_[brief summary of content]\n\n\n\n# Examples\nanalysis_01_exploratory.Rmd\nanalysis_02_regression.Rmd\n\n\nAnalysis files that DO directly create a table or figure should be prefixed with the word “table” or “fig” respectively and named as follows\n\ntable_[brief summary of content] or\n\nfig_[brief summary of content]\n\n\n\n# Examples\ntable_network_characteristics.Rmd\nfig_reporting_patterns.Rmd\n\n\n\n\n\n\n\nNote\n\n\n\n🗒Side Note: We sometimes do data manipulation (create variables, subset data, reshape data) in an analysis file if that analysis (or table or chart) is the only analysis that uses the modified data. Otherwise, we do the modifications in a separate data cleaning file.\n\n\n\nImages\n\nShould typically be exported as png (especially when they are intended for use HTML files).\n\nShould typically be saved in a separate “img” folder under the project home directory.\n\nShould be given a descriptive name.\n\nExample: histogram_heights.png, NOT fig_02.png.\n\nWe have found that the following image sizes typically work pretty well for our projects.\n\n1920 x 1080 for HTML\n\n770 x 360 for Word\n\n\nWord and PDF output files\n\nWe typically save them in a separate “docs” folder under the project home directory.\nWhenever possible, we try to set the Word or PDF file name to match the name of the R file that it was created in.\n\nExample: first_quarter_report.Rmd creates docs/first_quarter_report.pdf\n\n\nExported data files (i.e., RDS, RData, CSV, Excel, etc.)\n\nWe typically save them in a separate “data” folder under the project home directory.\nWhenever possible, we try to set the Word or PDF file name to match the name of the R file that it was created in.\n\nExample: data_03_texas_only.Rmd creates data/data_03_texas_only.csv\n\n\n\n\n\n\n\n1. Wickham H. Style guide. In: Advanced R.; 2019.",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Coding Best Practices</span>"
    ]
  },
  {
    "objectID": "chapters/using_pipes/using_pipes.html",
    "href": "chapters/using_pipes/using_pipes.html",
    "title": "11  Using Pipes",
    "section": "",
    "text": "11.1 What are pipes?\n🤔 What are pipes? This |&gt; is the pipe operator. As of version 4.1, the pipe operator is part of base R. Prior to version 4.1, the pipe operator was only available from the magrittr. The pipe imported from the magrittr package looked like %&gt;% and you may still come across it in R code – including in this book.\n🤔 What does the pipe operator do? In our opinion, the pipe operator makes your R code much easier to read and understand.\n🤔 How does it do that? It makes your R code easier to read and understand by allowing you to view your nested functions in the order you want them to execute, as opposed to viewing them literally nested inside of each other.\nYou were first introduced to nesting functions in the Let’s get programming chapter. Recall that functions return values, and the R language allows us to directly pass those returned values into other functions for further calculations. We referred to this as nesting functions and said it was a big deal because it allows us to do very complex operations in a scalable way, without storing a bunch of unneeded intermediate objects in our global environment.\nIn that chapter, we also discussed a potential downside of nesting functions. Namely, our R code can become really difficult to read when we start nesting lots of functions inside one another.\nPipes allow us to retain the benefits of nesting functions without making our code really difficult to read. At this point, we think it’s best to show you an example. In the code below we want to generate a sequence of numbers, then we want to calculate the log of each of the numbers, and then find the mean of the logged values.\n# Performing an operation using a series of steps.\nmy_numbers &lt;- seq(from = 2, to = 100, by = 2)\nmy_numbers_logged &lt;- log(my_numbers)\nmean_my_numbers_logged &lt;- mean(my_numbers_logged)\nmean_my_numbers_logged\n\n[1] 3.662703\n👆 Here’s what we did above:\nThe obvious first question here is, “why would I ever want to do that?” Good question! You probably won’t ever want to do what we just did in the code chunk above, but we haven’t learned many functions for working with real data yet and we don’t want to distract you with a bunch of new functions right now. Instead, we want to demonstrate what pipes do. So, we’re stuck with this silly example.\n👍 What’s nice about the code above? We would argue that it is pretty easy to read because each line does one thing and it follows a series of steps in logical order. First, create the numbers. Second, log the numbers. Third, get the mean of the logged numbers.\n👎 What could be better about the code above? All we really wanted was the mean value of the logged numbers (i.e., mean_my_numbers_logged); however, on our way to getting mean_my_numbers_logged we also created two other objects that we don’t care about – my_numbers and my_numbers_logged. It took us time to do the extra typing required to create those objects, and those objects are now cluttering up our global environment. It may not seem like that big of a deal here, but in a real data analysis project these things can really add up.\nNext, let’s try nesting these functions instead:\n# Performing an operation using nested functions.\nmean_my_numbers_logged &lt;- mean(log(seq(from = 2, to = 100, by = 2)))\nmean_my_numbers_logged\n\n[1] 3.662703\n👆Here’s what we did above:\n👍 What’s nice about the code above? It is certainly more efficient than the sequential step method we used at first. We went from using 4 lines of code to using 2 lines of code, and we didn’t generate any unneeded objects.\n👎 What could be better about the code above? Many people would say that this code is harder to read than than the the sequential step method we used at first. This is primarily due to the fact that each line no longer does one thing, and the code no longer follows a sequence of steps from start to finish. For example, the final operation we want to do is calculate the mean, but the mean() function is the first function we see when we read the code.\nFinally, let’s try see what this code looks like when we use pipes:\n# Performing an operation using pipes.\nmean_my_numbers_logged &lt;- seq(from = 2, to = 100, by = 2) |&gt; \n  log() |&gt; \n  mean()\nmean_my_numbers_logged\n\n[1] 3.662703\n👆Here’s what we did above:\n👏 As you can see, by using pipes we were able to retain the benefits of performing the operation in a series of steps (i.e., each line of code does one thing and they follow in sequential order) and the benefits of nesting functions (i.e., more efficient code).\nThe utility of the pipe operator may not be immediately apparent to you based on this very simple example. So, next we’re going to show you a little snippet of code from one of our research projects. In the code chunk that follows, the operation we’re trying to perform on the data is written in two different ways – without pipes and with pipes. It’s very unlikely that you will know what this code does, but that isn’t really the point. Just try to get a sense of which version is easier for you to read.\n# Nest functions without pipes\nresponses &lt;- select(ungroup(filter(group_by(filter(merged_data, !is.na(incident_number)), incident_number), row_number() == 1)), date_entered, detect_data, validation)\n\n# Nest functions with pipes\nresponses &lt;- merged_data |&gt; \n  filter(!is.na(incident_number)) |&gt; \n  group_by(incident_number) |&gt; \n  filter(row_number() == 1) |&gt; \n  ungroup() |&gt; \n  select(date_entered, detect_data, validation)\nWhat do you think? Even without knowing what this code does, do you feel like one version is easier to read than the other?",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Using Pipes</span>"
    ]
  },
  {
    "objectID": "chapters/using_pipes/using_pipes.html#what-are-pipes",
    "href": "chapters/using_pipes/using_pipes.html#what-are-pipes",
    "title": "11  Using Pipes",
    "section": "",
    "text": "We created a vector of numbers called my_numbers using the seq() function.\n\nThen we used the log() function to create a new vector of numbers called my_numbers_logged, which contains the log values of the numbers in my_numbers.\n\nThen we used the mean() function to create a new vector called mean_my_numbers_logged, which contains the mean of the log values in my_numbers_logged.\n\nFinally, we printed the value of mean_my_numbers_logged to the screen to view.\n\n\n\n\n\n\n\n\nWe created a vector of numbers called mean_my_numbers_logged by nesting the seq() function inside of the log() function and nesting the log() function inside of the mean() function.\nThen, we printed the value of mean_my_numbers_logged to the screen to view.\n\n\n\n\n\n\n\nWe created a vector of numbers called mean_my_numbers_logged by passing the result of the seq() function directly to the log() function using the pipe operator, and passing the result of the the log() function directly to the mean() function using the pipe operator.\nThen, we printed the value of mean_my_numbers_logged to the screen to view.",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Using Pipes</span>"
    ]
  },
  {
    "objectID": "chapters/using_pipes/using_pipes.html#how-do-pipes-work",
    "href": "chapters/using_pipes/using_pipes.html#how-do-pipes-work",
    "title": "11  Using Pipes",
    "section": "11.2 How do pipes work?",
    "text": "11.2 How do pipes work?\nPerhaps we’ve convinced you that pipes are generally useful. But, it may not be totally obvious to you how to use them. They are actually really simple. Start by thinking about pipes as having a left side and a right side.\n\n\n\n\n\n\n\n\nFigure 11.1: Pipes have a left side and a right side.\n\n\n\n\n\nThe thing on the right side of the pipe operator should always be a function.\n\n\n\n\n\n\n\n\nFigure 11.2: A function should always be to the right of the pipe operator.\n\n\n\n\n\nThe thing on the left side of the pipe operator can be a function or an object.\n\n\n\n\n\n\n\n\nFigure 11.3: A function or an object can be to the left of the pipe operator.\n\n\n\n\n\nAll the pipe operator does is take the thing on the left side and pass it to the first argument of the function on the right side.\n\n\n\n\n\n\n\n\nFigure 11.4: Pipe the left side to the first argument of the function on the right side.\n\n\n\n\n\nIt’s a really simple concept, but it can also cause people a lot of confusion at first. So, let’s take look at a couple more concrete examples.\nBelow we pass a vector of numbers to the to the mean() function, which returns the mean value of those numbers to us.\n\nmean(c(2, 4, 6, 8))\n\n[1] 5\n\n\nWe can also use a pipe to pass that vector of numbers to the mean() function.\n\nc(2, 4, 6, 8) |&gt; mean()\n\n[1] 5\n\n\nSo, the R interpreter took the thing on the left side of the pipe operator, stuck it into the first argument of the function on the right side of the pipe operator, and then executed the function. In this case, the mean() function doesn’t require any other arguments, so we don’t have to write anything else inside of the mean() function’s parentheses. When we see c(2, 4, 6, 8) |&gt; mean(), R sees mean(c(2, 4, 6, 8))\nHere’s one more example. Pretty soon we will learn how to use the filter() function from the dplyr package to keep only a subset of rows from our data frame. Let’s start by simulating some data:\n\n# Simulate some data\nheight_and_weight &lt;- tibble(\n  id     = c(\"001\", \"002\", \"003\", \"004\", \"005\"),\n  sex    = c(\"Male\", \"Male\", \"Female\", \"Female\", \"Male\"),\n  ht_in  = c(71, 69, 64, 65, 73),\n  wt_lbs = c(190, 176, 130, 154, 173)\n)\n\nheight_and_weight\n\n# A tibble: 5 × 4\n  id    sex    ht_in wt_lbs\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 001   Male      71    190\n2 002   Male      69    176\n3 003   Female    64    130\n4 004   Female    65    154\n5 005   Male      73    173\n\n\nIn order to work, the filter() function requires us to pass two values to it. The first value is the name of the data frame object with the rows we want to subset. The second is the condition used to subset the rows. Let’s say that we want to do a subgroup analysis using only the females in our data frame. We could use the filter() function like so:\n\n# First value = data frame name (height_and_weight)\n# Second value = condition for keeping rows (when the value of sex is Female)\nfilter(height_and_weight, sex == \"Female\")\n\n# A tibble: 2 × 4\n  id    sex    ht_in wt_lbs\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 003   Female    64    130\n2 004   Female    65    154\n\n\n👆Here’s what we did above:\n\nWe kept only the rows from the data frame called height_and_weight that had a value of Female for the variable called sex using dplyr’s filter() function.\n\nWe can also use a pipe to pass the height_and_weight data frame to the filter() function.\n\n# First value = data frame name (height_and_weight)\n# Second value = condition for keeping rows (when the value of sex is Female)\nheight_and_weight |&gt; filter(sex == \"Female\")\n\n# A tibble: 2 × 4\n  id    sex    ht_in wt_lbs\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 003   Female    64    130\n2 004   Female    65    154\n\n\nAs you can see, we get the exact same result. So, the R interpreter took the thing on the left side of the pipe operator, stuck it into the first argument of the function on the right side of the pipe operator, and then executed the function. In this case, the filter() function needs a value supplied to two arguments in order to work. So, we wrote sex == \"Female\" inside of the filter() function’s parentheses. When we see height_and_weight |&gt; filter(sex == \"Female\"), R sees filter(height_and_weight, sex == \"Female\").\n\n\n\n\n\n\nNote\n\n\n\n🗒Side Note: This pattern – a data frame piped into a function, which is usually then piped into one or more additional functions is something that you will see over and over in this book.\n\n\nDon’t worry too much about how the filter() function works. That isn’t the point here. The two main takeaways so far are:\n\nPipes make your code easier to read once you get used to them.\nThe R interpreter knows how to automatically take whatever is on the left side of the pipe operator and make it the value that gets passed to the first argument of the function on the right side of the pipe operator.\n\n\n11.2.1 Keyboard shortcut\nTyping |&gt; over and over can be tedious! Thankfully, RStudio provides a keyboard shortcut for inserting the pipe operator into your R code.\nOn Mac type shift + command + m.\nOn Windows type shift + control + m\nIt may not seem totally intuitive at first, but this shortcut is really handy once you get used to it.\n\n\n11.2.2 Pipe style\nAs with all the code we write, style is an important consideration. We generally agree with the recommendations given in the Tidyverse style guide. In particular:\n\nWe tend to use pipes in such a way that each line of code does one, and only one, thing.\nIf a line of code contains a pipe operator, the pipe operator should generally be the last thing typed on the line.\nThe pipe operator should always have a space in front of it.\nIf the pipe operator isn’t the last thing typed on the line, then it should be have a space after it too.\n“If the function you’re piping into has named arguments (like mutate() or summarize()), put each argument on a new line. If the function doesn’t have named arguments (like select() or filter()), keep everything on one line unless it doesn’t fit, in which case you should put each argument on its own line.”1\n“After the first step of the pipeline, indent each line by two spaces. RStudio will automatically put the spaces in for you after a line break following a |&gt; . If you’re putting each argument on its own line, indent by an extra two spaces. Make sure ) is on its own line, and un-indented to match the horizontal position of the function name.”1\n\nEach of these recommendations are demonstrated in the code below.\n\n# Do this...\nfemale_height_and_weight &lt;- height_and_weight |&gt; # Line 1\n  filter(sex == \"Female\") |&gt;                     # Line 2\n  summarise(                                     # Line 3\n    mean_ht = mean(ht_in),                       # Line 4\n    sd_ht   = sd(ht_in)                          # Line 5\n  ) |&gt;                                           # Line 6\n  print()                                        # Line 7\n\n# A tibble: 1 × 2\n  mean_ht sd_ht\n    &lt;dbl&gt; &lt;dbl&gt;\n1    64.5 0.707\n\n\nIn the code above, we would first like you to notice that each line of code does one, and only one, thing. Line 1 only assigns the result of the code pipeline to a new object – female_height_and_weight, line 2 only keeps the rows in the data frame we want – rows for females, line 3 only opens the summarise() function, line 4 only calculates the mean of the ht_in column, line 5 only calculates the standard deviation of the ht_in column, line 6 only closes the summarise() function, and line 7 only prints the result to the screen.\nSecond, we’d like you to notice that each line containing a pipe operator (i.e., lines 1, 2, and 6) ends with the pipe operator, and the pipe operators all have a space in front of them.\nThird, we’d like you to notice that each named argument in the summarise() function is written on its own line (i.e., lines 4 and 5).\nFinally, we’d like you notice that each step of the pipeline is indented two spaces (i.e., lines 2, 3, 6, and 7), lines 4 and 5 are indented an additional two spaces because they contain named arguments to the summarise() function, and that the summarise() function’s closing parenthesis is on its own line (i.e., line 6), horizontally aligned with the “s” in “summarise(”.\nNow compare that with the code in the code chunk below.\n\n# Avoid this...\nfemale_height_and_weight &lt;- height_and_weight |&gt; filter(sex == \"Female\") |&gt; \n  summarise(mean_ht = mean(ht_in), sd_ht = sd(ht_in)) |&gt; print()  \n\n# A tibble: 1 × 2\n  mean_ht sd_ht\n    &lt;dbl&gt; &lt;dbl&gt;\n1    64.5 0.707\n\n\nAlthough we get the same result as before, most people would agree that the code is harder to quickly glance at and read. Further, most people would also agree that it would be more difficult to add or rearrange steps when the code is written that way. As previously stated, there is a certain amount of subjectivity in what constitutes “good” style. But, we will once again reiterate that it is important to adopt some style and use it consistently. If you are a beginning R programmer, why not adopt the tried-and-true styles suggested here and adjust later if you have a compelling reason to do so?",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Using Pipes</span>"
    ]
  },
  {
    "objectID": "chapters/using_pipes/using_pipes.html#final-thought-on-pipes",
    "href": "chapters/using_pipes/using_pipes.html#final-thought-on-pipes",
    "title": "11  Using Pipes",
    "section": "11.3 Final thought on pipes",
    "text": "11.3 Final thought on pipes\nWe think it’s important to note that not everyone in the R programming community is a fan of using pipes. We hope that we’ve made a compelling case for why we use pipes, but we acknowledge that it is ultimately a preference, and that using pipes is not the best choice in all circumstances. Whether or not you choose to use the pipe operator is up to you; however, we will be using them extensively throughout the remainder of this book.\n\n\n\n\n1. Wickham H, Çetinkaya-Rundel M, Grolemund G. Workflow: Code style. In: R for Data Science. second.; 2023.",
    "crumbs": [
      "Coding Tools and Best Practices",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Using Pipes</span>"
    ]
  },
  {
    "objectID": "chapters/data_transfer/data_transfer.html",
    "href": "chapters/data_transfer/data_transfer.html",
    "title": "12  Introduction to Data Transfer",
    "section": "",
    "text": "In previous chapters, we learned how to write our own simple R programs by directly creating data frames in RStudio with the data.frame() function, the tibble() function, and the tribble() function. We consider this to be a really fundamental skill to master because it allows us to simulate data and it allows us to get data into R regardless of what format that data is stored in (assuming we can “see” the stored data). In other words, if nothing else, we can always resort to creating data frames this way.\nIn practice, however, this is not how people generally exchange data. You might recall that in Section 2.2.1 Transferring data We briefly mentioned the need to get data into R that others have stored in various different file types. These file types are also sometimes referred to as file formats. Common examples encountered in epidemiology include database files, spreadsheets, text files, SAS data sets, and Stata data sets.\n\n\n\n\n\n\n\n\n\nFurther, the data frames we’ve created so far don’t currently live in our global environment from one programming session to the next. We haven’t yet learned how to efficiently store our data long-term. We think the limitations of having to manually create a data frame every time we start a new programming session are probably becoming obvious to you at this point.\nIn this part of the book, we will learn to import data stored in various different file types into R for data management and analysis, we will learn to store R data frames in a more permanent way so that we can come back later to modify or analyze them, and we will learn to export data so that we may efficiently share it with others.",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Introduction to Data Transfer</span>"
    ]
  },
  {
    "objectID": "chapters/file_paths/file_paths.html",
    "href": "chapters/file_paths/file_paths.html",
    "title": "13  File Paths",
    "section": "",
    "text": "13.1 Finding file paths\nNow that we know how file paths are constructed, we can always type them manually. However, typing file paths manually is tedious and error prone. Luckily, both Windows and MacOS have shortcuts that allow us to easily copy and paste file paths into R.\nOn a Mac, we right-click on the file we want the path for and a drop-down menu will appear. Then, click the Get Info menu option.\nNow, we just copy the file path in the Where section of the get info window and paste it into our R code.\nAlternatively, as shown below, we can right click on the file we want the path for to open the same drop-down menu shown above. But, if we hold down the alt/option key the Copy menu option changes to Copy ... as Pathname. We can then left-click that option to copy the path and paste it into our R code.\nFigure 13.1: A gif about file paths.\nA similar method exists in Windows as well. First, we hold down the shift key and right click on the file we want the path for. Then, we click Copy as path in the drop-down menu that appears and paste the file path into our R code.",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>File Paths</span>"
    ]
  },
  {
    "objectID": "chapters/file_paths/file_paths.html#relative-file-paths",
    "href": "chapters/file_paths/file_paths.html#relative-file-paths",
    "title": "13  File Paths",
    "section": "13.2 Relative file paths",
    "text": "13.2 Relative file paths\nAll of the file paths we’ve seen so far in this chapter are absolute file paths (as opposed to relative file paths). In this case, absolute just means that the file path begins with the computer’s home directory. Remember, that the home directory in the examples above was /Users/bradcannell. When we are collaborating with other people, or sometimes even when we use more than one computer to work on our projects by ourselves, this can problematic. Pause here for a moment and think about why that might be…\nUsing absolute file paths can be problematic because the home directory can be different on every computer we use and is almost certainly different on one of our collaborator’s computers. Let’s take a look at an example. In the screenshot below, we are importing an Excel spreadsheet called form_20.xlsx into R as an R data frame named df. Don’t worry about the import code itself. We will learn more about [importing Microsoft Excel spreadsheets][Importing Microsoft Excel spreadsheets] soon. For now, just look at the file path we are passing to the read_excel() function. By doing so, we are telling R where to go find the Excel file that we want to import. In this case, are we giving R an absolute or relative file path?\n\n\n\n\n\n\n\n\n\nWe are giving R an absolute file path. We know this because it starts with the home directory – /Users/bradcannell. Does our code work?\nYes! Our code does work. We can tell because there are no errors on the screen and the df object we created looks as we expect it to when we print it to the screen. Great!!\nNow, let’s say that our research assistant – Arthur Epi – is going to help us analyze this data as well. So, we share this code file with him. What do you think will happen when he runs the code on his computer?\n\n\n\n\n\n\n\n\n\nWhen Arthur tries to import this file on his computer using our code, he gets an error. The error tells him that the path /Users/bradcannell/Dropbox/02 Teaching/R4Epi Textbook/my_first_project/data/form_20.xlsx doesn’t exist. And on Arthur’s computer it doesn’t! The file form_20.xlsx exists, but not at the location /Users/bradcannell/Dropbox/02 Teaching/R4Epi Textbook/my_first_project/data/. This is because Arthur’s home directory is /Users/arthurepi not /Users/bradcannell. The directions are totally different!\nTo make this point clearer, let’s return to our directions to the store example from earlier in the chapter. In that example, we only gave one list of directions to the store.\n\n\n\n\n\n\n\n\n\nNotice that these directions assume that we are starting from our house. As long as we leave from our house, they work great! But what happens if we are at someone else’s house and we ask you to go to the store and buy a loaf of bread? You’d walk out the front door and immediately discover that the directions don’t make any sense! You’d think, “Camp Bowie Blvd.? Where is that? I don’t see that street anywhere!”\nDid the store disappear? No, of course not! The store is still there. It’s just that our directions to the store assume that we are starting from our house. If these directions were a file path, they would be an absolute file path. They start all the way from our home and only work from our home.\nSo, could Arthur just change the absolute file path to work on his computer? Sure! He could do that, but then the file path wouldn’t work on Brad’s computer anymore. So, could there just be two code chunks in the file – one for Brad’s computer and one for Arthur’s computer? Sure! We could do that, but then one code chunk or the other will always throw an error on someone’s computer. That will mean that we won’t ever be able to just run our R code in its entirety. We’ll have to run it chunk-by-chunk to make sure we skip the chunk that throws an error. And this problem would just be multiplied if we are working with 5, 10, or 15 other collaborators instead of just 1. So, is there a better solution?\nYes! A better solution is to use a relative file path. Returning to our directions to the store example, it would be like giving directions to the store from a common starting point that everyone knows.\n\n\n\n\n\n\n\n\n\nNotice that the directions are now from a common location, which isn’t somebody’s “home”. Instead, it’s the corner of Camp Bowie Blvd. and Hulen St. You could even say that the directions are now relative to a common starting place. Now, we can give these directions to anyone and they can use them as long as they can find the corner of Camp Bowie and Hulen! Relative file paths work in much the same way. We tell RStudio to anchor itself at a common location that exists on everyone’s computer and then all the directions are relative to that location. But, how can we do that? What location do all of our collaborators have on all of their computers?\nThe answer is our R project’s directory (i.e., folder)! In order to effectively use relative file paths in R, we start by creating an R project. If you don’t remember how to create R projects, this would be a good time to go back and review the [R projects] chapter.\nIn the screenshot below, we can see that our RStudio session is open in the context of our R project called my_first_project.\n\n\n\n\n\n\n\n\n\nIn that context, R starts looking for files in our R project folder – no matter where we put the R project folder on our computer.\nFor example, in the next screenshot, we can see that the R project folder we previously created) (arrow 1), which is called my_first_project, is located on a computer’s desktop. One way we can tell that it’s an R project is because it contains an R project file (arrow 2). We can also see that our R project now contains a folder, which contains an Excel file called form_20.xlsx (arrow 3). Finally, we can see that we we’ve added a new Quarto/ file called test_relative_links.Rmd (arrow 4). That file contains the code we wrote to import form_20.xlsx as an R data frame.\n\n\n\n\n\n\n\n\n\nBecause we are using an R project, we can tell R where to find form_20.xlsx using a relative file path. That is, we can give R directions that begin at the R project’s directory. Remember, that just means the folder containing the R project file. In this case, my_first_project. Pause here for a minute. With that starting point in mind, how would you tell R to find form_20.xlsx?\nWell, you would say, “go into the folder called data, and then get the file called form_20.xlsx.” Written as a file path, what would that look like?\nIt would look like data/form_20.xlsx. Let’s give it a try!\n\n\n\n\n\n\n\n\n\nIt works! We can tell because there are no errors on the screen and the df object we created looks as we expect it to when we print it to the screen.\nNow, let’s try it on Arthur’s computer and see what happens.\n\n\n\n\n\n\n\n\n\nAs you can see, the absolute path still doesn’t work on Arthur’s computer, but the relative path does! It may not be obvious to you now, but this makes collaborating so much easier!\nLet’s quickly recap what we needed to do to be able to use relative file paths.\n\nWe need to create an R project.\nWe needed to save our R code and our data inside of the R project directory.\nWe needed to share the R project folder with our collaborators. This part wasn’t shown, but it was implied. We could have shared our R project by email. We could have shared our R project by using a shared cloud-based file storage service like Dropbox, Google Drive, or OneDrive. Better yet, we could have shared our R project using a GitHub repository, which we will discuss later in the book.\nWe replaced all absolute file paths in our code with relative file paths. In general, we should always use relative file paths if at all possible. It makes our code easier to read and maintain, and it makes life so much easier for us when we collaborate with others!\n\nNow that we know what file paths are and how to find them, let’s use them to import and export data to and from R.",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>File Paths</span>"
    ]
  },
  {
    "objectID": "chapters/importing_plain_text/importing_plain_text.html",
    "href": "chapters/importing_plain_text/importing_plain_text.html",
    "title": "14  Importing Plain Text Files",
    "section": "",
    "text": "14.1 Packages for importing data\nBase R contains several functions that can be used to import plain text files; however, I’m going to use the readr package to import data in the examples that follow. Compared to base R functions for importing plain text files, readr:\nIf you would like to follow along, I suggest that you go ahead and install and load readr now.\nlibrary(readr)",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Importing Plain Text Files</span>"
    ]
  },
  {
    "objectID": "chapters/importing_plain_text/importing_plain_text.html#packages-for-importing-data",
    "href": "chapters/importing_plain_text/importing_plain_text.html#packages-for-importing-data",
    "title": "14  Importing Plain Text Files",
    "section": "",
    "text": "Is roughly 10 times faster.\nDoesn’t convert character variables to factors by default.\nBehaves more consistently across operating systems and geographic locations.",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Importing Plain Text Files</span>"
    ]
  },
  {
    "objectID": "chapters/importing_plain_text/importing_plain_text.html#importing-space-delimited-files",
    "href": "chapters/importing_plain_text/importing_plain_text.html#importing-space-delimited-files",
    "title": "14  Importing Plain Text Files",
    "section": "14.2 Importing space delimited files",
    "text": "14.2 Importing space delimited files\nWe will start by importing data with values are separated by a single space. Not necessarily because this is the most common format you will encounter; in my experience it is not. But it’s about as simple as it gets, and other types of data are often considered special cases of files separated with a single space. So, it seems like a good place to start.\n\n\n\n\n\n\nTip\n\n\n\n🗒Side Note: In programming lingo, it is common to use the word delimited interchangeably with the word separated. For example, you might say “values separated by a single space” or you might say “a file with space delimited values.”\n\n\n\n\n\n\n\n\n\n\n\nFor our first example we will import a text file with values separated by a single space. The contents of the file are the now familiar height and weight data.\nYou may click here to download this file to your computer.\n\nsingle_space &lt;- read_delim(\n  file = \"single_delimited.txt\",\n  delim = \" \"\n)\n\nRows: 4 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\nchr (3): id, sex, ht_in\ndbl (1): wgt_lbs\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nsingle_space\n\n# A tibble: 4 × 4\n  id    sex    ht_in wgt_lbs\n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt;\n1 001   Male   71        190\n2 002   Male   .         176\n3 003   Female 64        130\n4 004   Female 65        154\n\n\n👆Here’s what we did above:\n\nWe used readr’s read_delim() function to import a data set with values that are delimited by a single space. Those values were imported as a data frame, and we assigned that data frame to the R object called single_space.\nYou can type ?read_delim into your R console to view the help documentation for this function and follow along with the explanation below.\nThe first argument to the read_delim() function is the file argument. The value passed to the file argument should be a file path that tells R where to find the data set on your computer.\nThe second argument to the read_delim() function is the delim argument. The value passed to the delim argument tells R what character separates each value in the data set. In this case, a single space separates the values. Note that we had to wrap the single space in quotation marks.\nThe readr package imported the data and printed a message giving us some information about how it interpreted column names and column types. In programming lingo, deciding how to interpret the data that is being imported is called parsing the data.\n\nBy default, readr will assume that the first row of data contains variable names and will try to use them as column names in the data frame it creates. In this case, that was a good assumption. We want the columns to be named id, sex, ht_in, and wgt_lbs. Later, we will learn how to override this default behavior.\nBy default, readr will try to guess what type of data (e.g., numbers, character strings, dates, etc.) each column contains. It will guess based on analyzing the contents of the first 1,000 rows of the data. In this case, readr’s guess was not entirely correct (or at least not what we wanted). readr correctly guessed that the variables id and sex should be character variables, but incorrectly guessed that ht_in should be a character variable as well. Below, we will learn how to fix this issue.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nMake sure to always include the file extension in your file paths. For example, using “/single_delimited” instead of “/single_delimited.txt” above (i.e., no .txt) would have resulted in an error telling you that the filed does not exist.\n\n\n\n14.2.1 Specifying missing data values\nIn the previous example, readr guessed that the variable ht_in was a character variable. Take another look at the data and see if you can figure out why?\n\n\n\n\n\n\n\n\n\nDid you see the period in the third value of the third row? The period is there because this value is missing, and a period is commonly used to represent missing data. However, R represents missing data with the special NA value – not a period. So, the period is just a regular character value to R. When R reads the values in the ht_in column, it decides that it can easily turn the numbers into character values, but it doesn’t know how to turn the period into a number. So, the column is parsed as a character vector.\nBut as we said, this is not what we want. So, how do we fix it? Well, in this case, we will simply need to tell R that missing values are represented with a period in the data we are importing. We do that by passing that information to the na argument of the read_delim() function:\n\nsingle_space &lt;- read_delim(\n  file = \"single_delimited.txt\",\n  delim = \" \",\n  na = \".\"\n)\n\nRows: 4 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \" \"\nchr (2): id, sex\ndbl (2): ht_in, wgt_lbs\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nsingle_space\n\n# A tibble: 4 × 4\n  id    sex    ht_in wgt_lbs\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 001   Male      71     190\n2 002   Male      NA     176\n3 003   Female    64     130\n4 004   Female    65     154\n\n\n👆Here’s what we did above:\n\nBy default, the value passed to the na argument of the read_delim() function is c(\"\", \"NA\"). This means that R looks for nothing (i.e., a value should be there but isn’t - this really doesn’t make sense when the delimiter is a single space) or an NA.\nWe told R to look for a period to represent missing data instead of a nothing or an NA by passing the period character to the na argument.\nIt’s important to note that changing the value of the na argument does not change the way R represents missing data in the data frame that is created. It only tells R how to identify missing values in the raw data that we are importing. In the R data frame that is created, missing data will still be represented with the special NA value.",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Importing Plain Text Files</span>"
    ]
  },
  {
    "objectID": "chapters/importing_plain_text/importing_plain_text.html#importing-tab-delimited-files",
    "href": "chapters/importing_plain_text/importing_plain_text.html#importing-tab-delimited-files",
    "title": "14  Importing Plain Text Files",
    "section": "14.3 Importing tab delimited files",
    "text": "14.3 Importing tab delimited files\nSometimes you will encounter plain text files that contain values separated by tab characters instead of a single space. Files like these may be called tab separated value or tsv files, or they may be called tab-delimited files.\n\n\n\n\n\n\n\n\n\nTo import tab separated value files in R, we use a variation of the same program we just saw. We just need to tell R that now the values in the data will be delimited by tabs instead of a single space.\nYou may click here to download this file to your computer.\n\ntab &lt;- read_delim(\n  file = \"tab.txt\",\n  delim = \"\\t\"\n)\n\nRows: 4 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (2): id, sex\ndbl (2): ht_in, wgt_lbs\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ntab\n\n# A tibble: 4 × 4\n  id    sex    ht_in wgt_lbs\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 001   Male      71     190\n2 002   Male      69     176\n3 003   Female    64     130\n4 004   Female    65     154\n\n\n👆Here’s what we did above:\n\nWe used readr’s read_delim() function to import a data set with values that are delimited by tabs. Those values were imported as a data frame, and we assigned that data frame to the R object called tab.\nTo tell R that the values are now separated by tabs, we changed the value we passed to the delim argument to \"\\t\". This is a special symbol that means “tab” to R.\n\nI don’t personally receive tab separated values files very often. But, apparently, they are common enough to warrant a shortcut function in the readr package. That is, instead of using the read_delim() function with the value of the delim argument set to \"\\t\", we can simply pass our file path to the read_tsv() function. Under the hood, the read_tsv() function does exactly the same thing as the read_delim() function with the value of the delim argument set to \"\\t\".\n\ntab &lt;- read_tsv(\"tab.txt\")\n\nRows: 4 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (2): id, sex\ndbl (2): ht_in, wgt_lbs\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ntab\n\n# A tibble: 4 × 4\n  id    sex    ht_in wgt_lbs\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 001   Male      71     190\n2 002   Male      69     176\n3 003   Female    64     130\n4 004   Female    65     154",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Importing Plain Text Files</span>"
    ]
  },
  {
    "objectID": "chapters/importing_plain_text/importing_plain_text.html#importing-fixed-width-format-files",
    "href": "chapters/importing_plain_text/importing_plain_text.html#importing-fixed-width-format-files",
    "title": "14  Importing Plain Text Files",
    "section": "14.4 Importing fixed width format files",
    "text": "14.4 Importing fixed width format files\nYet another type of plain text file we will discuss is called a fixed width format or fwf file. Again, these files aren’t super common in my experience, but they can be sort of tricky when you do encounter them. Take a look at this example:\n\n\n\n\n\n\n\n\n\nAs you can see, a hallmark of fixed width format files is inconsistent spacing between values. For example, there is only one single space between the values 004 and Female in the fourth row. But, there are multiple spaces between the values 65 and 154. Therefore, we can’t tell R to look for a single space or tab to separate values. So, how do we tell R which characters (including spaces) go with which variable? Well, if you look closely you will notice that all variable values start in the same column. If you are wondering what I mean, try to imagine a number line along the top of the data:\n\n\n\n\n\n\n\n\n\nThis number line creates a sequence of columns across your data, with each column being 1 character wide. Notice that spaces are also considered a character with width just like any other. We can use these columns to tell R exactly which columns contain the values for each variable.\nYou may click here to download this file to your computer.\nNow, in this case we can just use readr’s read_table() function to import this data:\n\nfixed &lt;- read_table(\"fixed_width.txt\")\n\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  id = col_character(),\n  sex = col_character(),\n  ht_in = col_double(),\n  wgt_lbs = col_double()\n)\n\n\nWarning: 1 parsing failure.\nrow col  expected    actual              file\n  1  -- 4 columns 5 columns 'fixed_width.txt'\n\n\n\nfixed\n\n# A tibble: 4 × 4\n  id    sex    ht_in wgt_lbs\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 001   Male      71     190\n2 002   Male      69     176\n3 003   Female    64     130\n4 004   Female    65     154\n\n\n👆Here’s what we did above:\n\nWe used readr’s read_table() function to import data from a fixed width format file. Those values were imported as a data frame, and we assigned that data frame to the R object called fixed.\nYou can type ?read_table into your R console to view the help documentation for this function and follow along with the explanation below.\nBy default, the read_table() function looks for values to be separated by one or more columns of space.\n\nHowever, how could you import this data if there weren’t always spaces in between data values. For example:\n\n\n\n\n\n\n\n\n\nIn this case, the read_table() function does not give us the result we want.\n\nfixed &lt;- read_table(\"fixed_width_no_space.txt\")\n\n\n── Column specification ────────────────────────────────────────────────────────\ncols(\n  id = col_character(),\n  sex = col_double(),\n  ht_inwgt_lbs = col_double()\n)\n\n\nWarning: 3 parsing failures.\nrow col  expected    actual                       file\n  1  -- 3 columns 4 columns 'fixed_width_no_space.txt'\n  3  -- 3 columns 2 columns 'fixed_width_no_space.txt'\n  4  -- 3 columns 2 columns 'fixed_width_no_space.txt'\n\n\n\nfixed\n\n# A tibble: 4 × 3\n  id            sex ht_inwgt_lbs\n  &lt;chr&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n1 001Male        71          190\n2 002Male        69          176\n3 003Female64   130           NA\n4 004Female65   154           NA\n\n\nInstead, it parses the entire data set as a single character column. It does this because it can’t tell where the values for one variable stop and the values for the next variable start. However, because all the variables start in the same column, we can tell R how to parse the data correctly. We can actually do this in a couple different ways:\nYou may click here to download this file to your computer.\n\n14.4.1 Vector of column widths\nOne way to import this data is to tell R how many columns wide each variable is in the raw data. We do that like so:\n\nfixed &lt;- read_fwf(\n  file = \"fixed_width_no_space.txt\",\n  col_positions = fwf_widths(\n    widths    = c(3, 6, 5, 3),\n    col_names = c(\"id\", \"sex\", \"ht_in\", \"wgt_lbs\")\n  ),\n  skip = 1\n)\n\nRows: 4 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\n\nchr (2): id, sex\ndbl (2): ht_in, wgt_lbs\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nfixed\n\n# A tibble: 4 × 4\n  id    sex    ht_in wgt_lbs\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 001   Male      71     190\n2 002   Male      69     176\n3 003   Female    64     130\n4 004   Female    65     154\n\n\n👆Here’s what we did above:\n\nWe used readr’s read_fwf() function to import data from a fixed width format file. Those values were imported as a data frame, and we assigned that data frame to the R object called fixed.\nYou can type ?read_fwf into your R console to view the help documentation for this function and follow along with the explanation below.\nThe first argument to the read_fwf() function is the file argument. The value passed to the file argument should be file path that tells R where to find the data set on your computer.\nThe second argument to the read_fwf() function is the the col_positions argument. The value passed to this argument tells R the width (i.e., number of columns) that belong to each variable in the raw data set. This information is actually passed to the col_positions argument directly from the fwf_widths() function. This is an example of nesting functions.\n\nThe first argument to the fwf_widths() function is the widths argument. The value passed to the widths argument should be a numeric vector of column widths. The column width of each variable should be calculated as the number of columns that contain the values for that variable. For example, take another look at the data with the imaginary number line:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAll of the values for the variable id can be located within the first 3 columns of data. All of the values for the variable sex can be located within the next 6 columns of data. All of the values for the variable ht_in can be located within the next 5 columns of data. And, all of the values for the variable wgt_lbs can be located within the next 3 columns of data. Therefore, we pass the vector c(3, 6, 5, 3) to the widths argument.\n\n\nThe second argument to the fwf_widths() function is the col_names argument. The value passed to the col_names argument should be a character vector of column names.\n\n\n\n\nThe third argument of the read_fwf() function that we passed a value to is the skip argument. The value passed to the skip argument tells R how many rows to ignore before looking for data values in the raw data. In this case, we passed a value of one, which told R to ignore the first row of the raw data. We did this because the first row of the raw data contained variable names instead of data values, and we already gave R variable names in the col_names argument to the fwf_widths() function.\n\n\n\n14.4.2 Paired vector of start and end positions\nAnother way to import this data is to tell R how which columns each variable starts and stops at in the raw data. We do that like so:\n\nfixed &lt;- read_fwf(\n  file = \"fixed_width_no_space.txt\",\n  col_positions = fwf_positions(\n    start     = c(1, 4, 10, 15),\n    end       = c(3, 9, 11, 17),\n    col_names = c(\"id\", \"sex\", \"ht_in\", \"wgt_lbs\")\n  ),\n  skip = 1\n)\n\nRows: 4 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\n\nchr (2): id, sex\ndbl (2): ht_in, wgt_lbs\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nfixed\n\n# A tibble: 4 × 4\n  id    sex    ht_in wgt_lbs\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 001   Male      71     190\n2 002   Male      69     176\n3 003   Female    64     130\n4 004   Female    65     154\n\n\n👆Here’s what we did above:\n\nThis time, we passed column positions to the col_positions argument of read_fwf() directly from the fwf_positions() function.\n\nThe first argument to the fwf_positions() function is the start argument. The value passed to the start argument should be a numeric vector containing the first column that contains a value for each variable. For example, take another look at the data with the imaginary number line:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe first column that contains part of the value for the variable id can be located in column 1 of data. The first column that contains part of the value for the variable sex can be located in column 4 of data. The first column that contains part of the value for the variable ht_in can be located in column 10 of data. And, the first column that contains part of the value for the variable wgt_lbs can be located in column 15 of data. Therefore, we pass the vector c(1, 4, 10, 15) to the start argument.\n\n\nThe second argument to the fwf_positions() function is the end argument. The value passed to the end argument should be a numeric vector containing the last column that contains a value for each variable. The last column that contains part of the value for the variable id can be located in column 3 of data. The last column that contains part of the value for the variable sex can be located in column 9 of data. The last column that contains part of the value for the variable ht_in can be located in column 11 of data. And, the last column that contains part of the value for the variable wgt_lbs can be located in column 17 of data. Therefore, we pass the vector c(3, 9, 11, 17) to the end argument.\n\n\nThe third argument to the fwf_positions() function is the col_names argument. The value passed to the col_names argument should be a character vector of column names.\n\n\n\n\n\n14.4.3 Using named arguments\nAs a shortcut, either of the methods above can be written using named vectors. All this means is that we basically combine the widths and col_names arguments to pass a vector of column widths, or we combine the start, end, and col_names arguments to pass a vector of start and end positions. For example:\nColumn widths:\n\nread_fwf(\n  file = \"fixed_width_no_space.txt\",\n  col_positions = fwf_cols(\n    id      = 3,\n    sex     = 6,\n    ht_in   = 5,\n    wgt_lbs = 3\n  ),\n  skip = 1\n)\n\n# A tibble: 4 × 4\n  id    sex    ht_in wgt_lbs\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 001   Male      71     190\n2 002   Male      69     176\n3 003   Female    64     130\n4 004   Female    65     154\n\n\nColumn positions:\n\nread_fwf(\n  file = \"fixed_width_no_space.txt\",\n  col_positions = fwf_cols(\n    id      = c(1, 3),\n    sex     = c(4, 9),\n    ht_in   = c(10, 11),\n    wgt_lbs = c(15, 17)\n  ),\n  skip = 1\n)\n\nRows: 4 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\n\nchr (2): id, sex\ndbl (2): ht_in, wgt_lbs\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n# A tibble: 4 × 4\n  id    sex    ht_in wgt_lbs\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 001   Male      71     190\n2 002   Male      69     176\n3 003   Female    64     130\n4 004   Female    65     154",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Importing Plain Text Files</span>"
    ]
  },
  {
    "objectID": "chapters/importing_plain_text/importing_plain_text.html#importing-comma-separated-values-files",
    "href": "chapters/importing_plain_text/importing_plain_text.html#importing-comma-separated-values-files",
    "title": "14  Importing Plain Text Files",
    "section": "14.5 Importing comma separated values files",
    "text": "14.5 Importing comma separated values files\nThe final type of plain text file that we will discuss is by far the most common type used in my experience. I’m talking about the comma separated values or csv file. Unlike space and tab separated values files, csv file names end with the .csv file extension. Although, csv files are plain text files that can be opened in plain text editors such as Notepad for Windows or TextEdit for Mac, many people view csv files in spreadsheet applications like Microsoft Excel, Numbers for Mac, or Google Sheets.\n\n\n\n\n\nA csv file viewed in a plain text editor.\n\n\n\n\n\n\n\n\n\nA csv file viewed in Microsoft Excel.\n\n\n\n\nImporting standard csv files into R with the readr package is easy and uses a syntax that is very similar to read_delim() and read_tsv(). In fact, in many cases we only have to pass the path to the csv file to the read_csv() function like so:\nYou may click here to download this file to your computer.\n\ncsv &lt;- read_csv(\"comma.csv\")\n\nRows: 4 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): sex\ndbl (3): id, ht_in, wt_lbs\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\ncsv\n\n# A tibble: 4 × 4\n     id sex    ht_in wt_lbs\n  &lt;dbl&gt; &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1     1 Male      71    190\n2     2 Male      69    176\n3     3 Female    64    130\n4     4 Female    65    154\n\n\n👆Here’s what we did above:\n\nWe used readr’s read_csv() function to import a data set with values that are delimited by commas. Those values were imported as a data frame, and we assigned that data frame to the R object called csv.\nYou can type ?read_csv into your R console to view the help documentation for this function and follow along with the explanation below.\nLike read_tsv(), R is basically executing the read_delim() function with the value of the delim argument set to \",\" under the hood. You could also use the read_delim() function with the value of the delim argument set to \",\" if you wanted to.",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Importing Plain Text Files</span>"
    ]
  },
  {
    "objectID": "chapters/importing_plain_text/importing_plain_text.html#additional-arguments",
    "href": "chapters/importing_plain_text/importing_plain_text.html#additional-arguments",
    "title": "14  Importing Plain Text Files",
    "section": "14.6 Additional arguments",
    "text": "14.6 Additional arguments\nFor the most part, the data we imported in all of the examples above was relatively well behaved. What I mean by that is that the data basically “looked” like each of the read_ functions were expecting it to “look”. Therefore, we didn’t have to adjust many of the various read_ functions’ default values. The exception was changing the default value of the na argument to the read_delim() function. However, all of the read_ functions above have additional arguments that you may need to tweak on occasion. The two that I tend to adjust most often are the col_names and col_types arguments. It’s impossible for me to think of every scenario where you may need to do this, but I’ll walk through a basic example below, which should be sufficient for you to get the idea.\nTake a look at this csv file for a few seconds. It started as the same exact height and weight data we’ve been using, but I made a few changes. See if you can spot them all.\n\n\n\n\n\n\n\n\n\nWhen people record data in Microsoft Excel, they do all kinds of crazy things. In the screenshot above, I’ve included just a few examples of things I see all the time. For example:\n\nRow one contains generic variable names that don’t really serve much of a purpose.\nRow two is a blank line. I’m not sure why it’s there. Maybe the study staff finds it aesthetically pleasing?\nRow three contains some variable descriptions. These are actually useful, but they aren’t currently formatted in a way that makes for good variable names.\nRow 7, column D is a missing value. However, someone wrote the word “Missing” instead of leaving the cell blank.\nColumn E also contains some notes for the data collection staff that aren’t really part of the data.\n\nAll of the issues listed above are things we will have to deal with before we can analyze our data. Now, in this small data set we could just fix these issues directly in Microsoft Excel and then import the altered data into R with a simple call to read_csv() without adjusting any options. However, that this is generally a really bad idea.\n\n\n\n\n\n\nWarning\n\n\n\n\nI suggest that you don’t EVER alter your raw data. All kinds of crazy things happen with data and data files. If you keep your raw data untouched and in a safe place, worst case scenario you can always come back to it and start over. If you start messing with the raw data, then you may lose the ability to recover what it looked like in its original form forever. If you import the data into R before altering it then your raw data stays preserved\nIf you are going to make alterations in Excel prior to importing the data, I strongly suggest making a copy of the raw data first. Then, alter the copy before importing into R. But, even this can be a bad idea.\nIf you make alterations to the data in Excel then there is generally no record of those alterations. For example, let’s say you click in a cell and delete a value (maybe even by accident), and then send me the csv file. I will have no way of knowing that a value was deleted. When you alter the data directly in Excel (or any program that doesn’t require writing code), it can be really difficult for others (including future you) to know what was done to the data. You may be able manually compare the altered data to the original data if you have access to both, but who wants to do that – especially if the file is large? However, if you import the data into R as-is and programmatically make alterations with R code, then your R code will, by definition, serve a record of all alterations that were made.\nOften data is updated. You could spend a significant amount of time altering your data in Excel only to be sent an updated file next week. Often, the manual alterations you made in one Excel file are not transferable to another. However, if all alterations are made in R, then you can often just run the exact same code again on the updated data.\n\n\n\nSo, let’s walk through addressing these issues together. We’ll start by taking a look at our results with all of read_csv’s arguments left at their default values.\nYou may click here to download this file to your computer.\n\ncsv &lt;- read_csv(\"comma_complex.csv\")\n\nNew names:\nRows: 6 Columns: 5\n── Column specification\n──────────────────────────────────────────────────────── Delimiter: \",\" chr\n(5): Var1...1, Var1...2, Var3, Var4, Notes\nℹ Use `spec()` to retrieve the full column specification for this data. ℹ\nSpecify the column types or set `show_col_types = FALSE` to quiet this message.\n• `Var1` -&gt; `Var1...1`\n• `Var1` -&gt; `Var1...2`\n\n\n\ncsv\n\n# A tibble: 6 × 5\n  Var1...1 Var1...2        Var3                   Var4                     Notes\n  &lt;chr&gt;    &lt;chr&gt;           &lt;chr&gt;                  &lt;chr&gt;                    &lt;chr&gt;\n1 &lt;NA&gt;     &lt;NA&gt;            &lt;NA&gt;                   &lt;NA&gt;                     &lt;NA&gt; \n2 Study ID Participant Sex Paticipant Height (in) Participant Weight (lbs) &lt;NA&gt; \n3 1        Male            71                     190                      &lt;NA&gt; \n4 2        Male            &lt;NA&gt;                   176                      &lt;NA&gt; \n5 3        Female          64                     130                      &lt;NA&gt; \n6 4        Female          65                     Missing                  Call…\n\n\nThat is obviously not what we wanted. So, let’s start adjusting some of read_csv()’s defaults – staring with the column names.\n\ncsv &lt;- read_csv(\n  file = \"comma_complex.csv\",\n  col_names = c(\"id\", \"sex\", \"ht_in\", \"wgt_lbs\")\n)\n\nRows: 7 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): id, sex, ht_in, wgt_lbs, X5\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n# A tibble: 7 × 5\n  id       sex             ht_in                  wgt_lbs                  X5   \n  &lt;chr&gt;    &lt;chr&gt;           &lt;chr&gt;                  &lt;chr&gt;                    &lt;chr&gt;\n1 Var1     Var1            Var3                   Var4                     Notes\n2 &lt;NA&gt;     &lt;NA&gt;            &lt;NA&gt;                   &lt;NA&gt;                     &lt;NA&gt; \n3 Study ID Participant Sex Paticipant Height (in) Participant Weight (lbs) &lt;NA&gt; \n4 1        Male            71                     190                      &lt;NA&gt; \n5 2        Male            &lt;NA&gt;                   176                      &lt;NA&gt; \n6 3        Female          64                     130                      &lt;NA&gt; \n7 4        Female          65                     Missing                  Call…\n\n\n👆Here’s what we did above:\n\nWe passed a character vector of variable names to the col_names argument. Doing so told R to use the words in the character vector as column names instead of the values in the first row of the raw data (the default).\nBecause the character vector of names only contained 4 values, the last column was dropped from the data. R gives us a warning message to let us know. Specially, for each row it says that it was expecting 4 columns (because we gave it 4 column names), but actually found 5 columns. We’ll get rid of this message next.\n\n\ncsv &lt;- read_csv(\n  file = \"comma_complex.csv\",\n  col_names = c(\"id\", \"sex\", \"ht_in\", \"wgt_lbs\"),\n  col_types = cols(\n    col_character(),\n    col_character(),\n    col_integer(),\n    col_integer(),\n    col_skip()\n  )\n)\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\n\ncsv\n\n# A tibble: 7 × 4\n  id       sex             ht_in wgt_lbs\n  &lt;chr&gt;    &lt;chr&gt;           &lt;int&gt;   &lt;int&gt;\n1 Var1     Var1               NA      NA\n2 &lt;NA&gt;     &lt;NA&gt;               NA      NA\n3 Study ID Participant Sex    NA      NA\n4 1        Male               71     190\n5 2        Male               NA     176\n6 3        Female             64     130\n7 4        Female             65      NA\n\n\n👆Here’s what we did above:\n\nWe told R explicitly what type of values we wanted each column to contain. We did so by nesting a col_ function for each column type inside the col() function, which is passed directly to the col-types argument.\nYou can type ?readr::cols into your R console to view the help documentation for this function and follow along with the explanation below.\nNotice various column types (e.g., col_character()) are functions, and that they are nested inside of the cols() function. Because they are functions, you must include the parentheses. That’s just how the readr package is designed.\nNotice that the last column type we passed to the col_types argument was col_skip(). This tells R to ignore the 5th column in the raw data (5th because it’s the 5th column type we listed). Doing this will get rid of the warning we saw earlier.\nYou can type ?readr::cols into your R console to see all available column types.\nBecause we told R explicitly what type of values we wanted each column to contain, R had to drop any values that couldn’t be coerced to the type we requested. More specifically, they were coerced to missing (NA). For example, the value Var3 that was previously in the first row of the ht_in column. It was coerced to NA because R does not know (nor do I) how to turn the character string “Var3” into an integer. R gives us a warning message about this.\n\nNext, let’s go ahead and tell R to ignore the first three rows of the csv file. They don’t contain anything that is of use to us at this point.\n\ncsv &lt;- read_csv(\n  file = \"comma_complex.csv\",\n  col_names = c(\"id\", \"sex\", \"ht_in\", \"wgt_lbs\"),\n  col_types = cols(\n    col_character(),\n    col_character(),\n    col_integer(),\n    col_integer(),\n    col_skip()\n  ),\n  skip = 3\n)\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\n\ncsv\n\n# A tibble: 4 × 4\n  id    sex    ht_in wgt_lbs\n  &lt;chr&gt; &lt;chr&gt;  &lt;int&gt;   &lt;int&gt;\n1 1     Male      71     190\n2 2     Male      NA     176\n3 3     Female    64     130\n4 4     Female    65      NA\n\n\n👆Here’s what we did above:\n\nWe told R to ignore the first three rows of the csv file by passing the value 3 to the skip argument.\nThe remaining warning above is R telling us that it still had to convert the word “Missing” to an NA in the 4th row of the wgt_lbs column because it didn’t know how to turn the word “Missing” into an integer. This is actually exactly what we wanted to happen, but we can get rid of the warning by explicitly adding the word “Missing” to the list of values R looks for in the na argument.\n\n\ncsv &lt;- read_csv(\n  file = \"comma_complex.csv\",\n  col_names = c(\"id\", \"sex\", \"ht_in\", \"wgt_lbs\"),\n  col_types = cols(\n    col_character(),\n    col_character(),\n    col_integer(),\n    col_integer(),\n    col_skip()\n  ),\n  skip = 3,\n  na = c(\"\", \"NA\", \"Missing\")\n)\n\n\ncsv\n\n# A tibble: 4 × 4\n  id    sex    ht_in wgt_lbs\n  &lt;chr&gt; &lt;chr&gt;  &lt;int&gt;   &lt;int&gt;\n1 1     Male      71     190\n2 2     Male      NA     176\n3 3     Female    64     130\n4 4     Female    65      NA\n\n\nWow! This was kind of a long chapter! 🤯 But, you should now have the foundation you need to start importing data in R instead of creating data frames manually. At least as it pertains to data that is stored in plain text files. Next, we will learn how to import data that is stored in binary files. Most of the concepts we learned in this chapter will apply, but we will get to use a couple new packages 📦.",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Importing Plain Text Files</span>"
    ]
  },
  {
    "objectID": "chapters/importing_binary_files/importing_binary_files.html",
    "href": "chapters/importing_binary_files/importing_binary_files.html",
    "title": "15  Importing Binary Files",
    "section": "",
    "text": "15.1 Packages for importing data\nTechnically, base R does not contain any functions that can be used to import the binary file types discussed above. However, the foreign package contains functions that may be used to import SAS data sets and Stata data sets, and is installed by default when you install R on your computer. Having said that, we aren’t going to use the foreign package in this chapter. Instead, we’re going to use the following packages to import data in the examples below. If you haven’t done so already, we suggest that you go ahead and install these packages now.\nlibrary(readxl)\nlibrary(haven)",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Importing Binary Files</span>"
    ]
  },
  {
    "objectID": "chapters/importing_binary_files/importing_binary_files.html#packages-for-importing-data",
    "href": "chapters/importing_binary_files/importing_binary_files.html#packages-for-importing-data",
    "title": "15  Importing Binary Files",
    "section": "",
    "text": "readxl. We will use the readxl package to import Microsoft Excel files.\nhaven. We will use the haven package to import SAS and Stata data sets.",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Importing Binary Files</span>"
    ]
  },
  {
    "objectID": "chapters/importing_binary_files/importing_binary_files.html#importing-microsoft-excel-spreadsheets",
    "href": "chapters/importing_binary_files/importing_binary_files.html#importing-microsoft-excel-spreadsheets",
    "title": "15  Importing Binary Files",
    "section": "15.2 Importing Microsoft Excel spreadsheets",
    "text": "15.2 Importing Microsoft Excel spreadsheets\nWe probably sent data in Microsoft Excel files more than any other file format. Fortunately, the readxl package makes it really easy to import Excel spreadsheets into R. And, because that package is maintained by the same people who create the readr package that you have already seen, we think it’s likely that the readxl package will feel somewhat familiar right from the start.\nWe would be surprised if any of you had never seen an Excel spreadsheet before – they are pretty ubiquitous in the modern world – but we’ll go ahead and show a screenshot of our height and weight data in Excel for the sake of completeness.\n\n\n\n\n\n\n\n\n\nAll we have to do to import this spreadsheet into R as a data frame is passing the path to the excel file to the path argument of the read_excel() function.\nYou may click here to download this file to your computer.\n\nexcel &lt;- read_excel(\"excel.xlsx\")\n\n\nexcel\n\n# A tibble: 4 × 4\n  ID    sex    ht_in wgt_lbs\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 001   Male      71     190\n2 002   Male      69     176\n3 003   Female    64     130\n4 004   Female    65     154\n\n\n👆Here’s what we did above:\n\nWe used readxl’s read_excel() function to import a Microsoft Excel spreadsheet. That spreadsheet was imported as a data frame and we assigned that data frame to the R object called excel.\n\n\n\n\n\n\n\nWarning\n\n\n\nMake sure to always include the file extension in your file paths. For example, using “/excel” instead of “/excel.xlsx” above (i.e., no .xlsx) would have resulted in an error telling you that the filed does not exist.\n\n\nFortunately for us, just passing the Excel file to the read_excel() function like this will usually “just work.” But, let’s go ahead and simulate another situation that is slightly more complex. Once again, we’ve received data from a team that is using Microsoft Excel to capture some study data.\n\n\n\n\n\n\n\n\n\nAs you can see, this data looks very similar to the csv file we previously imported. However, it looks like the study team has done a little more formatting this time. Additionally, they’ve added a couple of columns we haven’t seen before – date of birth and annual household income.\nAs a final little wrinkle, the data for this study is actually the second sheet in this Excel file (also called a workbook). The study team used the first sheet in the workbook as a data dictionary that looks like this:\n\n\n\n\n\n\n\n\n\nOnce again, we will have to deal with some of the formatting that was done in Excel before we can analyze our data in R.\nYou may click here to download this file to your computer.\nWe’ll start by taking a look at the result we get when we try to pass this file to the read_excel() function without changing any of read_excel()’s default values.\n\nexcel &lt;- read_excel(\"excel_complex.xlsx\")\n\nNew names:\n• `` -&gt; `...2`\n• `` -&gt; `...3`\n\n\n\nexcel\n\n# A tibble: 8 × 3\n  `Height and Weight Study\\r\\nData Dictionary` ...2                        ...3 \n  &lt;chr&gt;                                        &lt;chr&gt;                       &lt;chr&gt;\n1 &lt;NA&gt;                                         &lt;NA&gt;                        &lt;NA&gt; \n2 Variable                                     Definition                  Type \n3 Study ID                                     Randomly assigned particip… Cont…\n4 Assigned Sex at Birth                        Sex the participant was as… Dich…\n5 Height (inches)                              Participant's height in in… Cont…\n6 Weight (lbs)                                 Participant's weight in po… Cont…\n7 Date of Birth                                Participant's date of birth Date \n8 Annual Household Income                      Participant's annual house… Cont…\n\n\nAnd, as we’re sure you saw coming, this isn’t the result we wanted. However, we can get the result we wanted by making a few tweaks to the default values of the sheet, col_names, col_types, skip, and na arguments of the read_excel() function.\n\nexcel &lt;- read_excel(\n  path = \"excel_complex.xlsx\",\n  sheet = \"Study Phase 1\",\n  col_names = c(\"id\", \"sex\", \"ht_in\", \"wgt_lbs\", \"dob\", \"income\"),\n  col_types = c(\n    \"text\",\n    \"text\",\n    \"numeric\",\n    \"numeric\",\n    \"date\",\n    \"numeric\",\n    \"skip\"\n  ),\n  skip = 3,\n  na = c(\"\", \"NA\", \"Missing\")\n)\n\n\nexcel\n\n# A tibble: 4 × 6\n  id    sex    ht_in wgt_lbs dob                 income\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dttm&gt;               &lt;dbl&gt;\n1 001   Male      71     190 1981-05-20 00:00:00  46000\n2 002   Male      NA     176 1990-08-16 00:00:00  67000\n3 003   Female    64     130 1980-02-21 00:00:00  49000\n4 004   Female    65      NA 1983-04-12 00:00:00  89000\n\n\nAs we said, the readr package and readxl package were developed by the same people. So, the code above looks similar to the code we used to import the csv file in the previous chapter. Therefore, we’re not going to walk through this code step-by-step. Rather, we’re just going to highlight some of the slight differences.\n\nYou can type ?read_excel into your R console to view the help documentation for this function and follow along with the explanation below.\nThe first argument to the read_excel() function is the path argument. It serves the same purpose as the file argument to read_csv() – it just has a different name.\nThe sheet argument to the read_excel() function tells R which sheet of the Excel workbook contains the data you want to import. In this case, the study team named that sheet “Study Phase 1”. We could have also passed the value 2 to the sheet argument because “Study Phase 1” is the second sheet in the workbook. However, we suggest using the sheet name. That way, if the study team sends you a new Excel file next week with different ordering, you are less likely to accidentally import the wrong data.\nThe value we pass to the col_types argument is now a vector of character strings instead of a list of functions nested in the col() function.\n\nThe values that the col_types function will accept are \"skip\" for telling R to ignore a column in the spreadsheet, \"guess\" for telling R to guess the variable type, \"logical\" for logical (TRUE/FALSE) variables, “numeric” for numeric variables, \"date\" for date variables, \"text\" for character variables, and \"list\" for everything else.\nNotice that we told R to import income as a numeric variable. This caused the commas and dollar signs to be dropped. We did this because keeping the commas and dollar signs would have required us to make income a character variable (numeric variables can only include numbers). If we had imported income as a character variable, we would have lost the ability to perform mathematical operations on it. Remember, it makes no sense to “add” two words together. Later, we will show you how to add dollar signs and commas back to the numeric values if you want to display them in your final results.\n\nWe used the col_names, skip, and na arguments in exactly the same way we used them in the read_csv function.\n\nYou should be able to import most of the data stored in Excel spreadsheets with just the few options that we discussed above. However, there may be times were importing spreadsheets is even more complicated. If you find yourself in that position, we suggest that you first check out the readxl website here.",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Importing Binary Files</span>"
    ]
  },
  {
    "objectID": "chapters/importing_binary_files/importing_binary_files.html#importing-data-from-other-statistical-analysis-software",
    "href": "chapters/importing_binary_files/importing_binary_files.html#importing-data-from-other-statistical-analysis-software",
    "title": "15  Importing Binary Files",
    "section": "15.3 Importing data from other statistical analysis software",
    "text": "15.3 Importing data from other statistical analysis software\nMany applications designed for statistical analysis allow you to save data in a binary format. One reason for this is that binary data formats allow you to save metadata alongside your data values. Metadata is data about the data. Using our running example, the data is about the heights, weights, and other characteristics of our study participants. Metadata about this data might include information like when this data set was created, or value labels that make the data easier to read (e.g., the dollar signs in the income variable).\nIn our experience, you are slightly more likely to have problems importing binary files saved from other statistical analysis applications than plain text files. Perhaps because they are more complex, the data just seems to become corrupt and do other weird things more often than is the case with plain text files. However, in our experience, it is also the case that when we are able to import binary files created in other statistical analysis applications, doing so requires less adjusting of default values. In fact, we will usually only need to pass the file path to the correct read_ function.\nBelow, we will see some examples of importing binary files saved in two popular statistical analysis applications – SAS and Stata. We will use the haven package to import both.",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Importing Binary Files</span>"
    ]
  },
  {
    "objectID": "chapters/importing_binary_files/importing_binary_files.html#importing-sas-data-sets",
    "href": "chapters/importing_binary_files/importing_binary_files.html#importing-sas-data-sets",
    "title": "15  Importing Binary Files",
    "section": "15.4 Importing SAS data sets",
    "text": "15.4 Importing SAS data sets\nSAS actually allows users to save data in more than one type of binary format. Data can be saved as SAS data sets or as SAS Transport files. SAS data set file names end with the .sas7bdat file extension. SAS Transport file file names end with the .xpt file extension.\nIn order to import a SAS data set, we typically only need to pass the correct file path to haven’s read_sas() function.\nYou may click here to download this file to your computer.\n\nsas &lt;- read_sas(\"height_and_weight.sas7bdat\")\n\n\nsas\n\n# A tibble: 4 × 4\n  ID    sex    ht_in wgt_lbs\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 001   Male      71     190\n2 002   Male      69     176\n3 003   Female    64     130\n4 004   Female    65     154\n\n\n👆Here’s what we did above:\n\nWe used haven’s read_sas() function to import a SAS data set. That data was imported as a data frame and we assigned that data frame to the R object called sas.\n\nIn addition to SAS data sets, data that has been altered in SAS can also be saved as a SAS transport file. Some of the national, population-based public health surveys (e.g., BRFSS and NHANES) make their data publicly available in this format.\nYou can download the 2018 BRFSS data as a SAS Transport file here. About halfway down the webpage, there is a link that says, “2018 BRFSS Data (SAS Transport Format)”.\n\n\n\n\n\n\n\n\n\nClicking that link should download the data to your computer. Notice that the SAS Transport file is actually stored inside a zip file. You can unzip the file first if you would like, but you don’t even have to do that. Amazingly, you can pass the path to the zipped .xpt file directly to the read_xpt() function like so:\n\nbrfss_2018 &lt;- read_xpt(\"LLCP2018XPT.zip\")\n\n\nhead(brfss_2018)\n\n# A tibble: 6 × 275\n  `_STATE` FMONTH IDATE    IMONTH IDAY  IYEAR DISPCODE SEQNO     `_PSU` CTELENM1\n     &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n1        1      1 01052018 01     05    2018      1100 20180000… 2.02e9        1\n2        1      1 01122018 01     12    2018      1100 20180000… 2.02e9        1\n3        1      1 01082018 01     08    2018      1100 20180000… 2.02e9        1\n4        1      1 01032018 01     03    2018      1100 20180000… 2.02e9        1\n5        1      1 01122018 01     12    2018      1100 20180000… 2.02e9        1\n6        1      1 01112018 01     11    2018      1100 20180000… 2.02e9        1\n# ℹ 265 more variables: PVTRESD1 &lt;dbl&gt;, COLGHOUS &lt;dbl&gt;, STATERE1 &lt;dbl&gt;,\n#   CELLFON4 &lt;dbl&gt;, LADULT &lt;dbl&gt;, NUMADULT &lt;dbl&gt;, NUMMEN &lt;dbl&gt;, NUMWOMEN &lt;dbl&gt;,\n#   SAFETIME &lt;dbl&gt;, CTELNUM1 &lt;dbl&gt;, CELLFON5 &lt;dbl&gt;, CADULT &lt;dbl&gt;,\n#   PVTRESD3 &lt;dbl&gt;, CCLGHOUS &lt;dbl&gt;, CSTATE1 &lt;dbl&gt;, LANDLINE &lt;dbl&gt;,\n#   HHADULT &lt;dbl&gt;, GENHLTH &lt;dbl&gt;, PHYSHLTH &lt;dbl&gt;, MENTHLTH &lt;dbl&gt;,\n#   POORHLTH &lt;dbl&gt;, HLTHPLN1 &lt;dbl&gt;, PERSDOC2 &lt;dbl&gt;, MEDCOST &lt;dbl&gt;,\n#   CHECKUP1 &lt;dbl&gt;, EXERANY2 &lt;dbl&gt;, SLEPTIM1 &lt;dbl&gt;, CVDINFR4 &lt;dbl&gt;, …\n\n\n👆Here’s what we did above:\n\nWe used haven’s read_xpt() function to import a zipped SAS Transport File. That data was imported as a data frame and we assigned that data frame to the R object called brfss_2018.\nBecause this is a large data frame (437,436 observations and 275 variables), we used the head() function to print only the first 6 rows of the data to the screen.\n\nBut, this demonstration actually gets even cooler. Instead of downloading the SAS Transport file to our computer before importing it, we can actually sometimes import files, including SAS Transport files, directly from the internet.\nFor example, you can download the 2017-2018 NHANES demographic data as a SAS Transport file here\n\n\n\n\n\n\n\n\n\nIf you right-click on the link that says, “DEMO_I Data [XPT - 3.3 MB]”, you will see an option to copy the link address.\n\n\n\n\n\n\n\n\n\nClick “Copy Link Address” and then navigate back to RStudio. Now, all you have to do is paste that link address where you would normally type a file path into the read_xpt() function. When you run the code chunk, the read_xpt() function will import the NHANES data directly from the internet (assuming you are connected to the internet). 😲\n\nnhanes_demo &lt;- read_xpt(\"https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/DEMO_J.XPT\")\n\n\nhead(nhanes_demo)\n\n# A tibble: 6 × 46\n   SEQN SDDSRVYR RIDSTATR RIAGENDR RIDAGEYR RIDAGEMN RIDRETH1 RIDRETH3 RIDEXMON\n  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 93703       10        2        2        2       NA        5        6        2\n2 93704       10        2        1        2       NA        3        3        1\n3 93705       10        2        2       66       NA        4        4        2\n4 93706       10        2        1       18       NA        5        6        2\n5 93707       10        2        1       13       NA        5        7        2\n6 93708       10        2        2       66       NA        5        6        2\n# ℹ 37 more variables: RIDEXAGM &lt;dbl&gt;, DMQMILIZ &lt;dbl&gt;, DMQADFC &lt;dbl&gt;,\n#   DMDBORN4 &lt;dbl&gt;, DMDCITZN &lt;dbl&gt;, DMDYRSUS &lt;dbl&gt;, DMDEDUC3 &lt;dbl&gt;,\n#   DMDEDUC2 &lt;dbl&gt;, DMDMARTL &lt;dbl&gt;, RIDEXPRG &lt;dbl&gt;, SIALANG &lt;dbl&gt;,\n#   SIAPROXY &lt;dbl&gt;, SIAINTRP &lt;dbl&gt;, FIALANG &lt;dbl&gt;, FIAPROXY &lt;dbl&gt;,\n#   FIAINTRP &lt;dbl&gt;, MIALANG &lt;dbl&gt;, MIAPROXY &lt;dbl&gt;, MIAINTRP &lt;dbl&gt;,\n#   AIALANGA &lt;dbl&gt;, DMDHHSIZ &lt;dbl&gt;, DMDFMSIZ &lt;dbl&gt;, DMDHHSZA &lt;dbl&gt;,\n#   DMDHHSZB &lt;dbl&gt;, DMDHHSZE &lt;dbl&gt;, DMDHRGND &lt;dbl&gt;, DMDHRAGZ &lt;dbl&gt;, …\n\n\n👆Here’s what we did above:\n\nWe used haven’s read_xpt() function to import a SAS Transport File directly from the NHANES website. That data was imported as a data frame and we assigned that data frame to the R object called nhanes_demo.\nBecause this is a large data frame (9,254 observations and 46 variables), we used the head() function to print only the first 6 rows of the data to the screen.",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Importing Binary Files</span>"
    ]
  },
  {
    "objectID": "chapters/importing_binary_files/importing_binary_files.html#importing-stata-data-sets",
    "href": "chapters/importing_binary_files/importing_binary_files.html#importing-stata-data-sets",
    "title": "15  Importing Binary Files",
    "section": "15.5 Importing Stata data sets",
    "text": "15.5 Importing Stata data sets\nFinally, we will import a Stata data set (.dta) to round out our discussion of importing data from other statistical analysis software packages. There isn’t much of anything new here – you could probably have even guessed how to do this without us showing you.\nYou may click here to download this file to your computer.\n\nstata &lt;- read_stata(\"height_and_weight.dta\")\n\n\nstata\n\n# A tibble: 4 × 4\n  ID    sex    ht_in wgt_lbs\n  &lt;chr&gt; &lt;chr&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1 001   Male      71     190\n2 002   Male      69     176\n3 003   Female    64     130\n4 004   Female    65     154\n\n\n👆Here’s what we did above:\n\nWe used haven’s read_stata() function to import a Stata data set. That data was imported as a data frame and we assigned that data frame to the R object called stata.\n\nYou now know how to write code that will allow you to import data stored in all of the file formats that we will use in this book, and the vast majority of formats that you are likely to encounter in your real-world projects. In the next section, We will introduce you to a tool in RStudio that makes importing data even easier.",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Importing Binary Files</span>"
    ]
  },
  {
    "objectID": "chapters/rstudio_import_tool/rstudio_import_tool.html",
    "href": "chapters/rstudio_import_tool/rstudio_import_tool.html",
    "title": "16  RStudio’s Data Import Tool",
    "section": "",
    "text": "In previous chapters, we learned how to programmatically import data into R. In this chapter, we will briefly introduce you to RStudio’s data import tool. Conceptually, we won’t be introducing anything you haven’t already seen before. We just want to make you aware of this tool, which can be a welcomed convenience at times.\nFor this example, we will use the import tool to help us import the same height and weight csv file we imported in the chapter on importing plain text files.\nYou may click here to download this file to your compter.\nTo open RStudio’s data import tool, click the Import Dataset dropdown menu near the top of the environment pane.\n\n\n\n\n\n\n\n\n\nNext, because this is a csv file, we will choose the From Text (readr) option from the dropdown menu. The difference between From Text (base) and From Text (readr) is that From Text (readr) will use functions from the readr package to import the data and From Text (base) will use base R functions to import the data.\n\n\n\n\n\n\n\n\n\nAfter you select a file type from the import tool dropdown menu, a separate data import window will open.\n\n\n\n\n\n\n\n\n\nAt this point, you should click the browse button to locate the file you want to import.\n\n\n\n\n\n\n\n\n\nDoing so will open your operating system’s file explorer window. Use that window to find and select the file you want to import. Again, we am using comma.csv for this demonstration.\n\n\n\n\n\n\n\n\n\nAfter selecting you file, there will be some changes in the data import window. Specifically,\n\nThe file path to the raw data you are importing will appear in the File/URL field.\nA preview of how R is currently parsing that data will appear in the Data Preview field.\nSome or all of the import options will become available for you to select or deselect.\nThe underlying code that R is currently using to import this data is displayed in the Code Preview window.\nThe copy to clipboard icon becomes clickable.\n\n\n\n\n\n\n\n\n\n\nImporting this simple data set doesn’t require us to alter many of the import options. However, we do want to point out that you can change the variable type by clicking in the column headers in the Data Preview field. After clicking, a dropdown menu will display that allows you to change variable types. This is equivalent to adjusting the default values passed to the col_types argument of the read_csv() function.\nWe will go ahead and change the ht_in and wgt_lbs variables from type double to type integer using the dropdown menu.\n\n\n\n\n\n\n\n\n\nAt this point, our data is ready for import. You can simply press the Import button in the bottom-right corner of the data import window. However, we are going to suggest that you don’t do that. Instead, we’re going to suggest that you click the clipboard icon to copy the code displayed in the Code Preview window and then click the Cancel button.\nNext, return to your R script or Quarto file and paste the code that was copied to your clipboard. At this point, you can run the code as though you wrote it. More importantly, this code is now a part of the record of how you conducted your data analysis. Further, if someone sends you an updated raw data set, you may only need to update the file path in your code instead of clicking around the data import tool again.\n\n\n\n\n\n\n\n\n\nThat concludes the portion of the book devoted to importing data. In the next chapter, we will discuss strategies for exporting data so that you can store it in a more long-term way and/or share it with others.",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>RStudio's Data Import Tool</span>"
    ]
  },
  {
    "objectID": "chapters/exporting_data_to_disk/exporting_data_to_disk.html",
    "href": "chapters/exporting_data_to_disk/exporting_data_to_disk.html",
    "title": "17  Exporting Data",
    "section": "",
    "text": "17.1 Plain text files\nMost of readr’s read_ functions that were introduced in the importing plain text files chapter have a write_ counterpart that allow you to export data from R into a plain text file.\nAdditionally, all of havens read_ functions that were introduced in the importing binary files chapter have a write_ counterpart that allow you to export data from R into SAS, Stata, and SPSS binary file formats.\nInterestingly, readxl does not have a write_excel() function for exporting R data frames as .xls or .xlsx files. However, the importance of this is mitigated by the fact that Excel can open .csv files and readr contains a function (write_csv())for exporting data frames in the .csv file format. If you absolutely have to export your data frame as a .xls or .xlsx file, there are other R packages capable of doing so (e.g., xlsx).\nSo, with all these options what format should you choose? our answer to this sort of depends on the answers to two questions. First, will this data be shared with anyone else? Second, will we need any of the metadata that would be lost if we export this data to a plain text file?\nUnless you have a compelling reason to do otherwise, we’re going to suggest that you always export your R data frames as csv files if you plan to share your data with others. The reason is simple. They just work. we can think of many times when someone sent me a SAS or Stata data set and we wasn’t able to import it for some reason or the data didn’t import in the way that we expected it to. we don’t recall ever having that experience with a csv file. Further, every operating system and statistical analysis software application that we’re aware of is able to accept csv files. Perhaps for that reason, they have become the closest thing to a standard for data sharing that exists – at least that we’re aware of.\nExporting an R data frame to a csv file is really easy. The example below shows how to export our simulated demographic data to a csv file on our computer’s desktop:\nreadr::write_csv(demo, \"demo.csv\")\n👆Here’s what we did above:\nEven if you don’t plan on sharing your data, there is another benefit to saving your data as a csv file. That is, it’s easy to open the file and take a quick peek if you need to for some reason. You don’t have to open R and load the file. You can just find the file on your computer, double-click it, and quickly view it in your text editor or spreadsheet application of choice.\nHowever, there is a downside to saving your data frames to a csv file. In general, csv files don’t store any metadata, which can sometimes be a problem (or a least a pain). For example, if you’ve coerced several variables to factors, that information would not be preserved in the csv file. Instead, the factors will be converted to character strings. If you need to preserve metadata, then you may want to save you data frames in a binary format.",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Exporting Data</span>"
    ]
  },
  {
    "objectID": "chapters/exporting_data_to_disk/exporting_data_to_disk.html#plain-text-files",
    "href": "chapters/exporting_data_to_disk/exporting_data_to_disk.html#plain-text-files",
    "title": "17  Exporting Data",
    "section": "",
    "text": "We used readr’s write_csv() function to export a data frame called demo in our global environment to a csv file on our desktop called demo.csv.\nYou can type ?write_csv into your R console to view the help documentation for this function and follow along with the explanation below.\nThe first argument to the write_csv() function is the x argument. The value passed to the x argument should be a data frame that is currently in our global environment.\nThe second argument to the write_csv() function is the path argument. The value passed to the path should be a file path telling R where to create the new csv file.\n\nYou name the csv file directly in the file path. Whatever name you write after the final slash in the file path is what the csv file will be named.\nAs always, make sure you remember to include the file extension in the file path.",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Exporting Data</span>"
    ]
  },
  {
    "objectID": "chapters/exporting_data_to_disk/exporting_data_to_disk.html#r-binary-files",
    "href": "chapters/exporting_data_to_disk/exporting_data_to_disk.html#r-binary-files",
    "title": "17  Exporting Data",
    "section": "17.2 R binary files",
    "text": "17.2 R binary files\nIn the chapter on importing binary files we mentioned that most statistical analysis software allows you to save your data in a binary file format. The primary advantage to doing so is that potentially useful metadata is stored alongside your analysis data. We were first introduced to factor vectors in [Let’s Get Programming] chapter. There, we saw how coercing some of your variables to factors can be useful. However, doing so requires R to store metadata along with the analysis data. That metadata would be lost if you were to export your data frame to a plain text file. This is an example of a time when we may want to consider exporting our data to a binary file format.\nR actually allows you to save your data in multiple different binary file formats. The two most popular are the .Rdata format and the .Rds format. we’re going to suggest that you use the .Rds format to save your R data frames. Exporting to this format is really easy with the readr package.\nThe example below shows how to export our simulated demographic data to an .Rds file on our computer’s desktop:\n\nreadr::write_rds(demo, \"demo.rds\")\n\n👆Here’s what we did above:\n\nWe used readr’s write_rds() function to export a data frame called demo in our globabl environment to an .Rds file on our desktop called demo.rds.\nYou can type ?write_rds into your R console to view the help documentation for this function and follow along with the explanation below.\nThe first argument to the write_rds() function is the x argument. The value passed to the x argument should be a data frame that is currently in our global environment.\nThe second argument to the write_csv() function is the path argument. The value passed to the path should be a file path telling R where to create the new .Rds file.\n\nYou name the .Rds file directly in the file path. Whatever name you write after the final slash in the file path is what the .Rds file will be named.\nAs always, make sure you remember to include the file extension in the file path.\n\n\nTo load the .Rds data back into your global environment, simply pass the path to the .Rds file to readrs read_rds() function:\n\n\ndemo &lt;- readr::read_rds(\"demo.rds\")\n\nThere is a final thought we want to share on exporting data frames. When we got to the end of this chapter, it occurred to me that the way we wrote it may give the impression that that you must choose to export data frames as plain text files or binary files, but not both. That isn’t the case. we frequently export our data as a csv file that we can easily open and view and/or share with others, but also export it to an .Rds file that retains useful metadata we might need the next time we return to our analysis. we suppose there could be times that your files are so large that this is not an efficient strategy, but that is generally not the case in our projects.",
    "crumbs": [
      "Data Transfer",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Exporting Data</span>"
    ]
  },
  {
    "objectID": "chapters/intro_descriptive_analysis/intro_descriptive_analysis.html",
    "href": "chapters/intro_descriptive_analysis/intro_descriptive_analysis.html",
    "title": "18  Introduction to Descriptive Analysis",
    "section": "",
    "text": "18.1 What is descriptive analysis and why would we do it?\nSo, we have all this data that tells us all this information about different traits or characteristics of the people for whom the data was collected. For example, if we collected data about the students in this course, we may have information about how tall you are, about what kind of insurance you have, and about what your favorite color is.\nstudent_id\nheight_in\ninsurance\ncolor\n\n\n\n\n1001\n64.96\nprivate\nblue\n\n\n1002\n67.93\nother\nyellow\n\n\n1003\n84.03\nnone\nred\nBut, unless you’re a celebrity, or under investigation for some reason, it’s unlikely that many people outside of your friends and family care to know any of this information about you, per se. Usually they want to know this information about the typical person in the population, or subpopulation, to which you belong. Or, they want to know more about the relationship between people who are like you in some way and some outcome that they are interested in.\nFor example: We typically aren’t interested in knowing that student 1002 (above) is 67.93 inches tall. We are typically more interested in knowing things like the average height of the class – [’r mean(height_in) |&gt; round(2)].\nBefore we can make any inferences or draw any conclusions, we must (or at least should) begin by conducting descriptive analysis of our data. This is also sometimes referred to as exploratory analysis. There are at least three reasons why we want to start with a descriptive analysis:",
    "crumbs": [
      "Descriptive Analysis",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Introduction to Descriptive Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/intro_descriptive_analysis/intro_descriptive_analysis.html#what-is-descriptive-analysis-and-why-would-we-do-it",
    "href": "chapters/intro_descriptive_analysis/intro_descriptive_analysis.html#what-is-descriptive-analysis-and-why-would-we-do-it",
    "title": "18  Introduction to Descriptive Analysis",
    "section": "",
    "text": "We can use descriptive analysis to uncover errors in our data.\n\nIt helps us understand the distribution of values in our variables.\n\nDescriptive analysis serve as a starting point for understanding relationships between our variables.",
    "crumbs": [
      "Descriptive Analysis",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Introduction to Descriptive Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/intro_descriptive_analysis/intro_descriptive_analysis.html#what-kind-of-descriptive-analysis-should-we-perform",
    "href": "chapters/intro_descriptive_analysis/intro_descriptive_analysis.html#what-kind-of-descriptive-analysis-should-we-perform",
    "title": "18  Introduction to Descriptive Analysis",
    "section": "18.2 What kind of descriptive analysis should we perform?",
    "text": "18.2 What kind of descriptive analysis should we perform?\nWhen conducting descriptive analysis, the method you choose will depend on the type of data you’re analyzing. At the most basic level, variables can be described as numerical or categorical.\n\n\n\n\n\n\n\n\n\nNumeric variables can then be further divided into continuous and discrete - the distinction being whether the variable can take on a continuum of values, or only set of certain values.\n\n\n\n\n\n\n\n\n\nCategorical variables can be subdivided into ordinal or nominal variables - depending on whether or not the categories can logically be ordered in a meaningful way.\n\n\n\n\n\n\n\n\n\nFinally, for all types, and subtypes, of variables there are both numerical and graphical methods we can use for descriptive analysis.\n\n\n\n\n\n\n\n\n\nIn the exercises that follow you will be introduced to measures of frequency, measures of central tendency, and measures of dispersion. Then, you’ll learn various methods for estimating and interpreting these measures using R.",
    "crumbs": [
      "Descriptive Analysis",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Introduction to Descriptive Analysis</span>"
    ]
  },
  {
    "objectID": "chapters/categorical_variables/categorical_variables.html",
    "href": "chapters/categorical_variables/categorical_variables.html",
    "title": "19  Numerical Descriptions of Categorical Variables",
    "section": "",
    "text": "19.1 Factors\nWe first learned about factors in the Let’s Get Programming chapter. Before moving on to calculating frequency counts and percentages, we will discuss factors in slightly greater depth here. As a reminder, factors can be useful for representing categorical data in R. To demonstrate, let’s simulate a simple little data frame.\n# Load dplyr for tibble()\nlibrary(dplyr)\ndemo &lt;- tibble(\n  id  = c(\"001\", \"002\", \"003\", \"004\"),\n  age = c(30, 67, 52, 56),\n  edu = c(3, 1, 4, 2)\n)\n👆 Here’s what we did above:\nEach participant in our data frame has a value for edu – 1, 2, 3, or 4. The value they have for that variable corresponds to the highest level of formal education they have completed, which is split up into categories that we defined. We can see which category each person is in by viewing the data.\ndemo\n\n# A tibble: 4 × 3\n  id      age   edu\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 001      30     3\n2 002      67     1\n3 003      52     4\n4 004      56     2\nWe can see that person 001 is in category 3, person 002 is in category 1, and so on. This compact representation of the categories is convenient for data entry and data manipulation, but it also has an obvious limitation – what do these numbers mean? We defined what these values mean for you above, but if you didn’t have that information, or some kind of prior knowledge about the process that was used to gather this data, then you would likely have no idea what these numbers mean.\nNow, we could have solved that problem by making education a character vector from the beginning. For example:\ndemo &lt;- tibble(\n  id       = c(\"001\", \"002\", \"003\", \"004\"),\n  age      = c(30, 67, 52, 56),\n  edu      = c(3, 1, 4, 2),\n  edu_char = c(\n    \"Some college\", \"Less than high school\", \"College graduate\", \n    \"High school graduate\"\n  )\n)\n\ndemo\n\n# A tibble: 4 × 4\n  id      age   edu edu_char             \n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                \n1 001      30     3 Some college         \n2 002      67     1 Less than high school\n3 003      52     4 College graduate     \n4 004      56     2 High school graduate\nBut, this strategy also has a few limitations.\n👎 First, entering data this way requires more typing. Not such a big deal in this case because we only have 4 participants. But, imagine typing out the categories as character strings 10, 20, or 100 times. 😫\n👎 Second, R summarizes character vectors alphabetically by default, which may not be the ideal way to order some categorical variables.\n👎 Third, creating categorical variables in our data frame as character vectors limits us to inputting only observed values for that variable. However, there are cases when other categories are possible and just didn’t apply to anyone in our data. That information may be useful to know.\nAt this point, we’re going to show you how to coerce a variable to a factor in your data frame. Then, we will return to showing you how using factors can overcome some of the limitations outlined above.",
    "crumbs": [
      "Descriptive Analysis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Numerical Descriptions of Categorical Variables</span>"
    ]
  },
  {
    "objectID": "chapters/categorical_variables/categorical_variables.html#factors",
    "href": "chapters/categorical_variables/categorical_variables.html#factors",
    "title": "19  Numerical Descriptions of Categorical Variables",
    "section": "",
    "text": "We created a data frame that is meant to simulate some demographic information about 4 hypothetical study participants.\nThe first variable (id) is the participant’s study id.\nThe second variable (age) is the participant’s age at enrollment in the study.\nThe third variable (edu) is the highest level of formal education the participant completed. Where:\n\n1 = Less than high school\n2 = High school graduate\n3 = Some college\n4 = College graduate\n\n\n\n\n\n\n\n\n\n\n\n\n\n19.1.1 Coerce a numeric variable\nThe code below shows one method for coercing a numeric vector into a factor.\n\n# Load dplyr for pipes and mutate()\nlibrary(dplyr)\n\n\ndemo &lt;- demo |&gt; \n  mutate(\n    edu_f = factor(\n      x      = edu,\n      levels = 1:4,\n      labels = c(\n        \"Less than high school\", \"High school graduate\", \"Some college\", \n        \"College graduate\"\n      )\n    )\n  )\n\ndemo\n\n# A tibble: 4 × 5\n  id      age   edu edu_char              edu_f                \n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                 &lt;fct&gt;                \n1 001      30     3 Some college          Some college         \n2 002      67     1 Less than high school Less than high school\n3 003      52     4 College graduate      College graduate     \n4 004      56     2 High school graduate  High school graduate \n\n\n👆Here’s what we did above:\n\nWe used dplyr’s mutate() function to create a new variable (edu_f) in the data frame called demo. The purpose of the mutate() function is to add new variables to data frames. We will discuss mutate() in greater detail in the [later in the book][creating and modifying columns].\n\nYou can type ?mutate into your R console to view the help documentation for this function and follow along with the explanation below.\nWe assigned this new data frame the name demo using the assignment operator (&lt;-).\nBecause we assigned it the name demo, our previous data frame named demo (i.e., the one that didn’t include edu_f) no longer exists in our global environment. If we had wanted to keep that data frame in our global environment, we would have needed to assign our new data frame a different name (e.g., demo_w_factor).\n\nThe first argument to the mutate() function is the .data argument. The value passed to the .data argument should be a data frame that is currently in our global environment. We passed the data frame demo to the .data argument using the pipe operator (|&gt;), which is why demo isn’t written inside mutate’s parentheses.\nThe second argument to the mutate() function is the ... argument. The value passed to the ... argument should be a name value pair. That means, a variable name, followed by an equal sign, followed by the values to be assigned to that variable name (name = value).\n\nThe name we passed to the ... argument was edu_f. This value tells R what to name the new variable we are creating.\n\nIf we had used the name edu instead, then the previous values in the edu variable would have been replaced with the new values. That is sometimes what you want to happen. However, when it comes to creating factors, we typically keep the numeric version of the variable in our data frame (e.g., edu) and add a new factor variable. We just often find that it can be useful to have both versions of the variable hanging around during the analysis process.\nWe also use the _f naming convention in our code. That means that when we create a new factor variable we name it the same thing the original variable was named with the addition of _f (for factor) at the end.\n\nIn this case, the value that will be assigned to the name edu_f will be the values returned by the factor() function. This is an example of nesting functions.\n\nWe used the factor() function to create a factor vector.\n\nYou can type ?factor into your R console to view the help documentation for this function and follow along with the explanation below.\nThe first argument to the factor() function is the x argument. The value passed to the x argument should be a vector of data. We passed the edu vector to the x argument.\nThe second argument to the factor() function is the levels argument. This argument tells R the unique values that the new factor variable can take. We used the shorthand 1:4 to tell R that edu_f can take the unique values 1, 2, 3, or 4.\nThe third argument to the factor() function is the labels argument. The value passed to the labels argument should be a character vector of labels (i.e., descriptive text) for each value in the levels argument. The order of the labels in the character vector we pass to the labels argument should match the order of the values passed to the levels argument. For example, the ordering of levels and labels above tells R that 1 should be labeled with “Less than high school”, 2 should be labeled with “High school graduate”, etc.\n\n\nWhen we printed the data frame above, the values in edu_f looked the same as the character strings displayed in edu_char. Notice, however, that the variable type displayed below edu_char in the data frame above is &lt;chr&gt; for character. Alternatively, the variable type displayed below edu_f is &lt;fctr&gt;. Although, labels are used to make factors look like character vectors, they are still integer vectors under the hood. For example:\n\nas.numeric(demo$edu_char)\n\nWarning: NAs introduced by coercion\n\n\n[1] NA NA NA NA\n\n\n\nas.numeric(demo$edu_f)\n\n[1] 3 1 4 2\n\n\nThere are two main reasons that you may want to use factors instead of character vectors at times:\n👍 First, R summarizes character vectors alphabetically by default, which may not be the ideal way to order some categorical variables. However, we can explicitly set the order of factor levels. This will be useful to us later when we analyze categorical variables. Here is a glimpse of things to come:\n\ntable(demo$edu_char)\n\n\n     College graduate  High school graduate Less than high school \n                    1                     1                     1 \n         Some college \n                    1 \n\n\n\ntable(demo$edu_f)\n\n\nLess than high school  High school graduate          Some college \n                    1                     1                     1 \n     College graduate \n                    1 \n\n\n👆Here’s what we did above:\n\nYou can type ?base::table into your R console to view the help documentation for this function and follow along with the explanation below.\nWe used the table() function to get a count of the number of times each unique value of edu_char appears in our data frame. In this case, each value appears one time. Notice that the results are returned to us in alphabetical order.\nNext, we used the table() function to get a count of the number of times each unique value of edu_f appears in our data frame. Again, each value appears one time. Notice, however, that this time the results are returned to us in the order that we passed to the levels argument of the factor() function above.\n\n👍 Second, creating categorical variables in our data frame as character vectors limits us to inputting only observed values for that variable. However, there are cases when other categories are possible and just didn’t apply to anyone in our data. That information may be useful to know. Factors allow us to tell R that other values are possible, even when they are unobserved in our data. For example, let’s add a fifth possible category to our education variable – graduate school.\n\ndemo &lt;- demo |&gt; \n  mutate(\n    edu_5cat_f = factor(\n      x      = edu,\n      levels = 1:5,\n      labels = c(\n        \"Less than high school\", \"High school graduate\", \"Some college\", \n        \"College graduate\", \"Graduate school\"\n      )\n    )\n  )\n\ndemo\n\n# A tibble: 4 × 6\n  id      age   edu edu_char              edu_f                 edu_5cat_f      \n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                 &lt;fct&gt;                 &lt;fct&gt;           \n1 001      30     3 Some college          Some college          Some college    \n2 002      67     1 Less than high school Less than high school Less than high …\n3 003      52     4 College graduate      College graduate      College graduate\n4 004      56     2 High school graduate  High school graduate  High school gra…\n\n\nNow, let’s use the table() function once again to count the number of times each unique level of edu_char appears in the data frame and the number of times each unique level of edu_5cat_f appears in the data frame:\n\ntable(demo$edu_char)\n\n\n     College graduate  High school graduate Less than high school \n                    1                     1                     1 \n         Some college \n                    1 \n\n\n\ntable(demo$edu_5cat_f)\n\n\nLess than high school  High school graduate          Some college \n                    1                     1                     1 \n     College graduate       Graduate school \n                    1                     0 \n\n\nNotice that R now tells us that the value Graduate school was possible but was observed zero times in the data.\n\n\n19.1.2 Coerce a character variable\nIt is also possible to coerce character vectors to factors. For example, we can coerce edu_char to a factor like so:\n\ndemo &lt;- demo |&gt; \n  mutate(\n    edu_f_from_char = factor(\n      x      = edu_char,\n      levels = c(\n        \"Less than high school\", \"High school graduate\", \"Some college\", \n        \"College graduate\", \"Graduate school\"\n      )\n    )\n  )\n\ndemo\n\n# A tibble: 4 × 7\n  id      age   edu edu_char              edu_f       edu_5cat_f edu_f_from_char\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                 &lt;fct&gt;       &lt;fct&gt;      &lt;fct&gt;          \n1 001      30     3 Some college          Some colle… Some coll… Some college   \n2 002      67     1 Less than high school Less than … Less than… Less than high…\n3 003      52     4 College graduate      College gr… College g… College gradua…\n4 004      56     2 High school graduate  High schoo… High scho… High school gr…\n\n\n\ntable(demo$edu_f_from_char)\n\n\nLess than high school  High school graduate          Some college \n                    1                     1                     1 \n     College graduate       Graduate school \n                    1                     0 \n\n\n👆Here’s what we did above:\n\nWe coerced a character vector (edu_char) to a factor using the factor() function.\nBecause the levels are character strings, there was no need to pass any values to the labels argument this time. Keep in mind, though, that the order of the values passed to the levels argument matters. It will be the order that the factor levels will be displayed in your analyses.\n\nNow that we know how to use factors, let’s return to our discussion of describing categorical variables.",
    "crumbs": [
      "Descriptive Analysis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Numerical Descriptions of Categorical Variables</span>"
    ]
  },
  {
    "objectID": "chapters/categorical_variables/categorical_variables.html#height-and-weight-data",
    "href": "chapters/categorical_variables/categorical_variables.html#height-and-weight-data",
    "title": "19  Numerical Descriptions of Categorical Variables",
    "section": "19.2 Height and Weight Data",
    "text": "19.2 Height and Weight Data\nBelow, we’re going to learn to do descriptive analysis in R by experimenting with some simulated data that contains several people’s sex, height, and weight. You can follow along with this lesson by copying and pasting the code chunks below in your R session.\n\n# Load the dplyr package. We will need several of dplyr's functions in the \n# code below.\nlibrary(dplyr)\n\n\n# Simulate some data\nheight_and_weight_20 &lt;- tibble(\n  id = c(\n    \"001\", \"002\", \"003\", \"004\", \"005\", \"006\", \"007\", \"008\", \"009\", \"010\", \"011\", \n    \"012\", \"013\", \"014\", \"015\", \"016\", \"017\", \"018\", \"019\", \"020\"\n  ),\n  sex = c(1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 2),\n  sex_f = factor(sex, 1:2, c(\"Male\", \"Female\")),\n  ht_in = c(\n    71, 69, 64, 65, 73, 69, 68, 73, 71, 66, 71, 69, 66, 68, 75, 69, 66, 65, 65, \n    65\n  ),\n  wt_lbs = c(\n    190, 176, 130, 154, 173, 182, 140, 185, 157, 155, 213, 151, 147, 196, 212, \n    190, 194, 176, 176, 102\n  )\n)\n\n\n19.2.1 View the data\nLet’s start our analysis by taking a quick look at our data…\n\nheight_and_weight_20\n\n# A tibble: 20 × 5\n   id      sex sex_f  ht_in wt_lbs\n   &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 001       1 Male      71    190\n 2 002       1 Male      69    176\n 3 003       2 Female    64    130\n 4 004       2 Female    65    154\n 5 005       1 Male      73    173\n 6 006       1 Male      69    182\n 7 007       2 Female    68    140\n 8 008       1 Male      73    185\n 9 009       2 Female    71    157\n10 010       1 Male      66    155\n11 011       1 Male      71    213\n12 012       2 Female    69    151\n13 013       2 Female    66    147\n14 014       2 Female    68    196\n15 015       1 Male      75    212\n16 016       2 Female    69    190\n17 017       2 Female    66    194\n18 018       2 Female    65    176\n19 019       2 Female    65    176\n20 020       2 Female    65    102\n\n\n👆Here’s what we did above:\n\nSimulated some data that we can use to practice categorical data analysis.\nWe viewed the data and found that it has 5 variables (columns) and 20 observations (rows).\nAlso notice that you can use the “Next” button at the bottom right corner of the printed data frame to view rows 11 through 20 if you are viewing this data in RStudio.",
    "crumbs": [
      "Descriptive Analysis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Numerical Descriptions of Categorical Variables</span>"
    ]
  },
  {
    "objectID": "chapters/categorical_variables/categorical_variables.html#calculating-frequencies",
    "href": "chapters/categorical_variables/categorical_variables.html#calculating-frequencies",
    "title": "19  Numerical Descriptions of Categorical Variables",
    "section": "19.3 Calculating frequencies",
    "text": "19.3 Calculating frequencies\nNow that we’re able to easily view our data, let’s return to the original purpose of this demonstration – calculating frequencies and proportions. At this point, we suspect that few of you would have any trouble telling me that the frequency of females in this data is 12 and the frequency of males in this data is 8. It’s pretty easy to just count the number of females and males in this small data set with only 20 rows. Further, if we asked you what proportion of this sample is female, most of you would still be able to easily tell me 12/20 = 0.6, or 60%. But, what if we had 100 observations or 1,000,000 observations? You’d get sick of counting pretty quickly. Fortunately, you don’t have to! Let R do it for you! As is almost always the case with R, there are multiple ways we can calculate the statistics that we’re interested in.\n\n19.3.1 The base R table function\nAs we already saw above, we can use the base R table() function like this:\n\ntable(height_and_weight_20$sex)\n\n\n 1  2 \n 8 12 \n\n\nAdditionally, we can use the CrossTable() function from the gmodels package, which gives us a little more information by default.\n\n\n19.3.2 The gmodels CrossTable function\n\n# Like all packages, you will have to install gmodels (install.packages(\"gmodels\")) before you can use the CrossTable() function. \ngmodels::CrossTable(height_and_weight_20$sex)\n\n\n \n   Cell Contents\n|-------------------------|\n|                       N |\n|         N / Table Total |\n|-------------------------|\n\n \nTotal Observations in Table:  20 \n\n \n          |         1 |         2 | \n          |-----------|-----------|\n          |         8 |        12 | \n          |     0.400 |     0.600 | \n          |-----------|-----------|\n\n\n\n \n\n\n\n\n19.3.3 The tidyverse way\nThe final way we’re going to discuss here is the tidyverse way, which is our preference. We will have to write a little additional code, but the end result will be more flexible, more readable, and will return our statistics to us in a data frame that we can save and use for further analysis. Let’s walk through this step by step…\n\n\n\n\n\n\nNote\n\n\n\n🗒Side Note: You should already be familiar with the pipe operator (|&gt;), but if it doesn’t look familiar to you, you can learn more about it in [Using pipes]. Don’t forget, if you are using RStudio, you can use the keyboard shortcut shift + command + m (Mac) or shift + control + m (Windows) to insert the pipe operator.\n\n\nFirst, we don’t want to view the individual values in our data frame. Instead, we want to condense those values into summary statistics. This is a job for the summarise() function.\n\nheight_and_weight_20 |&gt; \n  summarise()\n\n# A tibble: 1 × 0\n\n\nAs you can see, summarise() doesn’t do anything interesting on its own. We need to tell it what kind of summary information we want. We can use the n() function to count rows. By default, it will count all the rows in the data frame. For example:\n\nheight_and_weight_20 |&gt; \n  summarise(n())\n\n# A tibble: 1 × 1\n  `n()`\n  &lt;int&gt;\n1    20\n\n\n👆Here’s what we did above:\n\nWe passed our entire data frame to the summarise() function and asked it to count the number of rows in the data frame.\nThe result we get is a new data frame with 1 column (named n()) and one row with the value 20 (the number of rows in the original data frame).\n\nThis is a great start. However, we really want to count the number of rows that have the value “Female” for sex_f, and then separately count the number of rows that have the value “Male” for sex_f. Said another way, we want to break our data frame up into smaller data frames – one for each value of sex_f – and then count the rows. This is exactly what dplyr’s group_by() function does.\n\nheight_and_weight_20 |&gt;\n  group_by(sex_f) |&gt; \n  summarise(n())\n\n# A tibble: 2 × 2\n  sex_f  `n()`\n  &lt;fct&gt;  &lt;int&gt;\n1 Male       8\n2 Female    12\n\n\nAnd, that’s what we want.\n\n\n\n\n\n\nNote\n\n\n\n🗒Side Note: dplyr’s group_by() function operationalizes the Split - Apply - Combine strategy for data analysis. That sounds sort of fancy, but all it really means is that we split our data frame up into smaller data frames, apply our calculation separately to each smaller data frame, and then combine those individual results back together as a single result. So, in the example above, the height_and_weight_20 data frame was split into two separate little data frames (i.e., one for females and one for males), then the summarise() and n() functions counted the number of rows in each of the two smaller data frames (i.e., 12 and 8 respectively), and finally combined those individual results into a single data frame, which was printed to the screen for us to view.\n\n\nHowever, it will be awkward to work with a variable named n() (i.e., with parentheses) in the future. Let’s go ahead and assign it a different name. We can assign it any valid name we want. Some names that might make sense are n, frequency, or count. We’re going to go ahead and just name it n without the parentheses.\n\nheight_and_weight_20 |&gt;\n  group_by(sex_f) |&gt; \n  summarise(n = n())\n\n# A tibble: 2 × 2\n  sex_f      n\n  &lt;fct&gt;  &lt;int&gt;\n1 Male       8\n2 Female    12\n\n\n👆Here’s what we did above:\n\nWe added n = to our summarise function (summarise(n = n())) so that our count column in the resulting data frame would be named n instead of n().\n\nFinally, estimating categorical frequencies like this is such a common operation that dplyr has a shortcut for it – count(). We can use the count() function to get the same result that we got above.\n\nheight_and_weight_20 |&gt; \n  count(sex_f)\n\n# A tibble: 2 × 2\n  sex_f      n\n  &lt;fct&gt;  &lt;int&gt;\n1 Male       8\n2 Female    12",
    "crumbs": [
      "Descriptive Analysis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Numerical Descriptions of Categorical Variables</span>"
    ]
  },
  {
    "objectID": "chapters/categorical_variables/categorical_variables.html#calculating-percentages",
    "href": "chapters/categorical_variables/categorical_variables.html#calculating-percentages",
    "title": "19  Numerical Descriptions of Categorical Variables",
    "section": "19.4 Calculating percentages",
    "text": "19.4 Calculating percentages\nIn addition to frequencies, we will often be interested in calculating percentages for categorical variables. As always, there are many ways to accomplish this task in R. From here on out, we’re going to primarily use tidyverse functions.\nIn this case, the proportion of people in our data who are female can be calculated as the number who are female (12) divided by the total number of people in the data (20). Because we already know that there are 20 people in the data, we could calculate proportions like this:\n\nheight_and_weight_20 |&gt;\n  count(sex_f) |&gt; \n  mutate(prop = n / 20)\n\n# A tibble: 2 × 3\n  sex_f      n  prop\n  &lt;fct&gt;  &lt;int&gt; &lt;dbl&gt;\n1 Male       8   0.4\n2 Female    12   0.6\n\n\n👆Here’s what we did above:\n\nBecause the count() function returns a data frame just like any other data frame, we can manipulate it in the same ways we can manipulate any other data frame.\nSo, we used dplyr’s mutate() function to create a new variable in the data frame named prop. Again, we could have given it any valid name.\nThen we set the value of prop to be equal to the value of n divided by 20.\n\nThis works, but it would be better to have R calculate the total number of observations for the denominator (20) than for us to manually type it in. In this case, we can do that with the sum() function.\n\nheight_and_weight_20 |&gt; \n  count(sex_f) |&gt; \n  mutate(prop = n / sum(n))\n\n# A tibble: 2 × 3\n  sex_f      n  prop\n  &lt;fct&gt;  &lt;int&gt; &lt;dbl&gt;\n1 Male       8   0.4\n2 Female    12   0.6\n\n\n👆Here’s what we did above:\n\nInstead of manually typing in the total count for our denominator (20), we had R calculate it for us using the sum() function. The sum() function added together all the values of the variable n (i.e., 12 + 8 = 20).\n\nFinally, we just need to multiply our proportion by 100 to convert it to a percentage.\n\nheight_and_weight_20 |&gt; \n  count(sex_f) |&gt; \n  mutate(percent = n / sum(n) * 100)\n\n# A tibble: 2 × 3\n  sex_f      n percent\n  &lt;fct&gt;  &lt;int&gt;   &lt;dbl&gt;\n1 Male       8      40\n2 Female    12      60\n\n\n👆Here’s what we did above:\n\nChanged the name of the variable we are creating from prop to percent. But, we could have given it any valid name.\nMultiplied the proportion by 100 to convert it to a percentage.",
    "crumbs": [
      "Descriptive Analysis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Numerical Descriptions of Categorical Variables</span>"
    ]
  },
  {
    "objectID": "chapters/categorical_variables/categorical_variables.html#cat-missing-data",
    "href": "chapters/categorical_variables/categorical_variables.html#cat-missing-data",
    "title": "19  Numerical Descriptions of Categorical Variables",
    "section": "19.5 Missing data",
    "text": "19.5 Missing data\nIn the real world, you will frequently encounter data that has missing values. Let’s quickly take a look at an example by adding some missing values to our data frame.\n\nheight_and_weight_20 &lt;- height_and_weight_20 |&gt; \n  mutate(sex_f = replace(sex, c(2, 9), NA)) |&gt; \n  print()\n\n# A tibble: 20 × 5\n   id      sex sex_f ht_in wt_lbs\n   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 001       1     1    71    190\n 2 002       1    NA    69    176\n 3 003       2     2    64    130\n 4 004       2     2    65    154\n 5 005       1     1    73    173\n 6 006       1     1    69    182\n 7 007       2     2    68    140\n 8 008       1     1    73    185\n 9 009       2    NA    71    157\n10 010       1     1    66    155\n11 011       1     1    71    213\n12 012       2     2    69    151\n13 013       2     2    66    147\n14 014       2     2    68    196\n15 015       1     1    75    212\n16 016       2     2    69    190\n17 017       2     2    66    194\n18 018       2     2    65    176\n19 019       2     2    65    176\n20 020       2     2    65    102\n\n\n👆Here’s what we did above:\n\nReplaced the 2nd and 9th value of sex_f with NA (missing) using the replace() function.\n\nNow let’s see how our code from above handles this\n\nheight_and_weight_20 |&gt; \n  count(sex_f) |&gt; \n  mutate(percent = n / sum(n) * 100)\n\n# A tibble: 3 × 3\n  sex_f     n percent\n  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1     1     7      35\n2     2    11      55\n3    NA     2      10\n\n\nAs you can see, we are now treating missing as if it were a category of sex_f. Sometimes this will be the result you want. However, often you will want the n and percent of non-missing values for your categorical variable. This is sometimes referred to as a complete case analysis. There’s a couple of different ways we can handle this. We will simply filter out rows with a missing value for sex_f with dplyr’s filter() function.\n\nheight_and_weight_20 |&gt; \n  filter(!is.na(sex_f)) |&gt; \n  count(sex_f) |&gt; \n  mutate(percent = n / sum(n) * 100)\n\n# A tibble: 2 × 3\n  sex_f     n percent\n  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1     1     7    38.9\n2     2    11    61.1\n\n\n👆Here’s what we did above:\n\nWe used filter() to keep only the rows that have a non-missing value for sex_f. \n\nIn the R language, we use the is.na() function to tell the R interpreter to identify NA (missing) values in a vector. We cannot use something like sex_f == NA to identify NA values, which is sometimes confusing for people who are coming to R from other statistical languages.\nIn the R language, ! is the NOT operator. It sort of means “do the opposite.”\nSo, filter() tells R which rows of a data frame to keep, and is.na(sex_f) tells R to find rows with an NA value for the variable sex_f. Together, filter(is.na(sex_f)) would tell R to keep rows with an NA value for the variable sex_f. Adding the NOT operator ! tells R to do the opposite – keep rows that do NOT have an NA value for the variable sex_f.\n\nWe used our code from above to calculate the n and percent of non-missing values of sex_f.",
    "crumbs": [
      "Descriptive Analysis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Numerical Descriptions of Categorical Variables</span>"
    ]
  },
  {
    "objectID": "chapters/categorical_variables/categorical_variables.html#formatting-results",
    "href": "chapters/categorical_variables/categorical_variables.html#formatting-results",
    "title": "19  Numerical Descriptions of Categorical Variables",
    "section": "19.6 Formatting results",
    "text": "19.6 Formatting results\nNotice that now our percentages are being displayed with 5 digits to the right of the decimal. If we wanted to present our findings somewhere (e.g., a journal article or a report for our employer) we would almost never want to display this many digits. Let’s get R to round these numbers for us.\n\nheight_and_weight_20 |&gt; \n  filter(!is.na(sex_f)) |&gt; \n  count(sex_f) |&gt; \n  mutate(percent = (n / sum(n) * 100) |&gt; round(2))\n\n# A tibble: 2 × 3\n  sex_f     n percent\n  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1     1     7    38.9\n2     2    11    61.1\n\n\n👆Here’s what we did above:\n\nWe passed the calculated percentage values (n / sum(n) * 100) to the round() function to round our percentages to 2 decimal places.\n\nNotice that we had to wrap n / sum(n) * 100 in parentheses in order to pass it to the round() function with a pipe.\nWe could have alternatively written our R code this way: mutate(percent = round(n / sum(n) * 100, 2)).",
    "crumbs": [
      "Descriptive Analysis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Numerical Descriptions of Categorical Variables</span>"
    ]
  },
  {
    "objectID": "chapters/categorical_variables/categorical_variables.html#using-freqtables",
    "href": "chapters/categorical_variables/categorical_variables.html#using-freqtables",
    "title": "19  Numerical Descriptions of Categorical Variables",
    "section": "19.7 Using freqtables",
    "text": "19.7 Using freqtables\nIn the sections above, we learned how to use dplyr functions to calculate the frequency and percentage of observations that take on each value of a categorical variable. However, there can be a fair amount of code writing involved when using those methods. The more we have to repeatedly type code, the more tedious and error-prone it becomes. This is an idea we will return to many times in this book. Luckily, the R programming language allows us to write our own functions, which solves both of those problems.\nLater in this book, we will show you [how to write your own functions][writing functions]. For the time being, We’re going to suggest that you install and use a package we created called freqtables. The freqtables package is basically an enhanced version of the code we wrote in the sections above. We designed it to help us quickly make tables of descriptive statistics (i.e., counts, percentages, confidence intervals) for categorical variables, and it’s specifically designed to work in a dplyr pipeline.\nLike all packages, you need to first install it…\n\n# You may be asked if you want to update other packages on your computer that\n# freqtables uses. Go ahead and do so.\ninstall.packages(\"freqtables\")\n\nAnd then load it…\n\n# After installing freqtables on your computer, you can load it just like you\n# would any other package.\nlibrary(freqtables)\n\nNow, let’s use the freq_table() function from freqtables package to rerun our analysis from above.\n\nheight_and_weight_20 |&gt;\n  filter(!is.na(sex_f)) |&gt;\n  freq_table(sex_f)\n\n# A tibble: 2 × 9\n  var   cat       n n_total percent    se t_crit   lcl   ucl\n  &lt;chr&gt; &lt;chr&gt; &lt;int&gt;   &lt;int&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 sex_f 1         7      18    38.9  11.8   2.11  18.2  64.5\n2 sex_f 2        11      18    61.1  11.8   2.11  35.5  81.8\n\n\n👆Here’s what we did above:\n\nWe used filter() to keep only the rows that have a non-missing value for sex and passed the data frame on to the freq_table() function using a pipe.\nWe told the freq_table() function to create a univariate frequency table for the variable sex_f. A “univariate frequency table” just means a table (data frame) of useful statistics about a single categorical variable.\nThe univariate frequency table above includes:\n\nvar: The name of the categorical variable (column) we are analyzing.\ncat: Each of the different categories the variable var contains – in this case “Male” and “Female”.\nn: The number of rows where var equals the value in cat. In this case, there are 7 rows where the value of sex_f is Male, and 11 rows where the value of sex_f is Female.\nn_total: The sum of all the n values. This is also to total number of rows in the data frame currently being analyzed.\npercent: The percent of rows where var equals the value in cat.\nse: The standard error of the percent. This value is not terribly useful on its own; however, it’s necessary for calculating the 95% confidence intervals.\nt_crit: The critical value from the t distribution. This value is not terribly useful on its own; however, it’s necessary for calculating the 95% confidence intervals.\nlcl: The lower (95%, by default) confidence limit for the percentage percent.\nucl: The upper (95%, by default) confidence limit for the percentage percent.\n\n\nWe will continue using the freqtables package at various points throughout the book. We will also show you some other cool things we can do with freqtables. For now, all you need to know how to do is use the freq_table() function to calculate frequencies and percentages for single categorical variables.\n🏆 Congratulations! You now know how to use R to do some basic descriptive analysis of individual categorical variables.",
    "crumbs": [
      "Descriptive Analysis",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Numerical Descriptions of Categorical Variables</span>"
    ]
  },
  {
    "objectID": "chapters/intro_git_github/intro_git_github.html",
    "href": "chapters/intro_git_github/intro_git_github.html",
    "title": "20  Introduction to git and GitHub",
    "section": "",
    "text": "20.1 Versioning\nHave you ever worked on a paper or report and had a folder on your computer that looked something like this?\nSaving a bunch of different versions of a file like this is a real mess. It becomes even worse when you are trying to work with multiple people. What is contained in each document again? What order were the documents created in? What are the differences between the documents? Versioning helps us get around all of these problems.\nInstead of jumping straight into learning versioning with git and GitHub, we will start our discussion about versioning using a simple example in Google Docs. Not because Google Docs are especially relevant to anything else in this course, but because there are a lot of parallels between the Google Docs versioning system and the git versioning system when it is paired with Github. However, the Google Docs versioning system is a little bit more basic, easy to understand, and easy to experiment with. Later, we will refer back to some of these Google Docs examples when we are trying to explain how to use git and GitHub. If you’d like to do some experimenting of your own, feel free to navigate to https://docs.google.com/ now and follow along with the following demonstration.\nFirst, we will type a little bit of text in our Google Doc. It doesn’t really matter what we type — this is purely for demonstration purposes. In the example below, we type “Here is some text.”\nFigure 20.1: A gif about text in Google Docs.\nNow, let’s say that we decide to make a change to our text. Specifically, we decide to replace “some” with “just a little.”\nFigure 20.2: A gif about text change in Google Docs.\nNow, let’s say that we changed our mind again and we want to go back to using the original text. In this case, it would be really easy to go back to using the original text even without versioning. We could just use “undo” or even retype the previous text. But, let’s pretend for a minute that we changed a lot of text, and that we made those changes several weeks ago. Under those circumstances, how might we view the original version of the document? We can use the Google Docs versioning system. To do so, we can click File then Version history then See version history. This will bring up a new view that shows us all the changes we’ve made to this document, and when we made them.\nFigure 20.3: A gif about version history in Google Docs.\nThis is great! We don’t have to save a bunch of different files like we saw in the “messy” folder at the beginning of this section. Instead, there is only one document, and we can see all the versions of that document, who created the various versions of that document, when all the various versions of that document were created, and exactly what changed from one version to the next. In other words, we have a complete record of the evolution of this document in the version history — how we got from the blank document we started with to the current version of the document we are working with today.\nFurther, if we want to turn back the clock to a previous version of the document, we need only select that version and click the Restore this version button like this.\nFigure 20.4: A gif about restoring versions in Google Docs.\nBut, you can probably imagine how difficult it can be to find a previous version of a document by searching through a list of dates. In the example above, there were only three dates to look through, but in a real work document, there may be hundreds of versions saved. The dates, by themselves, aren’t very informative. Luckily, when we hit key milestones in the development of our document, Google Docs allows us to name them. That way, it will be easy to find that version in the future if we ever need to refer to it (assuming we give it an informative name).\nFor example, let’s say that we just added a table to our document that includes the mean values of the variables X and Y for two groups of people - Group 1 and Group 2. Completing this table is a key milestone in the evolution of our document and this is a great time to name the current version of the document just in case we ever need to refer back to it. To do so, we can click File then Version history then Name current version.\nFigure 20.5: A gif about naming current Google Doc versions.\nNotice that in the example above I used the word commit instead of the word save. In this case, they essentially mean the same thing, but soon you will see that git also uses the word commit to refer to taking a snapshot of the state of our project — similar to the way we just took a snapshot of the state of our document.\nNow let’s say that we decide to use medians in our table instead of means. After making that change, our document now looks like this.\nA gif about switching back to an old version in Google Docs.\nCan you guess what we are about to do next? That’s right! We changed our minds again and decided to switch back to using the mean values in the table. No problem! We can easily search for the version of the document that we committed, which includes the table of mean values. We can then restore that version as we did above.\nA gif about restoring versions in Google Docs.",
    "crumbs": [
      "Collaboration",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduction to git and GitHub</span>"
    ]
  },
  {
    "objectID": "chapters/intro_git_github/intro_git_github.html#preservation",
    "href": "chapters/intro_git_github/intro_git_github.html#preservation",
    "title": "20  Introduction to git and GitHub",
    "section": "20.2 Preservation",
    "text": "20.2 Preservation\nIn addition to versioning, the ability to preserve all of your code and related project files in the cloud is another great reason to consider using GitHub. In other words, you don’t have to worry about losing your code if your computer is lost, damaged, or replaced. All of your project files can easily be retrieved and restored from GitHub. Although the same is true for other cloud-based file storage services like Dropbox, Google Drive, and OneDrive, remember that GitHub has special built-in tools that those services do not provide.",
    "crumbs": [
      "Collaboration",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduction to git and GitHub</span>"
    ]
  },
  {
    "objectID": "chapters/intro_git_github/intro_git_github.html#reproducibility",
    "href": "chapters/intro_git_github/intro_git_github.html#reproducibility",
    "title": "20  Introduction to git and GitHub",
    "section": "20.3 Reproducibility",
    "text": "20.3 Reproducibility\nReproducibility, or more precisely, reproducible research, is a term that may be unfamiliar to many of you. Peng and Hichs (2021) give a nice introduction to reproducible research:1\n\nScientific progress has long depended on the ability of scientists to communicate to others the details of their investigations… In the past, it might have sufficed to describe the data collection and analysis using a few key words and high-level language. However, with today’s computing-intensive research, the lack of details about the data analysis in particular can make it impossible to recreate any of the results presented in a paper. Compounding these difficulties is the impracticality of describing these myriad details in traditional journal publications using natural language. To address this communication problem, a concept has emerged known as reproducible research, which aims to provide for others far more precise descriptions of an investigator’s work. As such, reproducible research is an extension of the usual communications practices of scientists, adapted to the modern era.\n\nThey go on to define reproducible research in the following way:1 2\n\nA published data analysis is reproducible if the analytic data sets and the computer code used to create the data analysis are made available to others for independent study and analysis.\n\nWe will not delve deeper into the general importance and challenges of reproducible research in this book; however, we encourage readers who are interested in learning more about reproducible research to take a look at both of the articles cited above. Additionally, we believe it’s important to highlight that GitHub is a great tool for making our research more reproducible. Specifically, it provides a platform where others can easily download the data (when we are allowed to make it available), computer code, and documentation needed to recreate our research results. This is a great asset for scientific progress, but only if researchers like us use it effectively.",
    "crumbs": [
      "Collaboration",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduction to git and GitHub</span>"
    ]
  },
  {
    "objectID": "chapters/intro_git_github/intro_git_github.html#collaboration",
    "href": "chapters/intro_git_github/intro_git_github.html#collaboration",
    "title": "20  Introduction to git and GitHub",
    "section": "20.4 Collaboration",
    "text": "20.4 Collaboration\nIn the sections above, we discussed the ways in which git and GitHub are tools we can use for versioning, preserving our code in the cloud, and making our research more reproducible. All of these are important benefits of using git and GitHub even if we don’t routinely collaborate with others to complete our projects. However, the power of GitHub is even greater when we think about using it as a tool for collaboration — including collaboration with our future selves.\nFor example, one research project that we (the authors) both work on is the Detection of Elder abuse Through Emergency Care Technicians (DETECT) project. Let’s say that we would like to start collaborating with you on DETECT. Perhaps we need your help preprocessing some of the DETECT data and conducting an analysis. So, how do we get started?\nBecause we created a repository on GitHub for the DETECT project, all of the files and documentation you need to get started are easily accessible to you. In fact, you don’t even have to reach out to us first for access. They are freely available to anyone who is interested. Please go ahead and use the following URL to view the DETECT repository now: https://github.com/brad-cannell/detect_pilot_test_5w. GitHub repositories may look a little confusing at first, but you will get used to them with practice.\n\n\n\n\n\n\nNote\n\n\n\n🗒Side Note: Repository is a git term that can seem a little confusing or intimidating at first. However, it’s really no big deal. You can think of a git repository as a folder that holds all of the files related to your project. On GitHub, each repository has its own separate website where people from anywhere in the world can access the files and documents related to your project. They can also communicate with you through your GitHub repository, post issues to your GitHub repository if they encounter a problem, and contribute code to your project.\n\n\nWe could have emailed the files back and forth, but what if we accidentally forget to send you one? What if one of the files is too large to email? What if two people are working on the same file at the same time and send out their revisions via email? Which version should we use? In the chapters that follow, we will show you how using GitHub to share project files gets around these, and other, collaboration issues.",
    "crumbs": [
      "Collaboration",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduction to git and GitHub</span>"
    ]
  },
  {
    "objectID": "chapters/intro_git_github/intro_git_github.html#summary",
    "href": "chapters/intro_git_github/intro_git_github.html#summary",
    "title": "20  Introduction to git and GitHub",
    "section": "20.5 Summary",
    "text": "20.5 Summary\nIn summary, git and GitHub are awesome tools to use when our projects involve research and/or data analysis. They allow us to store all of our files in the cloud with the added benefit of versioning and many other collaboration tools. The primary disadvantage of using GitHub instead of just emailing code files or using general-purpose cloud storage services is its learning curve. But, in the following chapters, we hope to give you enough knowledge to make GitHub immediately useful to you. Over time, you can continue to hone your GitHub skills and really take advantage of everything it has to offer. We think if you make this initial investment, it is unlikely that you will ever look back.\n\n\n\n\n1. Peng RD, Hicks SC. Reproducible research: A retrospective. Annu Rev Public Health. 2021;42:79-93.\n\n\n2. Peng RD. Reproducible research in computational science. Science. 2011;334(6060):1226-1227.",
    "crumbs": [
      "Collaboration",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Introduction to git and GitHub</span>"
    ]
  },
  {
    "objectID": "chapters/using_git_github/using_git_github.html",
    "href": "chapters/using_git_github/using_git_github.html",
    "title": "21  Using git and GitHub",
    "section": "",
    "text": "21.1 Install git\nBefore we can use git, we will need to install it on our computer. The following chapter of Pro Git provides instructions for installing git on Linux, Windows, and MacOS operating systems: Get Started Installing Git.\nIf you are using a Mac, it’s likely that you already have git — most Macs ship with git installed. To check, open your Terminal app. The Terminal app is located in the Utilities folder, which is located in the Applications folder. In the terminal app, type “git version”. If you see a version number, then it is already installed. If not, then please follow the installation instructions given in the link to Pro Git above.\nFigure 21.1: Checking git version in the MacOS terminal.",
    "crumbs": [
      "Collaboration",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Using git and GitHub</span>"
    ]
  },
  {
    "objectID": "chapters/using_git_github/using_git_github.html#sign-up-for-a-github-account",
    "href": "chapters/using_git_github/using_git_github.html#sign-up-for-a-github-account",
    "title": "21  Using git and GitHub",
    "section": "21.2 Sign up for a GitHub account",
    "text": "21.2 Sign up for a GitHub account\nWe have already alluded to the fact that git and GitHub are not the same thing. You can use git locally on your computer without ever using GitHub. Conversely, you can browse GitHub, and even do some limited contributing to code, without ever installing git on your computer (e.g., see Contributing to R4Epi. However, git and GitHub work best when used together. You don’t need to download anything to start using GitHub, but you will need to sign up for a free GitHub account. To do so, just navigate to https://github.com/",
    "crumbs": [
      "Collaboration",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Using git and GitHub</span>"
    ]
  },
  {
    "objectID": "chapters/using_git_github/using_git_github.html#install-gitkraken",
    "href": "chapters/using_git_github/using_git_github.html#install-gitkraken",
    "title": "21  Using git and GitHub",
    "section": "21.3 Install GitKraken",
    "text": "21.3 Install GitKraken\nGit is software for our computer. However, unlike most of the software we are used to using, git does not have a graphical user interface (GUI - pronounced “gooey”). In other words, there is no git application that we can open and start clicking around in. Instead, by default, we interact with git by typing commands into the computer’s terminal – also called “command line” in GitHub’s documentation – like we saw in Figure 21.1. The commands we type to use git kind of look like their own programming language. In our experience, interacting with git in the terminal is awkward, inefficient, and unnecessary for most new git users. And learning to use git in this way is a barrier to getting started in the first place. 😩\nThankfully, other third-party vendors have made excellent GUI’s for git that we can download and use for free. Our current favorite is called GitKraken. To use GitKraken, you will first need to navigate to the GitKraken website (https://www.gitkraken.com/). If it helps, you can think of git and GitKraken as having a relationship that is very similar to the relationship between R and RStudio. R is the language. RStudio is the application that makes it easier for us to use the R language to work with data. Similarly, git is the language and GitKraken is the application that makes it easier for us to use git to track versions of our project files.\nBefore you use the GitKraken client, you will need to sign up for an account. It may say that you need to sign up for a free trial. Go ahead and do it. The free trial is just for the “Pro” version. At the end of the free trial, you will automatically be downgraded to the “Free” version, which is… free. And, the free version will do everything you need to do to follow along with this book.\n\n\n\n\n\n\n\n\n\nNext, you will need to click on the “Try Free” button. Then, download and install the GitKraken Client to your computer.\n\n\n\n\n\n\n\n\n\nAs you are installing GitKraken, it should ask you if you want to sign up with your GitHub account. Yes, you do! It will make your life much easier down the road. If you didn’t sign up for a GitHub account in the previous step, please go back and do so.\n\n\n\n\n\n\n\n\n\nThen click the green Continue authorization button.\n\n\n\n\n\n\n\n\n\nThen, you will be asked to sign into your GitHub account – possibly using your two-factor authentication. When you see the success screen, you can close your browser and return to GitKraken.\n\n\n\n\n\n\n\n\n\nThe next thing you will do is create a profile. After you create a profile, you will be asked if you want the Repo Tab first or the Terminal Tab first. We recommend that you select the Repo Tab option.\n\n\n\n\n\n\n\n\n\nOnce you have installed Git and GitKraken, and you’ve created your GitHub account, you will have all the tools you need to follow along with all of the examples in this book. Speaking of examples, let’s go ahead and take a look at a couple now.",
    "crumbs": [
      "Collaboration",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Using git and GitHub</span>"
    ]
  },
  {
    "objectID": "chapters/using_git_github/using_git_github.html#example-1-contribute-to-r4epi",
    "href": "chapters/using_git_github/using_git_github.html#example-1-contribute-to-r4epi",
    "title": "21  Using git and GitHub",
    "section": "21.4 Example 1: Contribute to R4Epi",
    "text": "21.4 Example 1: Contribute to R4Epi\nIf you haven’t already done so, please read the contributing to R4Epi portion of the book’s welcome page. This will give you a gentle introduction to using GitHub, for a very practical purpose, without even needing to use git or GitKraken.",
    "crumbs": [
      "Collaboration",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Using git and GitHub</span>"
    ]
  },
  {
    "objectID": "chapters/using_git_github/using_git_github.html#example-2-create-a-repository-for-a-research-project",
    "href": "chapters/using_git_github/using_git_github.html#example-2-create-a-repository-for-a-research-project",
    "title": "21  Using git and GitHub",
    "section": "21.5 Example 2: Create a repository for a research project",
    "text": "21.5 Example 2: Create a repository for a research project\nIn this example, we will learn how to create our very own git and GitHub repositories from scratch. We can immediately begin using the lessons from this example for our research projects – even if we aren’t collaborating with others on them. Remember, there are at least four overarching reasons why you should consider learning to use git and GitHub as part of your workflow for your projects, and collaboration is only one of them. Not to mention the fact that it is often useful to think of our future selves as other collaborators, which we have mentioned and/or alluded to many times in this book.\nThere are many possible ways we could set up our project to take advantage of all that git and GitHub have to offer. We’re going to show you one possible sequence of steps in this example, but you may decide that you prefer a different sequence as you get more experience, and that’s totally fine!\nThis example is long! So, we created a brief outline that you can quickly reference in the future. Details are below.\nStep 1: Create a repository on GitHub\nStep 2: Clone the repository to your computer\nStep 3: Add an R project file to the repository\nStep 4: Update and commit gitignore\nStep 5: Keep adding and committing files\n\nStep 1: Create a repository on GitHub\nThe first thing we will do is create a repository on GitHub. Repositories are the fundamental organizational units of your GitHub account. Other cloud storage services like Dropbox are organized into file folders at every level. Meaning, you have your main Dropbox folder, which has other folders nested inside of it – many of which may have their own nested folders. Your GitHub account also stores all your files in file folders; however, the level one folders — those that aren’t nested inside of another folder — are called repositories (represented by the book icon in the image below and on the GitHub website). Typically, each repository is an entire, self-contained project. Like a file folder, each repository can contain other folders, code files, media files, data sets, and any other type of file needed to reproduce your research project.\n\n\n\n\n\nGitHub repositories compared to Dropbox.\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nJust because we can upload data to GitHub doesn’t mean we should upload data to GitHub. Often, the data we use in epidemiology contains protected health information (PHI) that we must go to great lengths to keep secure. In general, GitHub is NOT considered a secure place to store our data and should not be used for this purpose. Below, we will demonstrate how to make sure our data isn’t uploaded to GitHub with the rest of the files in our repository.\n\n\nTo create a new repository in GitHub, we will simply click the green Create repository button. This button will look slightly different depending on where we are at in the GitHub website. The screenshot below was taken from Arthur Epi’s (our fictitious research assistant) main landing page (i.e., https://github.com/).\n\n\n\n\n\n\n\n\n\nAfter clicking the green Create repository button, the next page Arthur will see is the setup page for his repository. For the purposes of this example, he will use the following information to set it up.\n\nRepository name: As the on-screen prompt says, great repository names are short and memorable. Further, the repository name must be unique to his account (i.e., he can’t have two repositories with the same name), and it can only include letters, numbers, dashes (-), underscores (_), and periods (.). We recommend using underscores to separate words to be consistent with the object naming guidelines from coding-best-practices. For this example, he will name the repository r4epi_example_project.\nDescription: The description is optional, but we like to fill it in. Arthur’s description should also be brief. Ideally it will allow others scanning our repository to quickly determine what it’s all about. For this example, the description will say, “An example repository that accompanies the git and GitHub chapters in the R4Epi book.”\nPublic/Private: We can choose to make our repositories public or private. If we make them public, they can be viewed by anyone on the internet. If we make them private, we can control who is able to view them. At first, you may be tempted to make your repositories private. It can feel vulnerable to put your project/code out there for the entire internet to view. However, we are going to recommend that you make all of your repositories public and be thoughtful about the files/documents/information you choose to upload to them. For example, we NEVER want to upload data containing information with PHI or individual identifiers in it. So, we will often need to figure out a different way to share our data with others who legitimately need access to it, but we can often use GitHub to share all other files related to the project. Making our repository public makes it easier for others to locate our work and potentially collaborate with us.\nAdd a README file: A README file has a special place in GitHub. Under the hood, it is just a markdown file. No different than the Quarto files we learned about in the chapter on Quarto files (. However, naming it README gives it a special status. When we include a README file in our repository, GitHub will automatically add it to our repository’s homepage. We should use it to give others more information about our project, what our repository does, how to use the files in our repository, and/or how to contribute. So, we will definitely want a README file. Arthur may as well go ahead and check the box to create it along with his repository (although, we can always add it later).\nAdd .gitignore: We will discuss .gitignore later. Briefly, you can think of it as a list of files we are telling GitHub to ignore (i.e., not to track). This gets back to versioning, which we discussed in the [Versioning] section of the introduction to git and GitHub chapter. For now, Arthur will just leave it as is.\nLicense: The GitHub documentation states that, “Public repositories on GitHub are often used to share open-source software. For your repository to truly be open source, you’ll need to license it so that others are free to use, change, and distribute the software.”1 Because we aren’t currently using our repository to create and distribute open-source software (like R!!), we don’t need to worry about adding a license. That isn’t to say that you won’t ever need to worry about a license. For more on choosing a license, we can consult the GitHub documentation or potentially consult with our employer or study sponsor. For example, our universities have officials that help us determine if our repositories need a license.\n\n\n\n\n\n\n\n\n\n\nNow, that he has completed all the setup steps, Arthur can click the green Create repository button. This will create his repository and take him to its homepage on GitHub. As you can see in the screenshot below (you can also navigate to the website yourself), GitHub creates a basic little website for the repository. The top middle portion of the page (outlined in red below) displays all of the files and folders in the repository. Currently, the repository only contains one file – README.md – but Arthur will add others soon.\n\n\n\n\n\n\n\n\n\nTo the right of files and folders section of the homepage is the About section of the page. This section (outlined in red below) contains the repository’s description, tags, and other information that we will ignore for now.\n\n\n\n\n\n\n\n\n\nBelow the files and folders section of the page is where the README file is displayed. Notice that by default, GitHub added the repository’s name and description to the README file. Not a bad start, but we can add all kinds of cool stuff to README – including tables, figured, images, links, and other media. In fact, you can add almost anything to a README file that you can add to any other website. This is a great place to get creative and really make your project stand out!\n\n\n\n\n\n\n\n\n\nNow, Arthur has a working GitHub repository up and running. Let’s pause for a moment to and celebrate! 🎉\nOkay, celebration complete. Now, what does he do with this new GitHub repository? Well, he does the four things covered in Introduction to git and GitHub\n\nHe will start adding files to his repository and document their purpose and evolution with versioning.\n\nIn the process, he will preserve his files, and by extension, his project.\n\nDoing so will help to make his research more reproducible.\n\nAnd make it easier for him to collaborate with others – including his future self.\n\nLet’s start by taking a look at versioning in GitHub. As we discussed in the Versioning section of the Introduction to git and GitHub chapter, GitHub uses the word commit to refer to taking a snapshot of the state of our project, similar to how we might typically think about saving a version of a document we are working on. We saw how we could view the version history of our Google Doc by clicking File then Version history then See version history. In GitHub, we can similarly view the version history (also called the commit history) of our repository. To do so, we navigate to our repository’s homepage, and click on the word commit in the top right corner of the files section (outlined in red below).\n\n\n\n\n\n\n\n\n\nThis will take us to our repository’s version history page. Currently, this repository only has one commit – the “Initial commit”. This name is used by convention in the GitHub community to refer to the first commit in the repository. The history also tells us when the commit was made and who made it. On the right side of the commit, there are three buttons.\n\n\n\n\n\n\n\n\n\n\nThe first button on the left that looks like two partially overlapping boxes will copy the commit’s ID so that we can paste it elsewhere if we want. In GitHub, every commit is assigned a unique ID, which is also called an “SHA” or “hash”. The commit ID is a string of 40 characters that can be used to refer to a specific commit. The 274519 displayed on the middle button is the first 7 characters of this commit’s ID.\nAs noted above, the middle button is labeled with the first 7 characters of this commit’s ID - 274519. Clicking on it will take us to a new screen with the details of what this commit does to the files in the repository (i.e., additions, edits, and deletions). Arthur will click it so we take a look momentarily.\nThe button on the far right, which is labeled with two angle brackets (&lt; &gt;) will take us back to the repository’s homepage. However, the files in the repository will be set back to the state they were in when the commit was made. In this case, there is only one commit. So, there’s no difference between the current state of the repository and the state it would be in if Arthur clicked this button. However, this button can be useful. If Arthur makes some changes to a file and then later wants to see what the file looked like before he made those changes, he can use this button to take a look.\n\nNow, Arthur will click the middle button labeled with the short version of the commit ID.\nOn the page he is taken to, we can see more details about what commit 274519 does to the files in the repository. The top section of the page (outlined in red below) contains pretty much the same information we saw on the previous page. The little symbol on the left that looks kind of like a backwards 4 with open circles at the ends of the lines tells us which branch we are operating on. Branches are a more advanced topic that we will discuss later. Currently, our repository only has one branch – the default main branch – and the symbol followed by the word “main” is telling us that this commit is on the main branch. To the far right of this section, there is a button that says Browse files. Clicking this button does the exact same thing as the button on the previous page that was labeled with two angle brackets (&lt; &gt;). Below the Browse files button, are the words 0 parents and commit 277451996a7e9a0a6e583124d762db2a9cd439a2. This tells us that this commit doesn’t have any parent commits and that the full commit ID is 277451996a7e9a0a6e583124d762db2a9cd439a2. We discussed commit ID’s above. The parent commit is the commit or commits that this commit is based on. In other words, what were the other things that happened to get us to this point? Because this is the initial commit, there are no parent commits.\n\n\n\n\n\n\n\n\n\nThe middle section of the commit details page tells us that applying this commit to the repository changes 1 file. In that file, there are two additions and no deletions. Below this text we can see which file was changed - README.md. This is also called the diff view because we can see the differences between this version of the file and previous versions of the file. In this case, because there wasn’t a previous version of the file, we just see the two additions that were made to the file. They are the level one header that was added to the first line of the file (i.e., # r4epi_example_project) and our project’s description was added to the second line of the file. These additions were made automatically by GitHub. We know they are additions because the background color is green and there is a little plus sign immediately to their left. We know which lines of the file were changed because GitHub shows us the line number immediately to the left of the plus signs.\n\n\n\n\n\n\n\n\n\nThe final section of the commit details page shows us any existing comments that Arthur, or others, made about this commit. It also allows us, or others to create a new comment, using the text box.\n\n\n\n\n\n\n\n\n\nIn the screenshot below, we can see an example comment. Note all the cool things features GitHub comments allow us to use. We can format the text, add bullets, add links, and even add clickable checkboxes.\n\n\n\n\n\n\n\n\n\nFinally, clicking the green Comment on this commit button adds our comment to the commit details page.\n\n\n\n\n\n\n\n\n\nLet’s pause here for a moment and try to appreciate how powerful GitHub already is compared to other cloud-based file storage services like Dropbox, Google Drive, or OneDrive. Like those file storage services, all of our files are backed up and preserved in the cloud and can easily be shared with others. However, unlike Dropbox, Google Drive, and OneDrive, we can turn our repository’s homepage into a little website describing our project, we can view all the changes that have been made to our project over time, we can see which specific lines of each file have changed and how, and we can gather all comments, questions, and concerns about the files in one place. Oh, and it’s Free!\n\n\nStep 2: Clone the repository to your computer\nAt this point, Arthur’s repository, which is just a fancy file folder, and the one file in his repository (README.md), only exist on the GitHub cloud.\n\n\n\n\n\n\nNote\n\n\n\n🗒Side Note: What is “the GitHub cloud”? For our purposes, the cloud just refers to a specific type of computer – called a server – that physically exists somewhere else in the world, which we can connect to over the internet. GitHub owns many servers, and our files are stored on one of them. After we connect to the GitHub server, we can pass files back and forth between our computer and GitHub’s computer (i.e., the server).\n\n\n\n\n\n\n\n\n\n\nFigure 21.2: GitHub Cloud.\n\n\n\n\n\nSo, how does he get the repository from the GitHub cloud to his computer so that he can start making changes to it?\nHe will clone the repository to his computer. Don’t get thrown off by the funny name. You can simply think “make a copy of” whenever you see the word “clone” for now. So, he will “make a copy of” the repository on his computer. However, cloning the repository actually does two very useful things at once:\n\nIt creates a copy of our repository, and all of the files and folders in it, on our computer.\n\nIt creates a connection between our computer and the GitHub cloud that allows us to pass files back and forth.\n\nThere are multiple possible ways we could clone our repository, but we’re going to use GitKraken in this book. If you did not already download GitKraken and connect it with your GitHub account as demonstrated at the beginning of the chapter, please do so now.\nWhen we open GitKraken, we should see something similar to the screenshot below. Arthur will start the cloning process by clicking the Clone a repo button.\n\n\n\n\n\n\n\n\n\nWhen the Repository Management dialogue box opens, he will need to make 3 changes.\n\nClick GitHub.com in the clone menu. This tells GitKraken that the repository he wants to clone currently lives on his GitHub account. Note that it has to be on his account in order for it to show up on this list – not someone else’s account. We will learn how to get files from someone else’s account later.\nSet the path where he wants the repository to be cloned to. Remember, the repository is a just a folder with some files in it. When we clone the repository to our computer, those files and folders will live on our computer somewhere. We need to tell GitKraken where we want them to live. In the screenshot below, Arthur is just cloning the repository to his computer’s desktop.\nTell GitKraken which repository on his GitHub account he wants to clone. We can use the drop-down arrow to search a list of all of our repositories. In the screenshot below, Arthur selected the r4epi_example_project repository.\n\n\n\n\n\n\n\n\n\n\nFinally, he will click the green Clone the repo! button. Now, he has successfully cloned his repository to his computer! 🎉\nBefore moving on, let’s pause and review what just happened.\n\n\n\n\n\n\n\n\n\nAs we discussed above, Arthur’s repository already existed on the GitHub cloud see Figure 21.2. In git terminology, the GitHub cloud called a remote repository, or “repo” for short. Remote repositories are just copies of our repository that live on the internet or some other network. Arthur then cloned his remote repository to his computer. That means, he made a copy of all of the files and folders on his computer. In git terminology, the repository on our computer is called a local repository.\nNow that he has successfully cloned his repository, he should be able to view it in two different ways.\nFirst, he should be able to see his repository’s file folder on his desktop (because that’s the location he chose above).\n\n\n\n\n\n\n\n\n\nSecond, he should be able to open a tab in GitKraken with all the versioning information about his repository.\n\n\n\n\n\n\n\n\n\nLet’s pause here and watch a brief video from GitKraken that orients us to the GitKraken user interface. For now, the first three minutes of the video is all we need. There may be some unfamiliar terms in the video. Don’t stress about it! We will cover the most important parts after the video and learn some of the other terms in future examples.\n\nMoving back to Arthur’s repository, we can see that the repository graph in the middle section of the user interface has only on commit – the initial commit. This matches what we saw on GitHub.\n\n\n\n\n\n\n\n\n\nIf we zoom in on the upper left corner of the left sidebar menu (outlined in red below), we can see that GitKraken is aware of two different places where the repository lives. First, it tells us that Arthur has a local repository on his computer with one branch – the main branch. Next, it tells us that there is one remote location for the repository – called “origin” – with one branch – the main branch.\nThe term “origin” is used by convention in the git language to refer to the remote repository that we originally cloned from. It uses the nickname “origin” instead of using the remote repository’s full URL (i.e., web address). Arthur could change this name if he wanted, but there’s really no need.\n\n\n\n\n\n\n\n\n\nAnother useful thing we can see in the current view, is that the local repository and the remote repository on GitHub are in sync. Meaning, the files and folders in the repository on Arthur’s computer are identical to the files and folders in the repository on the GitHub cloud. We know this because the little white and gray picture that represents the remote repository and the little picture of the laptop that represents the local repository are located side-by-side on the repository graph (see red arrow below). When we have made changes in one location or another, but haven’t synced those changes to the other location, the two icons will be in different rows of the repository graph. We will see an example of this soon.\n\n\n\n\n\n\n\n\n\n\n\nStep 3: Add an R project file to the repository\nThis step is technically optional, but we highly recommend it! We introduced R projects earlier in the book. Arthur will go ahead and add an R project file to his repository now. This will make his life easier later. To create a new R project, he just needs to click the drop-down arrow next to the words Project: (None) to open the projects menu. Then, he will click the New Project... option.\n\n\n\n\n\n\n\n\n\nThat will open the new project dialogue box. This time, he will click the Existing Directory option instead of clicking the New Directory option. Why? Because the directory (i.e., folder) he wants to contain his R project already exists on his computer. Arthur cloned it to his desktop in [step 2][Step 2: Clone the repository] above.\n\n\n\n\n\n\n\n\n\nAll Arthur has to do now, is tell RStudio where to find the r4epi_example_project directory on his computer using the Browse... button. In this case, on his desktop. Finally, he will click the Create Project button.\n\n\n\n\n\n\n\n\n\n\n\nStep 4: Update and commit gitignore\nLet’s take a look at Arthur’s RStudio files pane. Notice that there are now three files in the project directory. There is the README file, the .Rproj file, and a file called .gitignore. RStudio created this file automatically when Arthur designated the directory as an R project.\nOutside of the name – .gitignore – there is nothing special about this file. It’s just a plain text file. But naming it .gitignore tells the git software that it contains a list of files that git should ignore. By ignore, we mean, “pretend they don’t exist.”\n\n\n\n\n\n\n\n\n\nArthur will now open the .gitignore file and see what’s there.\n\n\n\n\n\n\n\n\n\nCurrently, there are four files on the .gitignore list. These files were added automatically by RStudio to try to help him out. Tracking versions of these files typically isn’t useful. Because these files are on the .gitignore list, git and GitHub won’t even notice if Arthur creates, edits, or deletes any of them. This means that they also won’t ever be uploaded to GitHub.\nAt this point, Arthur is going to go ahead and add one more file to the .gitignore list. He will add .DS_store to the list. .DS_store is a file that the MacOS operating system creates automatically when a Mac user navigates to a file or folder using Finder. None of that really matters for our purposes, though. What does matter is that there is no need to track versions of this file and it will be a constant annoyance if Arthur doesn’t ignore it.\nIf Arthur were using a Windows PC instead of a Mac, the .DS_store file should not be an issue. However, adding .DS_store to .gitignore isn’t a bad idea even when using a Windows PC for at least two reasons. First, there is no harm in doing so. Second, if Arthur ever collaborates with someone else on this project who is using a Mac, then the .DS_store file could find its way into the repository and become an annoyance. Therefore, we recommend always adding .DS_store to the .gitignore list regardless of the operating system you personally use.\nAdding .DS_store (or any other file name) to the .gitignore list is as simple as typing .DS_store on its own line of the .gitignore file and clicking Save.\n\n\n\n\n\n\n\n\n\nTypically, the next thing we would do after creating our repository is to start creating and adding the files we need to complete our analyses.\nNow, Arthur will open GitKraken so we can take a look. Notice that Arthur’s GitKraken looks different than it did the last time we viewed it. That’s because we’ve been making changes to the repository. Specifically, we’ve added two files since the last commit was made. There are at least two ways we can tell that is the case.\nFirst, the repository graph in the middle section of the user interface has now has two rows. The bottom row is still the initial commit, but now there is a row above it that says // WIP and has a + 2 symbol. WIP stands for work in progress and the + 2 indicates that there are two files that have changed (in this case, they were added) since the last commit. So, Arthur has been working on two files since his last commit.\nAdditionally, the commit panel on the right side of the screen shows that there are two new uncommitted and unstaged files in the directory. They are .gitignore and r4epi_example_project.Rproj.\n\n\n\n\n\n\n\n\n\nAt this point, Arthur wants to take a snapshot of the state of his repository. Meaning, he wants to save a version of his repository as it currently exists. To do that, he first needs to stage the changes since the previous commit that he wants to be included in this commit. In this case, he wants to include all changes. So, he will click the green Stage all changes button located in the commit panel.\n\n\n\n\n\n\n\n\n\nAfter clicking the Stage all changes button, the two new files are moved down to the Staged Files window of the commit panel.\n\n\n\n\n\n\n\n\n\nNext, Arthur will write a commit message. Just like there are best practices for writing R code, there are also best practices for writing commit messages. Here is a link to a blog post that we think does a good job of explaining these best practices: https://cbea.ms/git-commit.\nThe first line is called the commit message. You can think of the commit message as a brief summary of what this commit does to the repository. This message will help Arthur and his collaborators find key commits later in the future. In this context, “brief” means 72 characters or less. GitKraken tries to help us out by telling us how many characters we’ve typed in our commit message. Additionally, the commit message should be written in the imperative voice – like a command. Another way to think about it is that the commit message should typically complete the phrase, “If applied, this commit will…”. The screenshot below shows that Arthur wrote Add Rproj and gitignore to project (red arrow 1).\nIn addition to the commit message, there is also a description box we can use to add more details about the commit. Sometimes, this is unnecessary. However, when we do choose to add a description, it is best practice to use it to explain what the commit does or why we chose to do it rather than how it does whatever it does. That’s in the code. In the screenshot below, you can see that Arthur added some bulleted notes to the description (red arrow 2).\nFinally, Arthur will click the green commit button at the bottom of the commit panel (red arrow 3). This will commit (save) a version of our repository that includes the changes to any of the files in the Staged Files window.\n\n\n\n\n\n\n\n\n\nAnd here is what his GitKraken screen looks like after committing.\n\n\n\n\n\n\n\n\n\nLet’s pay special attention to what is being displayed in a couple of different areas. We’ll start by zooming in on the commit panel.\nAt the top of the commit panel, we can see the short version of the commit ID – 4a394b. Below that, we can see the commit message and description. Below that, we can see who created the commit and when. This tends to be more useful when we are collaborating with others. To the right of that information, GitKraken also shows us the commit ID for this commit’s parent commit – 277451. Finally, it shows us the file changes that this commit applies to our repository. More specifically, it shows us the changes that commit 4a394b makes to commit 277451.\n\n\n\n\n\n\n\n\n\nAt this point, you may be wondering what this whole parent-child thing is and why we keep talking about it. The diagram below is a very simple graphical representation of how git views our repository. It views it as a series of commits that chronologically build our repository when they are applied to each other in sequence. Familial terms are often used in the git community to describe the relationship between commits. For example, in the diagram below commit 4a394b is a child of commit 288451. Child commits are always more recent than parent commits. This knowledge is not incredibly useful to us at this point, but it can be helpful when we start to learn about more advanced topics like merging commits. For now, just be aware of the terminology.\n\n\n\n\n\n\n\n\n\nIt is also important to point out that Arthur’s most recent commit (4a394b) only exists in his local repository. That is, the repository on his computer. He has not yet shared the commit – or the new files associated with the commit – to the remote repository on GitHub.\n\n\n\n\n\n\n\n\n\nHow do we know? Well, one way we can tell is by looking at Arthur’s GitKraken window. In the repository graph, the local repository (i.e., the little laptop icon) and the remote repository (i.e., the little gray and white icon) are on different rows. Additionally, there is a little 1 next to an up arrow displayed to the left of the main branch of our local repository in the left panel of GitKraken. Both of these indicate that the most recent commits contained in each repository are different. Specifically, that the local repository is one commit ahead of the remote repository.\nThis concept is important to understand. [In Google Docs][versioning], when we made a change to our document locally, that change was automatically synced to Google’s servers. We didn’t have to do anything to save/create a version of the document. We had to put in a little effort if we wanted to name a particular version, but the version itself was already saved – identified using a date-time stamp. Conversely, git does not automatically make commits (i.e., save snapshots of the state of the files in our repository), nor does our local repository automatically sync up with our remote repository (in this case, GitHub). We have to do both of these things manually. This will create a little extra work for us, but it will also give us a lot more control.\n\n\n\n\n\n\n\n\n\nAs one additional check, Arthur can go look at the repository’s commit history on GitHub. As shown in the screenshot below, the commit history still only shows one commit – the initial commit.\n\n\n\n\n\n\n\n\n\nLet’s quickly pause and recap what Arthur has done so far.\n\n\n\n\n\n\n\n\n\nFirst, Arthur created a repository on GitHub. It was a remote repository because he accesses it over the internet. Then, he cloned (i.e., made a copy of) the remote repository to his computer. This copy is referred to as a local repository. Next, Arthur made some changes to the repository locally and committed them. At this point, the local repository is 1 commit ahead of the remote repository, and the changes that Arthur made locally are not currently reflected on GitHub.\nSo, how does Arthur sync the changes he made locally with GitHub? He will push them to GitHub, which GitKraken makes incredibly easy. All he needs to do is click the Push button at the top of his GitKraken window (see below).\n\n\n\n\n\n\n\n\n\nAfter doing so, we will once again see some changes. What changes do you notice in the screenshot below?\n\n\n\n\n\n\n\n\n\nIn the repository graph, the local repository (i.e., the little laptop icon) and the remote repository (i.e., the little gray and white icon) are back on the same row. Additionally, the little 1 next to an up arrow is no longer displayed in the left panel. Both of these changes indicate that the most recent commits contained in each repository are the same.\nAnd if Arthur once again checks GitHub…\n\n\n\n\n\n\n\n\n\nHe will now see that the GitHub repository also has two commits. He can click on the text that says 2 commits to view each commit in the commit history.\n\n\n\n\n\n\n\n\n\nIn the commit history, he can now see commit 4a394b7. Let’s take another pause here and recap.\n\n\n\n\n\n\n\n\n\nFirst, Arthur created a repository on GitHub. Then, he cloned the remote (i.e., GitHub) repository to his computer. Next, Arthur made some changes to the repository locally and committed them locally. Finally, he pushed the local commit up to GitHub. Now, his GitHub repository and local repository are in sync with each other.\nWe realize that it probably seems like it took a lot of work for Arthur to get everything set up. But in reality, all of the steps up to this point will only take a couple of minutes once you’ve gone through them a few times.\n\n\nStep 5: Keep adding and committing files\nAt this point, Arthur has his repositories all set up and is ready to start rocking and rolling on his actual data analysis. To round out this example, Arthur will add some data to his repository that he will eventually analyze using R.\n\n\n\n\n\n\n\n\n\nThe screenshot above shows that Arthur created a new folder inside the R project directory called data. He created it in the same way he would create any other new folder in his computer’s operating system. Then, he added a data set to the data folder he created. This particular data set happens to be stored in an Excel file named form_20.xlsx.\nNow, when Arthur checks GitKraken, this is what he sees in the commit panel.\n\n\n\n\n\n\n\n\n\nJust like before, GitHub is telling Arthur that he has a new unstaged file in the repository. Stop for a moment and think. What should Arthur do next?\nWas your answer, “stage and commit the new file”? If so, slow down and think again. Remember, in general, we don’t ever want to commit our research data to our GitHub repository. GitHub is not typically considered secure or private. So, how can Arthur keep the data in his local repository so that he can work with it, keep his local repository synced with GitHub, but make sure the data doesn’t get pushed up to GitHub?\nDo you remember earlier when Arthur told git and GitHub to ignore the .DS_Store file? In exactly the same way, Arthur can tell git and GitHub to ignore this data set. And once it’s ignored, it won’t ever be pushed to GitHub. Remember, our local git repository only includes files it’s tracking in commits, and it only pushes commits (and the files included in them) up to GitHub.\nIn the screenshot below, Arthur added data/ to line 6 of the .gitignore file. He could have added form_20.xlsx instead. That would have told git to ignore the form_20.xlsx data set specifically. However, Arthur doesn’t want to push any data to GitHub – including any data sets that he may add in the future. By adding data/ to the .gitignore file, he is telling git to ignore the entire folder named data and all of the files it contains – now and in the future.\n\n\n\n\n\n\n\n\n\nAfter saving the updated .gitignore file, the commit pane in GitKraken changes once again.\n\n\n\n\n\n\n\n\n\nThe new file data/form_20.xlsx is no longer showing up as an unstaged change. Instead, the only unstaged change showing up is the edited .gitignore file. We can tell that the changes to the .gitignore file are edits – as opposed to adding the file for the first time – because there is a little pencil icon to the left of the file name instead of a little green plus icon. Now what should Arthur do next?\nWas your answer, “stage and commit the edited file”? If so, you are correct! Now it is safe for Arthur to go ahead and commit these changes.\nAfter doing so, he can see that the GitHub repository contains 3 commits. Additionally, as shown the red box below, the data folder is nowhere to be found among the files contained in the GitHub repository.\n\n\n\n\n\n\n\n\n\nArthur will now add one final file to the r4epi_example_project as part of this example. He will add an Quartofile with a little bit of R code in it. The code will import form_20.xlsx into the global environment as a data frame.\n\n\n\n\n\n\n\n\n\nAn then he will commit and push the data_01_import.Rmd to GitHub in the same way he committed and pushed previous files to Github.\n\n\n\n\n\nA gif about data import.\n\n\n\n\nArthur can continue adding files to his local repository and then pushing them to GitHub in this fashion for the remainder of the time he is working on this project, and the introduction to git and GitHub chapter discusses why he should consider doing so.\nAfter going through this example, many students have three lingering questions:\n\nHow often should we commit?\nHow often should we push our commits to GitHub?\nIf we can’t use GitHub to share our data, how should we share data?\n\nWe will answer questions 1 & 2 immediately below. We will answer the third question in the next example.",
    "crumbs": [
      "Collaboration",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Using git and GitHub</span>"
    ]
  },
  {
    "objectID": "chapters/using_git_github/using_git_github.html#committing-and-pushing",
    "href": "chapters/using_git_github/using_git_github.html#committing-and-pushing",
    "title": "21  Using git and GitHub",
    "section": "21.6 Committing and pushing",
    "text": "21.6 Committing and pushing\nAs we are learning to use git and GitHub, it is reasonable to ask how often we should commit our work as we go along. For better or worse, there is no hard-and-fast rule we can give you here. In Happy Git and GitHub for the useR, Dr. Jennifer (Jenny) Bryan writes that we should commit “every time you finish a valuable chunk of work, probably many times a day.”2 This seems like a pretty good starting place to us.\nOf course, a natural follow-up question is to ask how often we should push our commits to GitHub. We could automatically push every commit we make to GitHub as soon as we make it. However, this isn’t always a good idea. It is much easier to edit or rollback commits that we have only made locally than it is to edit or rollback commits that we’ve pushed to our remote repository. For example, if we accidentally include a data set in a commit and push it to GitHub, this is a much bigger problem than if we accidentally include a data set in a commit and catch it before we push to GitHub. For this reason, we don’t suggest that you automatically push every commit you make to GitHub. So, how often should you push? Well, once again, there is no hard-and-fast rule. And once again, we think Dr. Bryan’s advice is a good starting point. She writes, “Do this [push] a few times a day, but possibly less often than you commit.”2 It is also worth noting that how often you commit and push will also be dictated, at least partially, by the dynamics of the group of people who are contributing to the repository. So far, we have really only seen a repository with a single contributor (i.e., Arthur Epi). That will change in the next example.\nThe advice above about committing and pushing may seem a little vague to you right now. It is a little vague. We apologize for that. However, we believe it’s also the best we can do. On the bright side, as you practice with git and GitHub, you will eventually fall into a rhythm that works well for you. Just give it a little time!",
    "crumbs": [
      "Collaboration",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Using git and GitHub</span>"
    ]
  },
  {
    "objectID": "chapters/using_git_github/using_git_github.html#example-3-contribute-to-a-research-project",
    "href": "chapters/using_git_github/using_git_github.html#example-3-contribute-to-a-research-project",
    "title": "21  Using git and GitHub",
    "section": "21.7 Example 3: Contribute to a research project",
    "text": "21.7 Example 3: Contribute to a research project\nWhen our research assistants begin helping us with data management and analysis projects, we often have them start by going to the project’s GitHub repository to read the existing documentation and clone all the existing code to their computer. This example is going to walk through that process step-by-step. For demonstration purposes, we will work with the example repository that our fictitious research assistant named Arthur Epi created in Example 2 above.\n\n\n\n\n\n\nNote\n\n\n\n🗒Side Note: It’s probably worth noting that in most real-world scenarios the roles here would be reversed. That is, we (Brad or Doug) would have created the original repository and Arthur would be working off of it. However, the example repository above was already created using Arthur’s GitHub account, and we will continue to work off of it in this example. If you are a research assistant working with us (i.e., Brad or Doug) in real life, and using this example to walk yourself through getting started on a real project, you should insert yourself (and your GitHub account) into Brad’s role (and GitHub account) in the example below.\n\n\nIn this example, we’re going to work collaboratively with Arthur on the r4epi_example_project. Arthur could have just emailed us all of the project files, but sometimes that might be many files, some of them may be very large, and he runs the risk of forgetting to send some of them by accident. Further, every time any of the contributors adds or updates a file, they will have to email all the other contributors the new file(s) and an explanation of the updates they’ve made. This process is typically inefficient and error prone. Conversely, Arthur could set up a shared folder on a cloud-based file storage service like Dropbox, Google Drive, or OneDrive. Doing so would circumvent the issues caused by emailing files that we just mentioned (i.e., many files, large files, forgetting files, and manually sending updates). However, Dropbox, Google Drive, and OneDrive aren’t designed to take advantage of all that git and GitHub have to offer (e.g., project documentation, versioning and version history, viewing differences between code versions, issue tracking, creating static websites for research dissemination, and more). Because Arthur created his repository on GitHub, all of the files and documentation we need to get started assisting him are easily accessible to us. All, he has to do is send us the repository’s web address, which is https://github.com/arthur-epi/r4epi_example_project.\nAfter navigating to a GitHub repository, the first thing we typically want to do is read the README. It should have some useful information for us about what the repository does, how it is organized, and how to use it. Because this is a fictitious, minimal example for the book, the current README in the r4epi_example_project project isn’t that useful, impressive, or informative. Matias Singers maintains a list of great READMEs at the following link that you may want to check out: https://github.com/matiassingers/awesome-readme. If you want to see an example README from a real research project that we worked on, you can check out this link: https://github.com/brad-cannell/detect_pilot_test_5w. After we read over the README file, we are ready to start making edits and additions to the project. But how do we do that?\nWhile it is technically possible for us to edit code files directly on GitHub (see [Contributing to R4Epi]), this is typically only a good idea for extremely minor edits (e.g., a typo in the documentation). Typically, we will want to make a copy of all the code files on our computer so that we can experiment with the edits we are making. Said another way, we can suggest edits to R code files directly on GitHub, but we can’t run those files in R directly on GitHub to make sure they do what we intend for them to do. To test our changes in R, we will need all of the repository’s files on our local computer. And how do we do that?\n\n21.7.1 Forking a repository\nIf your answer the question above was, “we clone the r4epi_example_project repository to our computer” you were close, but that isn’t our best option here. While we technically can clone public repositories that aren’t on our account, we can’t push any changes to them. And this is a good thing! Think about it, do we really want any person out there on the internet to be able to make changes to our repository anytime they want without any oversight from us? No way!\n\n\n\n\n\n\n\n\n\nIn this case, forking the repository is going to be the better option. This is another funny name, but we are once again just talking about making a copy of the repository. However, this time we are copying the repository from the original GitHub account (i.e., Arthur’s) to our GitHub account. With cloning, we were copying the repository from the original GitHub account to our computer. Do you see the difference? Let’s try to visualize it.\n\n\n\n\n\n\n\n\n\nThe purple arrow above indicates that we are forking (i.e., making a copy of) the original r4epi_example_project repository on Arthur’s GitHub account to Brad’s GitHub account. And doing so is really easy. All Brad has to do is log in to GitHub and navigate to Arthur’s r4epi_example_project repository located at https://github.com/arthur-epi/r4epi_example_project. Then, he needs to click on the Fork button located near the top-right corner of the screen.\n\n\n\n\n\n\n\n\n\nThen Brad will click the green Create fork button on the next page.\n\n\n\n\n\n\n\n\n\nAnd after a few moments, this will create an entirely new repository on Brad’s GitHub account. It will contain an exact copy of the all the files that were on the repository in Arthur’s GitHub account, but Brad is the owner of this repository on his account (shown in the screenshot below).\n\n\n\n\n\n\n\n\n\nBecause Brad is the owner of this repository, he can clone it to his local computer, work on it, and push changes up to GitHub in exactly the same way that Arthur did in the example above. Just to be clear, the changes that Brad pushes to his GitHub repository will have no effect on Arthur’s GitHub repository.\n\n\n\n\n\n\nNote\n\n\n\n🗒Side Note: As we’ve pointed out multiple times in this chapter, we generally do not want to upload research data to GitHub. Why? Because it isn’t typically considered private or secure. However, in order for Brad to do work on this project, he will need to access the data somehow. This will require Arthur to share to data with Brad through some means other than GitHub. Different organizations have different rules about what is considered secure. For example, it may be an encrypted email or it may be a link to a shared drive on a secure server. However the data is shared, it is important for Brad to create the same file structure on his computer that Arthur has on his computer. Otherwise, the R code will not work on both computers. Remember from the example above that Arthur created a data/ folder in his local repository and he moved the form_20.xlsx data to that folder. Then, in the data_01_import Quartofile, he imports the data using the relative path data/form_20.xlsx. In the chapter on file paths we discussed the advantages of using relative file paths when working collaboratively. Just remember, in order for this relative file path to work identically on Arthur’s computer and Brad’s computer, the folder structure and file names must also be identical. So, if Brad put the form_20.xlsx data in a folder in his local repository called data sets/ instead of data/, then the code in the data_01_import Quartofile would throw an error.\n\n\n\n\n\n\n\n\n\n\n\nNotice that in the diagram above, Arthur’s original repository is totally unaffected by any changes that Brad is pushing from his local computer to the repository on his GitHub account. There is no arrow from Brad’s remote repository going into Arthur’s remote repository. Again, this is a good thing. Literally anyone else in the world with a GitHub account could just as easily fork the repository and start making changes. If they also had the ability to make changes to the original repository at will, they could potentially do a lot of damage!\nHowever, in this case, Arthur and Brad do know each other and they are working collaboratively on this project. And at some point, the work that Brad is doing needs to be synced up with the work that Arthur is doing. In order to make that happen, Brad will need to send Arthur a request to pull the changes from Brad’s remote repository into Arthur’s remote repository. This is called a pull request.\n\n\n\n\n\n\n\n\n\n\n\n21.7.2 Creating a pull request\nTo make this section slightly more realistic, let’s say that Brad adds some code to data_01_import.Qmd. Specifically, he adds some code that will coerce the date_received column from character strings to dates (code below).\n\n\n\n\n\n\n\n\n\nThen, Brad commits the changes and pushes them up to his GitHub account. Now, when he checks his GitHub account he can see that his remote repository is 1 commit ahead of Arthur’s remote repository. And that makes sense, right? Brad just updated the code in data_01_import.Qmd, committed that changed, and pushed the commit to his GitHub account, but nothing has changed in the repository on Arthur’s GitHub account.\n\n\n\n\n\n\n\n\n\nNow, Brad needs to create a pull request. This pull request will let Arthur know that Brad has made some changes to the code that he wants to share with Arthur. To do so, Brad will click Contribute and then click the green Open pull request button as shown below.\n\n\n\n\n\n\n\n\n\nThe top section of the next screen, which is outlined in red below, allows Brad to select the repository and branch on his GitHub account that he wants to share with Arthur (to the right of the arrow). More specifically, he is sending a request to Arthur asking him to merge his code into Arthur’s code. In this case, the code he wants to ask Arthur to merge is on the main branch of the brad-cannell/r4epi_example_project repository (Brad’s repository only has one branch – the main branch – at this point). To the left of the arrow, Brad can select the repository and branch on Arthur’s GitHub account that he wants to ask Arthur to merge the code into. In this case, the main branch of the arthur-epi/r4epi_example_project repository (Arthur’s repository only has the main branch at this point as well).\nBelow the red box, GitHub is telling Brad about the commits that will be sent in this pull request and the changes that will be made to Arthur’s files if he merges the pull request into his repository. In this case, only one file in Arthur’s repository would be altered – data_01_import.Rmd. Below that, Brad can see that the exact differences between his version of data_01_import.Rmd and the version that currently exists in Arthur’s repository. How cool is that that Brad and Arthur can actually see exactly how this pull request changes the file state down to individual lines of code?\nBecause Brad is satisfied with what he sees here, he clicks the green Create pull request button shown in the middle right of the screenshot below.\n\n\n\n\n\n\n\n\n\nLet’s pause here and get explicit about two things.\n\nAs we’ve tried to really drive home above, this pull request will not automatically make any changes to Arthur’s repository. Rather, it will only send Arthur Brad’s code, ask him to review it, and then allow him to choose whether to incorporate it into his repository or not.\nPull requests are sent at the branch level not at the file level. Meaning, if Arthur accepts Brad’s pull request, it will make all of the files on his main branch identical to all of the files on Brad’s main branch (the main branch because that is the branch Brad chose in the screenshot above – and currently the only branch in either repository). In this case, that means that the only file that would change as a result of copying over the entire branch is data_01_import.Rmd. However, if Brad had made changes to data_01_import.Rmd and another file, Arthur would only have the option to merge both files or neither file. He would not have the option of merging data_01_import.Rmd only. Pull requests merge the entire branch, not specific files. We are emphasizing this because this may affect how you commit, push, and create pull requests when you are working collaboratively. More specifically, you may want to commit, push, and send pull requests more frequently than you would if you were working on a project independently.\n\nOn the next screen, Brad is given an opportunity to give the pull request a title and add a message for Arthur that give him some additional details. In general, it’s a good idea to fill this part out using similar conventions to those described above for commit messages.\nAfter filling out the commit message, Brad will click the green Create pull request button on last time, and he is done. This will send Arthur the pull request.\n\n\n\n\n\n\n\n\n\nThe next time Arthur checks the r4epi_example_project on GitHub, he will see that he has a new pull request.\n\n\n\n\n\n\n\n\n\nIf he clicks on the text Pull requests text, he will be taken to his pull requests page. It will show him all pending pull requests. In this case, there is just the one pull request that Brad sent.\n\n\n\n\n\n\n\n\n\nWhen he clicks on it, he will see a screen like the one in the screenshot below. Scanning from top to bottom, it will tell him which branch Brad is requesting to merge the code into, show him the message Brad wrote, tell him that he can merge this branch without any conflicts if he so chooses, and give him an opportunity to write a message back to Brad before deciding whether to merge this pull request or close it.\n\n\n\n\n\n\n\n\n\nHe also has the option to view some additional details by clicking the Commits tab, Checks tab, and/or Files changed tab towards the top of the screen. Let’s say he decides to click on the Files changed tab.\nOn the Files changed tab, Arthur can see each of the files that the pull request would change if he were to merge it into his repository (in this case, only one file). For each file, he can see (and even comment on) each specific line of code that would change. In this case, Arthur is pleased with the changes and navigates back to the Conversation tab by clicking on it.\n\n\n\n\n\n\n\n\n\nBack on the Conversation tab (see screenshot below), Arthur has some options. If he wants more clarification about the pull request, he can send leave a comment for Brad using the comment box near the bottom of the screen. If he knows that he does NOT want to merge this pull request into his code, he can click the Close pull request button at the bottom of the screen. This will close the pull request and his code will remain unchanged. In this case, Arthur wants to incorporate the changes that Brad sent over, so he clicks the green Merge pull request button in the middle of the screen.\n\n\n\n\n\n\n\n\n\nThen, he is given an opportunity to add some details about the changes this merge will make to the repository once it is committed. You can once again think of this message as having a very similar purpose to commit messages, which were discussed above. In fact, it will appear as a commit in the repository’s commit history.\nFinally, he clicks the green Confirm merge button.\n\n\n\n\n\n\n\n\n\nAnd if Arthur navigates back to his commit history page, he can see two new commits. Brad’s commit with the updated data_01_import.Qmd file, and the commit that was automatically created when Arthur merged the branches together.\n\n\n\n\n\n\n\n\n\nNow, Arthur takes a look at data_01_import.Qmd on his computer. To his surprise, the code to coerce date_received into dates isn’t there. Why not?\n\n\n\n\n\n\n\n\n\nWell, let’s open GitKraken on Arthur’s computer and see if we can help him figure it out. In the repository graph, Arthur’s local repository (i.e., the little laptop icon) and the remote repository (i.e., the little gray and white icon) are on different rows. Additionally, there is a little 2 next to a down arrow displayed to the left of the main branch of our local repository in the left panel of GitKraken. Both of these indicate that the most recent commits contained in each repository are different. Specifically, that the local repository is two commits behind the remote repository.\n\n\n\n\n\n\n\n\n\nSo, let’s pause here for a second and review what we’ve done so far. As shown in the figure below:\n\nBrad made some updates to the code on his computer and then committed those changes to his local repository. At this point, his local repository is out of sync with his remote repository, Arthur’s remote repository, and Arthur’s local repository.\nNext, Brad pushed that commit from his local repository up to his remote repository on GitHub. After doing so, his local repository and remote repository are synced with each other, but they are still out of sync with Arthur’s remote repository and Arthur’s local repository.\nThen, Brad created a pull request for Arthur. The request was for Arthur to pull the latest commit from Brad’s remote repository into Arthur’s remote repository.\nArthur accepted and merged Brad’s pull request. After doing so, his remote repository, Brad’s remote repository, and Brad’s local repository are all contain the updated data_01_import.Qmd file, but Arthur’s local repository still does not.\n\n\n\n\n\n\n\n\n\n\nSo, how does Arthur get his local repository in sync with his remote repository?\nArthur just needs to use the pull command to download the files from his updated remote repository and merge them into his local repository (step 5 below).\n\n\n\n\n\n\n\n\n\nAnd GitKraken makes pulling the files from his remote repository really easy. All Arthur needs to do is click the pull button shown in the screenshot below. GitKraken will download (also called fetch) the updated repository and merge the changes into his local repository.\n\n\n\n\n\n\n\n\n\nAnd as shown in the screenshot below, Arthur can now see that his local repository is now in sync with his remote repository once again! 🎉\n\n\n\n\n\n\n\n\n\nBut, what about Brad’s repository? Well, as you can see in the screenshot below, Brad’s remote repository is now 1 commit behind Arthur’s. Why?\nThis one is kind of weird/tricky. Although the code in Brad’s repository is now identical to the code in Arthur’s repository, the commit history is not. Remember, Arthur’s commit history from above? When he merged Brad’s code into his own, that automatically created an additional commit. And that additional commit does not currently exist in Brad’s commit history. It’s an easy fix though!\n\n\n\n\n\n\n\n\n\nAll Brad needs to do is a quick fetch from Arthur’s remote repository to merge that last commit into his commit history, and then pull it down to his local repository.\n\n\n\n\n\n\n\n\n\nTo do so, Brad will first click Fetch upstream followed by the green Fetch and merge button.\n\n\n\n\n\n\n\n\n\nAfter a few seconds, GitHub will show him that his remote repository is now synced up with Arthur’s remote repository. All he as to do now is a quick pull in GitHub.\n\n\n\n\n\n\n\n\n\nAnd now we have seen the basic process for collaboratively coding with git and GitHub. Don’t feel bad if you are still feeling a little bit confused. Git and GitHub are confusing at times even for experienced programmers. But that doesn’t mean that they aren’t still valuable tools! They are!\nWe also recognize that it might seem like that was a ton of steps above. Again, we went through this process slowly and methodically because we are all trying to learn here. In a real-life project with two experienced collaborators, the steps in this example would typically be completed in a matter of minutes. No big deal.",
    "crumbs": [
      "Collaboration",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Using git and GitHub</span>"
    ]
  },
  {
    "objectID": "chapters/using_git_github/using_git_github.html#summary",
    "href": "chapters/using_git_github/using_git_github.html#summary",
    "title": "21  Using git and GitHub",
    "section": "21.8 Summary",
    "text": "21.8 Summary\nThere is so much more to learn about git and GitHub, but that’s not what this book is about. So, we will stop here. We hope the examples above demonstrate some of the potential value of using git and GitHub in your project workflow. We also hope they give you enough information to get you started.\nHere are some free resources we recommend if you want to learn even more:\n\nChacon S, Straub B. Pro Git. Second. Apress; 2014. Accessed June 13, 2022. https://git-scm.com/book/en/v2\nGitHub. Getting started with GitHub. GitHub Docs. Accessed June 13, 2022. https://ghdocs-prod.azurewebsites.net/en/get-started\nBryan J. Happy Git and GitHub for the useR.; 2016. Accessed June 2, 2022. https://happygitwithr.com/index.html\nKeyes D. How to Use Git/GitHub with R. R for the Rest of Us. Published February 13, 2021. Accessed June 13, 2022. https://rfortherestofus.com/2021/02/how-to-use-git-github-with-r/\nWickham H, Bryan J. Chapter 18 Git and GitHub. In: R Packages. Accessed June 13, 2022. https://r-pkgs.org/git.html\n\n\n\n\n\n1. GitHub. Licensing a repository. Published online May 2022.\n\n\n2. Bryan J. Happy Git and GitHub for the useR.; 2016.",
    "crumbs": [
      "Collaboration",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Using git and GitHub</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "22  References",
    "section": "",
    "text": "1. Bryan J. Happy Git and GitHub\nfor the useR.; 2016.\n\n\n2. GitHub. Licensing a repository. Published\nonline May 2022.\n\n\n3. GitHub. About repositories. Published online\nDecember 2023.\n\n\n4. GitHub. About Issues. Github;\n2024.\n\n\n5. Ismay C, Kim AY. Chapter 1 getting started with\ndata in R. Published online November 2019.\n\n\n6. Peng\nRD. Reproducible research in computational science. Science.\n2011;334(6060):1226-1227.\n\n\n7. Peng\nRD, Hicks SC. Reproducible research: A retrospective. Annu Rev\nPublic Health. 2021;42:79-93.\n\n\n8. R\nCore Team. What Is r? R Foundation for Statistical Computing;\n2024.\n\n\n9. RStudio. RStudio. Published online\n2020.\n\n\n10. RStudio. FAQ: Tips for writing\nr-related questions. Published online September 2021.\n\n\n11. Stack Overflow. What are tags, and how should\nI use them? Published online January 2022.\n\n\n12. Stack Overflow. How do I ask a\ngood question? Published online January 2022.\n\n\n13. Wickham H. Style guide. In: Advanced\nR.; 2019.\n\n\n14. Wickham H, Çetinkaya-Rundel M, Grolemund G.\nWorkflow: Code style. In: R for Data Science.\nsecond.; 2023.",
    "crumbs": [
      "References",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>References</span>"
    ]
  },
  {
    "objectID": "chapters/appendices/glossary.html",
    "href": "chapters/appendices/glossary.html",
    "title": "Appendix A — Glossary",
    "section": "",
    "text": "Console\n\nThe console is located in RStudio’s bottom-right pane by default. The R console is an interactive programming environment where we can enter and execute R commands. It’s the the most basic interface for interacting with R, providing immediate feedback and results from the code we enter. The R console is useful for testing small pieces of code and interactive data exploration. However, we recommend using R scripts or Quarto/ files for all but the simplest programming or data analysis tasks.\n\n\nData frame. For our purposes, data frames are just R’s term for data set or data table. Data frames are made up of columns (variables) and rows (observations). In R, all columns of a data frame must have the same length.\nFunctions. Coming soon.\n\n\nArguments\n\nArguments always live inside the parentheses of R functions and receive information the function needs to generate the result we want.\n\n\n\nPass\n\nIn programming lingo, we pass a value to a function argument. For example, in the function call seq(from = 2, to = 100, by = 2) we could say that we passed a value of 2 to the from argument, we passed a value of 100 to the to argument, and we passed a value of 2 to the by argument.\n\n\n\nReturn\n\nInstead of saying, “the seq() function gives us a sequence of numbers…” we could say, “the seq() function returns a sequence of numbers…” In programming lingo, functions return one or more results.\n\n\n\nGlobal environment. Coming soon.\n\nIssue (GitHub)\n\nGitHub’s documentation says issues are “items you can create in a repository to plan, discuss and track work. Issues are simple to create and flexible to suit a variety of scenarios. You can use issues to track work, give or receive feedback, collaborate on ideas or tasks, and efficiently communicate with others.”1\n\n\nObjects. Coming soon.\n\nR\n\nR’s documentation says “R is a language and environment for statistical computing and graphics. It is a GNU project which is similar to the S language and environment which was developed at Bell Laboratories (formerly AT&T, now Lucent Technologies) by John Chambers and colleagues.”2 R is open source, and you can download it for free from The Comprehensive R Archive Network (CRAN) at https://cran.r-project.org/.\n\nRepository\n\nGitHub’s documentation says “a repository contains all of your code, your files, and each file’s revision history. You can discuss and manage your work within the repository.”3 A repository can exist locally as a set of files on your computer. A repository can also exist remotely as a set of files on a sever somewhere, for example, on GitHub.\n\nRStudio\n\nRStudio is an integrated development environment (IDE) for R. It includes a console, syntax-highlighting editor that supports direct code execution, as well as tools for plotting, history, debugging and workspace management. RStudio is available in open source and commercial editions and runs on the desktop (Windows, Mac, and Linux) or in a browser connected to RStudio Server or RStudio Server Pro (Debian/Ubuntu, Red Hat/CentOS, and SUSE Linux).4\n\n\n\n\n\n\n1. GitHub. About Issues. Github; 2024.\n\n\n2. R Core Team. What Is r? R Foundation for Statistical Computing; 2024.\n\n\n3. GitHub. About repositories. Published online December 2023.\n\n\n4. RStudio. RStudio. Published online 2020.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Glossary</span>"
    ]
  }
]